{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we import the useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then we create a data_path to be able to download the data easily when we need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>693200.0</td>\n",
       "      <td>126</td>\n",
       "      <td>692800.0</td>\n",
       "      <td>110</td>\n",
       "      <td>693300.0</td>\n",
       "      <td>50</td>\n",
       "      <td>692700.0</td>\n",
       "      <td>165</td>\n",
       "      <td>693400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>693500.0</td>\n",
       "      <td>50</td>\n",
       "      <td>692500.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>650400.0</td>\n",
       "      <td>501</td>\n",
       "      <td>650200.0</td>\n",
       "      <td>106</td>\n",
       "      <td>650500.0</td>\n",
       "      <td>245</td>\n",
       "      <td>650100.0</td>\n",
       "      <td>259</td>\n",
       "      <td>650600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>650700.0</td>\n",
       "      <td>141</td>\n",
       "      <td>649900.0</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>636200.0</td>\n",
       "      <td>153</td>\n",
       "      <td>635800.0</td>\n",
       "      <td>150</td>\n",
       "      <td>636300.0</td>\n",
       "      <td>100</td>\n",
       "      <td>635700.0</td>\n",
       "      <td>15</td>\n",
       "      <td>636400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>636500.0</td>\n",
       "      <td>105</td>\n",
       "      <td>635500.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>724800.0</td>\n",
       "      <td>4</td>\n",
       "      <td>724500.0</td>\n",
       "      <td>14</td>\n",
       "      <td>724900.0</td>\n",
       "      <td>50</td>\n",
       "      <td>724300.0</td>\n",
       "      <td>312</td>\n",
       "      <td>725100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>725200.0</td>\n",
       "      <td>379</td>\n",
       "      <td>724100.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>622900.0</td>\n",
       "      <td>110</td>\n",
       "      <td>622700.0</td>\n",
       "      <td>100</td>\n",
       "      <td>623000.0</td>\n",
       "      <td>523</td>\n",
       "      <td>622600.0</td>\n",
       "      <td>300</td>\n",
       "      <td>623100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>623200.0</td>\n",
       "      <td>605</td>\n",
       "      <td>622400.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1    2         3    4         5    6         7    8         9   \\\n",
       "0   1  693200.0  126  692800.0  110  693300.0   50  692700.0  165  693400.0   \n",
       "1   0  650400.0  501  650200.0  106  650500.0  245  650100.0  259  650600.0   \n",
       "2   1  636200.0  153  635800.0  150  636300.0  100  635700.0   15  636400.0   \n",
       "3   0  724800.0    4  724500.0   14  724900.0   50  724300.0  312  725100.0   \n",
       "4   0  622900.0  110  622700.0  100  623000.0  523  622600.0  300  623100.0   \n",
       "\n",
       "   ...   12        13   14        15   16  17  18  19  20  21  \n",
       "0  ...   50  693500.0   50  692500.0  250   0   1   0   1   0  \n",
       "1  ...  328  650700.0  141  649900.0  277   0   0   1   1   1  \n",
       "2  ...  110  636500.0  105  635500.0  201   0   1   0   1   0  \n",
       "3  ...  100  725200.0  379  724100.0   56   1   0   0   1   1  \n",
       "4  ...  249  623200.0  605  622400.0  200   1   0   1   1   0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/arthur/Documents/STUDY/Imperial/Deep Learning /Project/DL-2024-CW-data/Data_A.csv\"\n",
    "data = pd.read_csv(DATA_PATH, header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets rename the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sell_side_l1_price</th>\n",
       "      <th>sell_side_l1_volume</th>\n",
       "      <th>buy_side_l1_price</th>\n",
       "      <th>buy_side_l1_volume</th>\n",
       "      <th>sell_side_l2_price</th>\n",
       "      <th>sell_side_l2_volume</th>\n",
       "      <th>buy_side_l2_price</th>\n",
       "      <th>buy_side_l2_volume</th>\n",
       "      <th>sell_side_l3_price</th>\n",
       "      <th>...</th>\n",
       "      <th>buy_side_l3_volume</th>\n",
       "      <th>sell_side_l4_price</th>\n",
       "      <th>sell_side_l4_volume</th>\n",
       "      <th>buy_side_l4_price</th>\n",
       "      <th>buy_side_l4_volume</th>\n",
       "      <th>prev_change_1</th>\n",
       "      <th>prev_change_2</th>\n",
       "      <th>prev_change_3</th>\n",
       "      <th>prev_change_4</th>\n",
       "      <th>prev_change_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500040</td>\n",
       "      <td>5.740033e+05</td>\n",
       "      <td>234.810725</td>\n",
       "      <td>5.736515e+05</td>\n",
       "      <td>236.838405</td>\n",
       "      <td>5.741346e+05</td>\n",
       "      <td>286.496845</td>\n",
       "      <td>5.735219e+05</td>\n",
       "      <td>289.917960</td>\n",
       "      <td>5.742612e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>313.517335</td>\n",
       "      <td>5.743861e+05</td>\n",
       "      <td>336.284370</td>\n",
       "      <td>5.732733e+05</td>\n",
       "      <td>324.823960</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>0.500710</td>\n",
       "      <td>0.500170</td>\n",
       "      <td>0.500260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500001</td>\n",
       "      <td>1.333872e+05</td>\n",
       "      <td>686.787006</td>\n",
       "      <td>1.332522e+05</td>\n",
       "      <td>673.709255</td>\n",
       "      <td>1.334060e+05</td>\n",
       "      <td>878.593489</td>\n",
       "      <td>1.332350e+05</td>\n",
       "      <td>836.628974</td>\n",
       "      <td>1.334200e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>763.523120</td>\n",
       "      <td>1.334308e+05</td>\n",
       "      <td>955.762494</td>\n",
       "      <td>1.332134e+05</td>\n",
       "      <td>683.779299</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.808000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.806000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.809000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.805000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.810000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.811000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.803000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.397000e+05</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.395000e+05</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>4.398000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.393000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.399000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.400000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.391000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.615000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.609000e+05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.616000e+05</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.605500e+05</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.617000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.618000e+05</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.603000e+05</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.637000e+05</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>6.631000e+05</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>6.638000e+05</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>6.630000e+05</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>6.640000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>6.641000e+05</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>6.627000e+05</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.018400e+06</td>\n",
       "      <td>54367.000000</td>\n",
       "      <td>1.016000e+06</td>\n",
       "      <td>100200.000000</td>\n",
       "      <td>1.018500e+06</td>\n",
       "      <td>80224.000000</td>\n",
       "      <td>1.015400e+06</td>\n",
       "      <td>146425.000000</td>\n",
       "      <td>1.018900e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>100400.000000</td>\n",
       "      <td>1.020000e+06</td>\n",
       "      <td>64878.000000</td>\n",
       "      <td>1.014800e+06</td>\n",
       "      <td>100400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  sell_side_l1_price  sell_side_l1_volume  \\\n",
       "count  200000.000000        2.000000e+05        200000.000000   \n",
       "mean        0.500040        5.740033e+05           234.810725   \n",
       "std         0.500001        1.333872e+05           686.787006   \n",
       "min         0.000000        3.808000e+05             1.000000   \n",
       "25%         0.000000        4.397000e+05            73.000000   \n",
       "50%         1.000000        5.615000e+05           100.000000   \n",
       "75%         1.000000        6.637000e+05           275.000000   \n",
       "max         1.000000        1.018400e+06         54367.000000   \n",
       "\n",
       "       buy_side_l1_price  buy_side_l1_volume  sell_side_l2_price  \\\n",
       "count       2.000000e+05       200000.000000        2.000000e+05   \n",
       "mean        5.736515e+05          236.838405        5.741346e+05   \n",
       "std         1.332522e+05          673.709255        1.334060e+05   \n",
       "min         3.806000e+05            1.000000        3.809000e+05   \n",
       "25%         4.395000e+05           88.000000        4.398000e+05   \n",
       "50%         5.609000e+05          100.000000        5.616000e+05   \n",
       "75%         6.631000e+05          293.000000        6.638000e+05   \n",
       "max         1.016000e+06       100200.000000        1.018500e+06   \n",
       "\n",
       "       sell_side_l2_volume  buy_side_l2_price  buy_side_l2_volume  \\\n",
       "count        200000.000000       2.000000e+05       200000.000000   \n",
       "mean            286.496845       5.735219e+05          289.917960   \n",
       "std             878.593489       1.332350e+05          836.628974   \n",
       "min               1.000000       3.805000e+05            1.000000   \n",
       "25%             100.000000       4.393000e+05          100.000000   \n",
       "50%             200.000000       5.605500e+05          200.000000   \n",
       "75%             310.000000       6.630000e+05          329.000000   \n",
       "max           80224.000000       1.015400e+06       146425.000000   \n",
       "\n",
       "       sell_side_l3_price  ...  buy_side_l3_volume  sell_side_l4_price  \\\n",
       "count        2.000000e+05  ...       200000.000000        2.000000e+05   \n",
       "mean         5.742612e+05  ...          313.517335        5.743861e+05   \n",
       "std          1.334200e+05  ...          763.523120        1.334308e+05   \n",
       "min          3.810000e+05  ...            1.000000        3.811000e+05   \n",
       "25%          4.399000e+05  ...          100.000000        4.400000e+05   \n",
       "50%          5.617000e+05  ...          200.000000        5.618000e+05   \n",
       "75%          6.640000e+05  ...          380.000000        6.641000e+05   \n",
       "max          1.018900e+06  ...       100400.000000        1.020000e+06   \n",
       "\n",
       "       sell_side_l4_volume  buy_side_l4_price  buy_side_l4_volume  \\\n",
       "count        200000.000000       2.000000e+05       200000.000000   \n",
       "mean            336.284370       5.732733e+05          324.823960   \n",
       "std             955.762494       1.332134e+05          683.779299   \n",
       "min               1.000000       3.803000e+05            1.000000   \n",
       "25%             100.000000       4.391000e+05          100.000000   \n",
       "50%             200.000000       5.603000e+05          200.000000   \n",
       "75%             393.000000       6.627000e+05          400.000000   \n",
       "max           64878.000000       1.014800e+06       100400.000000   \n",
       "\n",
       "       prev_change_1  prev_change_2  prev_change_3  prev_change_4  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.500200       0.500750       0.500710       0.500170   \n",
       "std         0.500001       0.500001       0.500001       0.500001   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       prev_change_5  \n",
       "count  200000.000000  \n",
       "mean        0.500260  \n",
       "std         0.500001  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN_NAMES = [\n",
    "    \"label\",\n",
    "    \"sell_side_l1_price\", \"sell_side_l1_volume\",\n",
    "    \"buy_side_l1_price\", \"buy_side_l1_volume\",\n",
    "    \"sell_side_l2_price\", \"sell_side_l2_volume\",\n",
    "    \"buy_side_l2_price\", \"buy_side_l2_volume\",\n",
    "    \"sell_side_l3_price\", \"sell_side_l3_volume\",\n",
    "    \"buy_side_l3_price\", \"buy_side_l3_volume\",\n",
    "    \"sell_side_l4_price\", \"sell_side_l4_volume\",\n",
    "    \"buy_side_l4_price\", \"buy_side_l4_volume\",\n",
    "    \"prev_change_1\", \"prev_change_2\", \"prev_change_3\", \n",
    "    \"prev_change_4\", \"prev_change_5\"\n",
    "]\n",
    "\n",
    "data.columns = COLUMN_NAMES\n",
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a few remarks first. Note that there is no missing values, the dataset is easy to read. When we look at the volume columns, we see that the order of magnitude is around $10^2$-$10^3$, but the maximum values are in the order of $10^5$, these values seem extreme so it should be interesting to see how they impact the dataset. We will take a look at the different features distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution for volume & price for level 1 (buy and sell)\n",
    "def plot_distributions(data, features, title):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(data[feature], kde=True, color='blue', bins=50)\n",
    "        plt.title(f\"{title}: {feature}\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Features for volume and price for level 1\n",
    "level_1_features = [\"sell_side_l1_price\", \"sell_side_l1_volume\", \"buy_side_l1_price\", \"buy_side_l1_volume\"]\n",
    "plot_distributions(data, level_1_features, title=\"Distribution for Level 1 Features\")\n",
    "\n",
    "# Features for prev_change 1 & 2\n",
    "prev_changes = [\"prev_change_1\", \"prev_change_2\"]\n",
    "plot_distributions(data, prev_changes, title=\"Distribution for Previous Changes\")\n",
    "\n",
    "# Boxplot for volume level 1 and level 2 (buy and sell)\n",
    "boxplot_features = [\n",
    "    \"sell_side_l1_volume\", \"buy_side_l1_volume\",\n",
    "    \"sell_side_l2_volume\", \"buy_side_l2_volume\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data[boxplot_features])\n",
    "plt.title(\"Boxplot for Volume Features (Level 1 and Level 2)\")\n",
    "plt.xticks(range(len(boxplot_features)), boxplot_features, rotation=45)\n",
    "plt.ylabel(\"Volume\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see the proportion of volume values that are greater than $10^4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: sell_side_l1_volume, Proportion of values > 10^4: 5.45%\n",
      "Feature: buy_side_l1_volume, Proportion of values > 10^4: 5.65%\n",
      "Feature: sell_side_l2_volume, Proportion of values > 10^4: 9.05%\n",
      "Feature: buy_side_l2_volume, Proportion of values > 10^4: 8.70%\n",
      "Feature: sell_side_l3_volume, Proportion of values > 10^4: 8.45%\n",
      "Feature: buy_side_l3_volume, Proportion of values > 10^4: 8.25%\n",
      "Feature: sell_side_l4_volume, Proportion of values > 10^4: 10.50%\n",
      "Feature: buy_side_l4_volume, Proportion of values > 10^4: 6.50%\n"
     ]
    }
   ],
   "source": [
    "volume_features = [col for col in data.columns if \"volume\" in col]\n",
    "proportions = {}\n",
    "threshold = 10**4\n",
    "for feature in volume_features:\n",
    "    total_values = len(data[feature])\n",
    "    values_above_threshold = (data[feature] > threshold).sum()\n",
    "    proportions[feature] = values_above_threshold / total_values\n",
    "for feature, proportion in proportions.items():\n",
    "    print(f\"Feature: {feature}, Proportion of values > 10^4: {100*proportion:.2%}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this coursework, we want to predict midprice change direction based on data that has no time series structur. Thus, we might want to remove the extreme volume values from our training set. Let see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 931\n",
      "Remaining rows: 199069\n"
     ]
    }
   ],
   "source": [
    "volume_features = [col for col in data.columns if \"volume\" in col]\n",
    "threshold = 10**4\n",
    "truncated_data_set = data[~data[volume_features].gt(threshold).any(axis=1)].copy()\n",
    "rows_removed = len(data) - len(truncated_data_set)\n",
    "print(f\"Rows removed: {rows_removed}\")\n",
    "print(f\"Remaining rows: {len(truncated_data_set)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1°) First naive model: Intuitive LOB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this basic model is based on a simple economic idea: if the BUY volume is greater than the SELL volume, the price will rise. There is many volume columns so we will try different features and see which one is the best for predicting the price change. \n",
    "There is different way to see it, we can look at first order book level to have a primitive intuition of market bevaior, or we can treat all the information given by data set and look at all the volume by summing them. We assume that the levels follow each other in order, as suggested by the project statement. This allows us to sum them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sell_side_l1_price</th>\n",
       "      <th>sell_side_l1_volume</th>\n",
       "      <th>buy_side_l1_price</th>\n",
       "      <th>buy_side_l1_volume</th>\n",
       "      <th>sell_side_l2_price</th>\n",
       "      <th>sell_side_l2_volume</th>\n",
       "      <th>buy_side_l2_price</th>\n",
       "      <th>buy_side_l2_volume</th>\n",
       "      <th>sell_side_l3_price</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume_Ratio_L4</th>\n",
       "      <th>Total_Sell_Volume_1+2</th>\n",
       "      <th>Total_Buy_Volume_1+2</th>\n",
       "      <th>Volume_Ratio_1+2</th>\n",
       "      <th>Total_Sell_Volume_1+2+3</th>\n",
       "      <th>Total_Buy_Volume_1+2+3</th>\n",
       "      <th>Volume_Ratio_1+2+3</th>\n",
       "      <th>Total_Sell_Volume_1+2+3+4</th>\n",
       "      <th>Total_Buy_Volume_1+2+3+4</th>\n",
       "      <th>Volume_Ratio_1+2+3+4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>693200.0</td>\n",
       "      <td>126</td>\n",
       "      <td>692800.0</td>\n",
       "      <td>110</td>\n",
       "      <td>693300.0</td>\n",
       "      <td>50</td>\n",
       "      <td>692700.0</td>\n",
       "      <td>165</td>\n",
       "      <td>693400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>176</td>\n",
       "      <td>275</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>413</td>\n",
       "      <td>325</td>\n",
       "      <td>0.559621</td>\n",
       "      <td>463</td>\n",
       "      <td>575</td>\n",
       "      <td>0.446050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>650400.0</td>\n",
       "      <td>501</td>\n",
       "      <td>650200.0</td>\n",
       "      <td>106</td>\n",
       "      <td>650500.0</td>\n",
       "      <td>245</td>\n",
       "      <td>650100.0</td>\n",
       "      <td>259</td>\n",
       "      <td>650600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337321</td>\n",
       "      <td>746</td>\n",
       "      <td>365</td>\n",
       "      <td>0.671467</td>\n",
       "      <td>894</td>\n",
       "      <td>693</td>\n",
       "      <td>0.563327</td>\n",
       "      <td>1035</td>\n",
       "      <td>970</td>\n",
       "      <td>0.516209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>636200.0</td>\n",
       "      <td>153</td>\n",
       "      <td>635800.0</td>\n",
       "      <td>150</td>\n",
       "      <td>636300.0</td>\n",
       "      <td>100</td>\n",
       "      <td>635700.0</td>\n",
       "      <td>15</td>\n",
       "      <td>636400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343137</td>\n",
       "      <td>253</td>\n",
       "      <td>165</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>403</td>\n",
       "      <td>275</td>\n",
       "      <td>0.594395</td>\n",
       "      <td>508</td>\n",
       "      <td>476</td>\n",
       "      <td>0.516260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>724800.0</td>\n",
       "      <td>4</td>\n",
       "      <td>724500.0</td>\n",
       "      <td>14</td>\n",
       "      <td>724900.0</td>\n",
       "      <td>50</td>\n",
       "      <td>724300.0</td>\n",
       "      <td>312</td>\n",
       "      <td>725100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871264</td>\n",
       "      <td>54</td>\n",
       "      <td>326</td>\n",
       "      <td>0.142105</td>\n",
       "      <td>204</td>\n",
       "      <td>426</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>583</td>\n",
       "      <td>482</td>\n",
       "      <td>0.547418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>622900.0</td>\n",
       "      <td>110</td>\n",
       "      <td>622700.0</td>\n",
       "      <td>100</td>\n",
       "      <td>623000.0</td>\n",
       "      <td>523</td>\n",
       "      <td>622600.0</td>\n",
       "      <td>300</td>\n",
       "      <td>623100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751553</td>\n",
       "      <td>633</td>\n",
       "      <td>400</td>\n",
       "      <td>0.612778</td>\n",
       "      <td>1071</td>\n",
       "      <td>649</td>\n",
       "      <td>0.622674</td>\n",
       "      <td>1676</td>\n",
       "      <td>849</td>\n",
       "      <td>0.663762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  sell_side_l1_price  sell_side_l1_volume  buy_side_l1_price  \\\n",
       "0      1            693200.0                  126           692800.0   \n",
       "1      0            650400.0                  501           650200.0   \n",
       "2      1            636200.0                  153           635800.0   \n",
       "3      0            724800.0                    4           724500.0   \n",
       "4      0            622900.0                  110           622700.0   \n",
       "\n",
       "   buy_side_l1_volume  sell_side_l2_price  sell_side_l2_volume  \\\n",
       "0                 110            693300.0                   50   \n",
       "1                 106            650500.0                  245   \n",
       "2                 150            636300.0                  100   \n",
       "3                  14            724900.0                   50   \n",
       "4                 100            623000.0                  523   \n",
       "\n",
       "   buy_side_l2_price  buy_side_l2_volume  sell_side_l3_price  ...  \\\n",
       "0           692700.0                 165            693400.0  ...   \n",
       "1           650100.0                 259            650600.0  ...   \n",
       "2           635700.0                  15            636400.0  ...   \n",
       "3           724300.0                 312            725100.0  ...   \n",
       "4           622600.0                 300            623100.0  ...   \n",
       "\n",
       "   Volume_Ratio_L4  Total_Sell_Volume_1+2  Total_Buy_Volume_1+2  \\\n",
       "0         0.166667                    176                   275   \n",
       "1         0.337321                    746                   365   \n",
       "2         0.343137                    253                   165   \n",
       "3         0.871264                     54                   326   \n",
       "4         0.751553                    633                   400   \n",
       "\n",
       "   Volume_Ratio_1+2  Total_Sell_Volume_1+2+3  Total_Buy_Volume_1+2+3  \\\n",
       "0          0.390244                      413                     325   \n",
       "1          0.671467                      894                     693   \n",
       "2          0.605263                      403                     275   \n",
       "3          0.142105                      204                     426   \n",
       "4          0.612778                     1071                     649   \n",
       "\n",
       "   Volume_Ratio_1+2+3  Total_Sell_Volume_1+2+3+4  Total_Buy_Volume_1+2+3+4  \\\n",
       "0            0.559621                        463                       575   \n",
       "1            0.563327                       1035                       970   \n",
       "2            0.594395                        508                       476   \n",
       "3            0.323810                        583                       482   \n",
       "4            0.622674                       1676                       849   \n",
       "\n",
       "   Volume_Ratio_1+2+3+4  \n",
       "0              0.446050  \n",
       "1              0.516209  \n",
       "2              0.516260  \n",
       "3              0.547418  \n",
       "4              0.663762  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed = data.copy()\n",
    "\n",
    "# Add total sell and buy volumes for combined levels (L1 to L4)\n",
    "data_transformed[\"Total_Sell_Volume\"] = (\n",
    "    data_transformed[\"sell_side_l1_volume\"] + data_transformed[\"sell_side_l2_volume\"] + \n",
    "    data_transformed[\"sell_side_l3_volume\"] + data_transformed[\"sell_side_l4_volume\"]\n",
    ")\n",
    "\n",
    "data_transformed[\"Total_Buy_Volume\"] = (\n",
    "    data_transformed[\"buy_side_l1_volume\"] + data_transformed[\"buy_side_l2_volume\"] + \n",
    "    data_transformed[\"buy_side_l3_volume\"] + data_transformed[\"buy_side_l4_volume\"]\n",
    ")\n",
    "\n",
    "# Add ratio\n",
    "data_transformed[\"Volume_Ratio\"] = (\n",
    "    data_transformed[\"Total_Sell_Volume\"] / \n",
    "    (data_transformed[\"Total_Sell_Volume\"] + data_transformed[\"Total_Buy_Volume\"])\n",
    ")\n",
    "\n",
    "# Add individual levels and combinations\n",
    "combinations = {\n",
    "    \"L1\": [\"sell_side_l1_volume\", \"buy_side_l1_volume\"],\n",
    "    \"L2\": [\"sell_side_l2_volume\", \"buy_side_l2_volume\"],\n",
    "    \"L3\": [\"sell_side_l3_volume\", \"buy_side_l3_volume\"],\n",
    "    \"L4\": [\"sell_side_l4_volume\", \"buy_side_l4_volume\"],\n",
    "    \"1+2\": [\"sell_side_l1_volume\", \"sell_side_l2_volume\", \"buy_side_l1_volume\", \"buy_side_l2_volume\"],\n",
    "    \"1+2+3\": [\"sell_side_l1_volume\", \"sell_side_l2_volume\", \"sell_side_l3_volume\", \n",
    "              \"buy_side_l1_volume\", \"buy_side_l2_volume\", \"buy_side_l3_volume\"],\n",
    "    \"1+2+3+4\": [\"sell_side_l1_volume\", \"sell_side_l2_volume\", \"sell_side_l3_volume\", \"sell_side_l4_volume\", \n",
    "                \"buy_side_l1_volume\", \"buy_side_l2_volume\", \"buy_side_l3_volume\", \"buy_side_l4_volume\"]\n",
    "}\n",
    "\n",
    "# Calculate total sell and buy volumes for each combination\n",
    "for key, columns in combinations.items():\n",
    "    sell_columns = [col for col in columns if \"sell\" in col]\n",
    "    buy_columns = [col for col in columns if \"buy\" in col]\n",
    "    \n",
    "    data_transformed[f\"Total_Sell_Volume_{key}\"] = data_transformed[sell_columns].sum(axis=1)\n",
    "    data_transformed[f\"Total_Buy_Volume_{key}\"] = data_transformed[buy_columns].sum(axis=1)\n",
    "    data_transformed[f\"Volume_Ratio_{key}\"] = (\n",
    "        data_transformed[f\"Total_Sell_Volume_{key}\"] /\n",
    "        (data_transformed[f\"Total_Sell_Volume_{key}\"] + data_transformed[f\"Total_Buy_Volume_{key}\"])\n",
    "    )\n",
    "\n",
    "data_transformed.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the accuracies for the LOB ratio model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Volume_Ratio: 0.5936\n",
      "Accuracy for Volume_Ratio_L1: 0.6839\n",
      "Accuracy for Volume_Ratio_L2: 0.5277\n",
      "Accuracy for Volume_Ratio_L3: 0.5154\n",
      "Accuracy for Volume_Ratio_L4: 0.5053\n",
      "Accuracy for Volume_Ratio_1+2: 0.6352\n",
      "Accuracy for Volume_Ratio_1+2+3: 0.6097\n",
      "Accuracy for Volume_Ratio_1+2+3+4: 0.5936\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "ratios = [\"Volume_Ratio\"] + [f\"Volume_Ratio_{key}\" for key in combinations.keys()]\n",
    "for ratio in ratios:\n",
    "    # prediction based on ratio\n",
    "    prediction_column = f\"Prediction_{ratio}\"\n",
    "    data_transformed[prediction_column] = (data_transformed[ratio] < 0.5).astype(int)\n",
    "    accuracy = accuracy_score(data_transformed[\"label\"], data_transformed[prediction_column])\n",
    "    accuracies[ratio] = accuracy\n",
    "for ratio, accuracy in accuracies.items():\n",
    "    print(f\"Accuracy for {ratio}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the level 1 volume is enough to get an accuracy of 0.68 which is already an arbitrage in itself. Now this analysis highlights that the information is not equally distributed among the dataset. This suggests to perform a dimension reduction using PCA. The accuracy we want to beat with our Deep Learning Model is set at 0.68. First we will try a model that uses SHAP values analysis to see which features are the most important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2°) SHAP values analysis\n",
    "\n",
    "The Shap values analysis allow us to have an idea of each feature's importance, for this we gonna take a basic deep learning model and use a small sample of data in order to have a decent execution speed. The aim is not to make good predictions but to have an \"importance ranking\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5727 - loss: 1.8980\n",
      "Epoch 2/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 1.4443\n",
      "Epoch 3/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 1.1954\n",
      "Epoch 4/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6425 - loss: 1.0150\n",
      "Epoch 5/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.8933\n",
      "Epoch 6/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.8268\n",
      "Epoch 7/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.7702\n",
      "Epoch 8/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.7215\n",
      "Epoch 9/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6734 - loss: 0.6978\n",
      "Epoch 10/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6835 - loss: 0.6689\n",
      "Elapsed Time: 0.11 minutes\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639d9fb827414812b253f6503c0be608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 996us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 993us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 969us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 991us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 991us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 983us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 968us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 969us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_PATH, header=None) \n",
    "\n",
    "COLUMN_NAMES = [\n",
    "    \"label\",\n",
    "    \"sell_side_l1_price\", \"sell_side_l1_volume\",\n",
    "    \"buy_side_l1_price\", \"buy_side_l1_volume\",\n",
    "    \"sell_side_l2_price\", \"sell_side_l2_volume\",\n",
    "    \"buy_side_l2_price\", \"buy_side_l2_volume\",\n",
    "    \"sell_side_l3_price\", \"sell_side_l3_volume\",\n",
    "    \"buy_side_l3_price\", \"buy_side_l3_volume\",\n",
    "    \"sell_side_l4_price\", \"sell_side_l4_volume\",\n",
    "    \"buy_side_l4_price\", \"buy_side_l4_volume\",\n",
    "    \"prev_change_1\", \"prev_change_2\", \"prev_change_3\", \n",
    "    \"prev_change_4\", \"prev_change_5\"\n",
    "]\n",
    "\n",
    "data.columns = COLUMN_NAMES\n",
    "data.describe()\n",
    "\n",
    "X = data.iloc[:, 1:].values  # features\n",
    "y = data.iloc[:, 0].values   # labels\n",
    "# Normalize the features: crucial if we want to apply PCA later on\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_sample, y_sample = resample(X, y, n_samples=5000, random_state=42)\n",
    "def build_model(units=64, learning_rate=0.001, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(units, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_sample.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(units // 2, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "best_params = {\n",
    "    'model__units': 128,\n",
    "    'model__learning_rate': 0.001,\n",
    "    'model__dropout_rate': 0.3,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32\n",
    "}\n",
    "best_model = KerasClassifier(\n",
    "    model=build_model,\n",
    "    model__units=best_params['model__units'],\n",
    "    model__learning_rate=best_params['model__learning_rate'],\n",
    "    model__dropout_rate=best_params['model__dropout_rate'],\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    verbose=1\n",
    ")\n",
    "start_time = time.time()\n",
    "# train\n",
    "best_model.fit(X_sample, y_sample)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed Time: {elapsed_time / 60:.2f} minutes\")\n",
    "# SHAP feature importance\n",
    "explainer = shap.KernelExplainer(best_model.predict, shap.sample(X_sample, 100))\n",
    "shap_values = explainer.shap_values(X_sample[:50]) \n",
    "feature_names = np.array(COLUMN_NAMES[1:]) \n",
    "shap.summary_plot(shap_values, X_sample[:50], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first levels information are the most important features and that the past changes are also signifactive. We notice also that the volume features for level 2,3 4 are not really important which follows our intuition that we got from the LOB model. An idea would be to test a dataset where we only keep the volume features for level 1, but a better way to implement this idea is to do a PCA, we will reduce the number of features and keep the whole variance information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3°) PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio for each component: [0.39409315 0.09961686 0.06898437 0.04410975 0.04373939 0.04347362\n",
      " 0.04117595 0.04089    0.04053797 0.04020227 0.0372587  0.03636626\n",
      " 0.03607781 0.03347252]\n",
      "Cumulative explained variance: [0.39409315 0.49371001 0.56269438 0.60680413 0.65054352 0.69401714\n",
      " 0.73519309 0.77608309 0.81662107 0.85682333 0.89408204 0.9304483\n",
      " 0.9665261  0.99999862]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_PATH, header=None) \n",
    "data.columns = COLUMN_NAMES\n",
    "\n",
    "X = data.drop(columns=[\"label\"])\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "n_components = 14\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)  \n",
    "X_test_pca = pca.transform(X_test_scaled)       \n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio for each component: {explained_variance_ratio}\")\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "print(f\"Cumulative explained variance: {cumulative_variance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4°) Deep Learning model: comparing performance of our 3 dataset : PCA , PCA with extreme values removed and normal dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will find the best hyperparameters with a fixed number of epochs of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "Dropout: 0.2\n",
      "Batch Size: 20\n",
      "Neurons: 160\n",
      "Activation: relu\n",
      "Test Accuracy: 0.7153\n",
      "Test Loss: 0.5439\n"
     ]
    }
   ],
   "source": [
    "# Sample 30% of the data\n",
    "sample_data = data.sample(frac=0.3, random_state=42)\n",
    "X_sample = sample_data.drop(columns=[\"label\"])\n",
    "y_sample = sample_data[\"label\"]\n",
    "\n",
    "# Split the sample into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "dropouts = [0.1, 0.2, 0.3]\n",
    "batch_sizes = [20, 50, 100, 200]\n",
    "neurons = [60, 80, 120, 160, 180, 200]\n",
    "activations = ['relu', 'leaky_relu']\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform grid search\n",
    "for dropout, batch_size, neuron, activation in product(dropouts, batch_sizes, neurons, activations):\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=(X_train_scaled.shape[1],)))\n",
    "    if activation == 'relu':\n",
    "        model.add(Dense(neuron, activation='relu'))\n",
    "    elif activation == 'leaky_relu':\n",
    "        model.add(Dense(neuron))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(neuron // 2, activation=activation if activation == 'relu' else None))\n",
    "    if activation == 'leaky_relu':\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(neuron // 4, activation=activation if activation == 'relu' else None))\n",
    "    if activation == 'leaky_relu':\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"dropout\": dropout,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"neurons\": neuron,\n",
    "        \"activation\": activation,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_loss\": test_loss\n",
    "    })\n",
    "\n",
    "# Find the best parameters\n",
    "best_result = max(results, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "# Print the best result\n",
    "print(\"Best Parameters:\")\n",
    "print(f\"Dropout: {best_result['dropout']}\")\n",
    "print(f\"Batch Size: {best_result['batch_size']}\")\n",
    "print(f\"Neurons: {best_result['neurons']}\")\n",
    "print(f\"Activation: {best_result['activation']}\")\n",
    "print(f\"Test Accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Test Loss: {best_result['test_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are quite logical, but in order to have a reasonable time of speed, we'll set batchsize at 100 and neurons at 128 which is not too far from 160. Now will analyze where to stop the epochs in order to avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6349 - loss: 0.6286 - val_accuracy: 0.7030 - val_loss: 0.5580\n",
      "Epoch 2/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.5677 - val_accuracy: 0.7040 - val_loss: 0.5585\n",
      "Epoch 3/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.5594 - val_accuracy: 0.7086 - val_loss: 0.5489\n",
      "Epoch 4/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.5553 - val_accuracy: 0.7082 - val_loss: 0.5471\n",
      "Epoch 5/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.5543 - val_accuracy: 0.7085 - val_loss: 0.5457\n",
      "Epoch 6/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7072 - loss: 0.5499 - val_accuracy: 0.7096 - val_loss: 0.5443\n",
      "Epoch 7/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.5476 - val_accuracy: 0.7091 - val_loss: 0.5445\n",
      "Epoch 8/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.5495 - val_accuracy: 0.7120 - val_loss: 0.5414\n",
      "Epoch 9/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.5468 - val_accuracy: 0.7109 - val_loss: 0.5424\n",
      "Epoch 10/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7087 - loss: 0.5472 - val_accuracy: 0.7125 - val_loss: 0.5420\n",
      "Epoch 11/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.5462 - val_accuracy: 0.7109 - val_loss: 0.5436\n",
      "Epoch 12/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.5446 - val_accuracy: 0.7120 - val_loss: 0.5407\n",
      "Epoch 13/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.5440 - val_accuracy: 0.7129 - val_loss: 0.5411\n",
      "Epoch 14/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7117 - loss: 0.5417 - val_accuracy: 0.7140 - val_loss: 0.5405\n",
      "Epoch 15/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.5411 - val_accuracy: 0.7137 - val_loss: 0.5398\n",
      "Epoch 16/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.5404 - val_accuracy: 0.7145 - val_loss: 0.5396\n",
      "Epoch 17/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.5419 - val_accuracy: 0.7138 - val_loss: 0.5387\n",
      "Epoch 18/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.5431 - val_accuracy: 0.7162 - val_loss: 0.5377\n",
      "Epoch 19/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 0.5402 - val_accuracy: 0.7160 - val_loss: 0.5380\n",
      "Epoch 20/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.5420 - val_accuracy: 0.7151 - val_loss: 0.5380\n",
      "Epoch 21/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.5405 - val_accuracy: 0.7144 - val_loss: 0.5393\n",
      "Epoch 22/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.5389 - val_accuracy: 0.7172 - val_loss: 0.5382\n",
      "Epoch 23/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.5390 - val_accuracy: 0.7164 - val_loss: 0.5374\n",
      "Epoch 24/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.5367 - val_accuracy: 0.7145 - val_loss: 0.5387\n",
      "Epoch 25/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.5357 - val_accuracy: 0.7180 - val_loss: 0.5366\n",
      "Epoch 26/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.5369 - val_accuracy: 0.7147 - val_loss: 0.5371\n",
      "Epoch 27/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.5395 - val_accuracy: 0.7174 - val_loss: 0.5368\n",
      "Epoch 28/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.5403 - val_accuracy: 0.7169 - val_loss: 0.5352\n",
      "Epoch 29/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7147 - loss: 0.5385 - val_accuracy: 0.7171 - val_loss: 0.5362\n",
      "Epoch 30/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5364 - val_accuracy: 0.7161 - val_loss: 0.5362\n",
      "Epoch 31/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5358 - val_accuracy: 0.7164 - val_loss: 0.5378\n",
      "Epoch 32/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.5372 - val_accuracy: 0.7162 - val_loss: 0.5355\n",
      "Epoch 33/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5367 - val_accuracy: 0.7176 - val_loss: 0.5355\n",
      "Epoch 34/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5379 - val_accuracy: 0.7174 - val_loss: 0.5367\n",
      "Epoch 35/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.5387 - val_accuracy: 0.7178 - val_loss: 0.5370\n",
      "Epoch 36/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.5371 - val_accuracy: 0.7178 - val_loss: 0.5363\n",
      "Epoch 37/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7130 - loss: 0.5378 - val_accuracy: 0.7186 - val_loss: 0.5353\n",
      "Epoch 38/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.5380 - val_accuracy: 0.7158 - val_loss: 0.5361\n",
      "Epoch 39/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.5357 - val_accuracy: 0.7182 - val_loss: 0.5364\n",
      "Epoch 40/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.5356 - val_accuracy: 0.7202 - val_loss: 0.5345\n",
      "Epoch 41/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5350 - val_accuracy: 0.7177 - val_loss: 0.5343\n",
      "Epoch 42/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.5336 - val_accuracy: 0.7165 - val_loss: 0.5369\n",
      "Epoch 43/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.5363 - val_accuracy: 0.7162 - val_loss: 0.5356\n",
      "Epoch 44/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.5353 - val_accuracy: 0.7176 - val_loss: 0.5369\n",
      "Epoch 45/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.5363 - val_accuracy: 0.7183 - val_loss: 0.5357\n",
      "Epoch 46/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.5339 - val_accuracy: 0.7182 - val_loss: 0.5340\n",
      "Epoch 47/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.5333 - val_accuracy: 0.7172 - val_loss: 0.5343\n",
      "Epoch 48/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.5319 - val_accuracy: 0.7174 - val_loss: 0.5359\n",
      "Epoch 49/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7165 - loss: 0.5349 - val_accuracy: 0.7156 - val_loss: 0.5360\n",
      "Epoch 50/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5323 - val_accuracy: 0.7189 - val_loss: 0.5348\n",
      "Epoch 51/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5310 - val_accuracy: 0.7192 - val_loss: 0.5347\n",
      "Epoch 52/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.5339 - val_accuracy: 0.7168 - val_loss: 0.5351\n",
      "Epoch 53/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5324 - val_accuracy: 0.7176 - val_loss: 0.5347\n",
      "Epoch 54/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.5337 - val_accuracy: 0.7182 - val_loss: 0.5346\n",
      "Epoch 55/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.5323 - val_accuracy: 0.7180 - val_loss: 0.5364\n",
      "Epoch 56/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.5362 - val_accuracy: 0.7182 - val_loss: 0.5363\n",
      "Epoch 57/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5308 - val_accuracy: 0.7201 - val_loss: 0.5345\n",
      "Epoch 58/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.5310 - val_accuracy: 0.7187 - val_loss: 0.5342\n",
      "Epoch 59/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5307 - val_accuracy: 0.7181 - val_loss: 0.5345\n",
      "Epoch 60/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5327 - val_accuracy: 0.7183 - val_loss: 0.5334\n",
      "Epoch 61/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.5300 - val_accuracy: 0.7168 - val_loss: 0.5361\n",
      "Epoch 62/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5322 - val_accuracy: 0.7179 - val_loss: 0.5349\n",
      "Epoch 63/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.5321 - val_accuracy: 0.7176 - val_loss: 0.5345\n",
      "Epoch 64/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.5337 - val_accuracy: 0.7195 - val_loss: 0.5349\n",
      "Epoch 65/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5330 - val_accuracy: 0.7184 - val_loss: 0.5353\n",
      "Epoch 66/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.5319 - val_accuracy: 0.7179 - val_loss: 0.5348\n",
      "Epoch 67/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.5326 - val_accuracy: 0.7168 - val_loss: 0.5369\n",
      "Epoch 68/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7202 - loss: 0.5318 - val_accuracy: 0.7187 - val_loss: 0.5345\n",
      "Epoch 69/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.5310 - val_accuracy: 0.7206 - val_loss: 0.5341\n",
      "Epoch 70/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.5314 - val_accuracy: 0.7196 - val_loss: 0.5341\n",
      "Epoch 71/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.5313 - val_accuracy: 0.7191 - val_loss: 0.5340\n",
      "Epoch 72/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5292 - val_accuracy: 0.7195 - val_loss: 0.5338\n",
      "Epoch 73/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.5315 - val_accuracy: 0.7174 - val_loss: 0.5349\n",
      "Epoch 74/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.5326 - val_accuracy: 0.7141 - val_loss: 0.5397\n",
      "Epoch 75/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5288 - val_accuracy: 0.7188 - val_loss: 0.5349\n",
      "Epoch 76/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5300 - val_accuracy: 0.7186 - val_loss: 0.5359\n",
      "Epoch 77/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.5342 - val_accuracy: 0.7201 - val_loss: 0.5336\n",
      "Epoch 78/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5316 - val_accuracy: 0.7188 - val_loss: 0.5344\n",
      "Epoch 79/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.5309 - val_accuracy: 0.7183 - val_loss: 0.5351\n",
      "Epoch 80/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5310 - val_accuracy: 0.7193 - val_loss: 0.5344\n",
      "Epoch 81/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.5283 - val_accuracy: 0.7195 - val_loss: 0.5360\n",
      "Epoch 82/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5305 - val_accuracy: 0.7172 - val_loss: 0.5345\n",
      "Epoch 83/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.5328 - val_accuracy: 0.7199 - val_loss: 0.5338\n",
      "Epoch 84/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.5292 - val_accuracy: 0.7202 - val_loss: 0.5343\n",
      "Epoch 85/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.5299 - val_accuracy: 0.7190 - val_loss: 0.5354\n",
      "Epoch 86/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5286 - val_accuracy: 0.7180 - val_loss: 0.5348\n",
      "Epoch 87/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5303 - val_accuracy: 0.7197 - val_loss: 0.5349\n",
      "Epoch 88/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.5312 - val_accuracy: 0.7195 - val_loss: 0.5357\n",
      "Epoch 89/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.5309 - val_accuracy: 0.7197 - val_loss: 0.5332\n",
      "Epoch 90/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.5313 - val_accuracy: 0.7201 - val_loss: 0.5345\n",
      "Epoch 91/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.5291 - val_accuracy: 0.7191 - val_loss: 0.5342\n",
      "Epoch 92/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7216 - loss: 0.5300 - val_accuracy: 0.7194 - val_loss: 0.5343\n",
      "Epoch 93/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.5305 - val_accuracy: 0.7171 - val_loss: 0.5346\n",
      "Epoch 94/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.5317 - val_accuracy: 0.7195 - val_loss: 0.5342\n",
      "Epoch 95/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.5307 - val_accuracy: 0.7206 - val_loss: 0.5330\n",
      "Epoch 96/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.5291 - val_accuracy: 0.7179 - val_loss: 0.5351\n",
      "Epoch 97/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5317 - val_accuracy: 0.7179 - val_loss: 0.5350\n",
      "Epoch 98/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5295 - val_accuracy: 0.7209 - val_loss: 0.5345\n",
      "Epoch 99/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.5285 - val_accuracy: 0.7189 - val_loss: 0.5339\n",
      "Epoch 100/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5288 - val_accuracy: 0.7187 - val_loss: 0.5324\n",
      "Epoch 101/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5301 - val_accuracy: 0.7180 - val_loss: 0.5341\n",
      "Epoch 102/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.5291 - val_accuracy: 0.7188 - val_loss: 0.5339\n",
      "Epoch 103/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5258 - val_accuracy: 0.7212 - val_loss: 0.5342\n",
      "Epoch 104/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.5311 - val_accuracy: 0.7193 - val_loss: 0.5343\n",
      "Epoch 105/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5297 - val_accuracy: 0.7182 - val_loss: 0.5345\n",
      "Epoch 106/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.5277 - val_accuracy: 0.7193 - val_loss: 0.5342\n",
      "Epoch 107/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.5318 - val_accuracy: 0.7179 - val_loss: 0.5343\n",
      "Epoch 108/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.5310 - val_accuracy: 0.7190 - val_loss: 0.5351\n",
      "Epoch 109/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5287 - val_accuracy: 0.7187 - val_loss: 0.5340\n",
      "Epoch 110/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5273 - val_accuracy: 0.7172 - val_loss: 0.5345\n",
      "Epoch 111/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5272 - val_accuracy: 0.7191 - val_loss: 0.5338\n",
      "Epoch 112/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.5292 - val_accuracy: 0.7159 - val_loss: 0.5363\n",
      "Epoch 113/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5300 - val_accuracy: 0.7187 - val_loss: 0.5348\n",
      "Epoch 114/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5301 - val_accuracy: 0.7181 - val_loss: 0.5339\n",
      "Epoch 115/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5287 - val_accuracy: 0.7182 - val_loss: 0.5336\n",
      "Epoch 116/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.5294 - val_accuracy: 0.7178 - val_loss: 0.5352\n",
      "Epoch 117/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.5298 - val_accuracy: 0.7183 - val_loss: 0.5352\n",
      "Epoch 118/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.5307 - val_accuracy: 0.7201 - val_loss: 0.5345\n",
      "Epoch 119/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.5291 - val_accuracy: 0.7214 - val_loss: 0.5338\n",
      "Epoch 120/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5270 - val_accuracy: 0.7214 - val_loss: 0.5333\n",
      "Epoch 121/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5282 - val_accuracy: 0.7193 - val_loss: 0.5356\n",
      "Epoch 122/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.5281 - val_accuracy: 0.7195 - val_loss: 0.5343\n",
      "Epoch 123/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5274 - val_accuracy: 0.7193 - val_loss: 0.5357\n",
      "Epoch 124/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.5274 - val_accuracy: 0.7203 - val_loss: 0.5339\n",
      "Epoch 125/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5286 - val_accuracy: 0.7193 - val_loss: 0.5344\n",
      "Epoch 126/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5273 - val_accuracy: 0.7184 - val_loss: 0.5346\n",
      "Epoch 127/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.5300 - val_accuracy: 0.7192 - val_loss: 0.5344\n",
      "Epoch 128/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5280 - val_accuracy: 0.7191 - val_loss: 0.5352\n",
      "Epoch 129/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5300 - val_accuracy: 0.7189 - val_loss: 0.5359\n",
      "Epoch 130/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.5280 - val_accuracy: 0.7184 - val_loss: 0.5342\n",
      "Epoch 131/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5262 - val_accuracy: 0.7202 - val_loss: 0.5339\n",
      "Epoch 132/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.5280 - val_accuracy: 0.7174 - val_loss: 0.5357\n",
      "Epoch 133/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.5275 - val_accuracy: 0.7193 - val_loss: 0.5334\n",
      "Epoch 134/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5297 - val_accuracy: 0.7202 - val_loss: 0.5337\n",
      "Epoch 135/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.5301 - val_accuracy: 0.7197 - val_loss: 0.5344\n",
      "Epoch 136/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5287 - val_accuracy: 0.7209 - val_loss: 0.5345\n",
      "Epoch 137/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5268 - val_accuracy: 0.7219 - val_loss: 0.5345\n",
      "Epoch 138/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5279 - val_accuracy: 0.7217 - val_loss: 0.5344\n",
      "Epoch 139/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5274 - val_accuracy: 0.7203 - val_loss: 0.5349\n",
      "Epoch 140/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5269 - val_accuracy: 0.7196 - val_loss: 0.5339\n",
      "Epoch 141/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5256 - val_accuracy: 0.7197 - val_loss: 0.5338\n",
      "Epoch 142/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5262 - val_accuracy: 0.7189 - val_loss: 0.5347\n",
      "Epoch 143/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5262 - val_accuracy: 0.7198 - val_loss: 0.5350\n",
      "Epoch 144/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.5275 - val_accuracy: 0.7214 - val_loss: 0.5325\n",
      "Epoch 145/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5269 - val_accuracy: 0.7188 - val_loss: 0.5354\n",
      "Epoch 146/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5271 - val_accuracy: 0.7180 - val_loss: 0.5346\n",
      "Epoch 147/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5266 - val_accuracy: 0.7212 - val_loss: 0.5355\n",
      "Epoch 148/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5246 - val_accuracy: 0.7186 - val_loss: 0.5340\n",
      "Epoch 149/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.5286 - val_accuracy: 0.7192 - val_loss: 0.5338\n",
      "Epoch 150/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5262 - val_accuracy: 0.7207 - val_loss: 0.5331\n",
      "Epoch 151/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5266 - val_accuracy: 0.7199 - val_loss: 0.5336\n",
      "Epoch 152/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.5273 - val_accuracy: 0.7191 - val_loss: 0.5347\n",
      "Epoch 153/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5268 - val_accuracy: 0.7212 - val_loss: 0.5331\n",
      "Epoch 154/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5271 - val_accuracy: 0.7191 - val_loss: 0.5339\n",
      "Epoch 155/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5256 - val_accuracy: 0.7205 - val_loss: 0.5337\n",
      "Epoch 156/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5297 - val_accuracy: 0.7194 - val_loss: 0.5337\n",
      "Epoch 157/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5245 - val_accuracy: 0.7183 - val_loss: 0.5353\n",
      "Epoch 158/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7177 - loss: 0.5293 - val_accuracy: 0.7189 - val_loss: 0.5346\n",
      "Epoch 159/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7206 - loss: 0.5266 - val_accuracy: 0.7198 - val_loss: 0.5345\n",
      "Epoch 160/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5243 - val_accuracy: 0.7198 - val_loss: 0.5335\n",
      "Epoch 161/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5244 - val_accuracy: 0.7181 - val_loss: 0.5356\n",
      "Epoch 162/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5267 - val_accuracy: 0.7208 - val_loss: 0.5339\n",
      "Epoch 163/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5272 - val_accuracy: 0.7185 - val_loss: 0.5349\n",
      "Epoch 164/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.5270 - val_accuracy: 0.7196 - val_loss: 0.5337\n",
      "Epoch 165/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.5261 - val_accuracy: 0.7196 - val_loss: 0.5357\n",
      "Epoch 166/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5294 - val_accuracy: 0.7193 - val_loss: 0.5336\n",
      "Epoch 167/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5249 - val_accuracy: 0.7182 - val_loss: 0.5338\n",
      "Epoch 168/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5260 - val_accuracy: 0.7215 - val_loss: 0.5330\n",
      "Epoch 169/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5269 - val_accuracy: 0.7207 - val_loss: 0.5339\n",
      "Epoch 170/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5287 - val_accuracy: 0.7205 - val_loss: 0.5341\n",
      "Epoch 171/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5245 - val_accuracy: 0.7196 - val_loss: 0.5344\n",
      "Epoch 172/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5289 - val_accuracy: 0.7183 - val_loss: 0.5344\n",
      "Epoch 173/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5256 - val_accuracy: 0.7157 - val_loss: 0.5357\n",
      "Epoch 174/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5265 - val_accuracy: 0.7188 - val_loss: 0.5346\n",
      "Epoch 175/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5272 - val_accuracy: 0.7180 - val_loss: 0.5360\n",
      "Epoch 176/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5261 - val_accuracy: 0.7189 - val_loss: 0.5357\n",
      "Epoch 177/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5234 - val_accuracy: 0.7204 - val_loss: 0.5341\n",
      "Epoch 178/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5253 - val_accuracy: 0.7202 - val_loss: 0.5334\n",
      "Epoch 179/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.5258 - val_accuracy: 0.7186 - val_loss: 0.5349\n",
      "Epoch 180/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5261 - val_accuracy: 0.7201 - val_loss: 0.5340\n",
      "Epoch 181/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5236 - val_accuracy: 0.7183 - val_loss: 0.5334\n",
      "Epoch 182/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.5278 - val_accuracy: 0.7167 - val_loss: 0.5370\n",
      "Epoch 183/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5273 - val_accuracy: 0.7205 - val_loss: 0.5345\n",
      "Epoch 184/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5260 - val_accuracy: 0.7188 - val_loss: 0.5349\n",
      "Epoch 185/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5264 - val_accuracy: 0.7187 - val_loss: 0.5342\n",
      "Epoch 186/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5251 - val_accuracy: 0.7203 - val_loss: 0.5339\n",
      "Epoch 187/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5260 - val_accuracy: 0.7182 - val_loss: 0.5334\n",
      "Epoch 188/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5268 - val_accuracy: 0.7173 - val_loss: 0.5350\n",
      "Epoch 189/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5288 - val_accuracy: 0.7169 - val_loss: 0.5337\n",
      "Epoch 190/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5276 - val_accuracy: 0.7184 - val_loss: 0.5341\n",
      "Epoch 191/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.5267 - val_accuracy: 0.7182 - val_loss: 0.5350\n",
      "Epoch 192/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5247 - val_accuracy: 0.7199 - val_loss: 0.5343\n",
      "Epoch 193/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5246 - val_accuracy: 0.7189 - val_loss: 0.5350\n",
      "Epoch 194/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5258 - val_accuracy: 0.7198 - val_loss: 0.5335\n",
      "Epoch 195/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5271 - val_accuracy: 0.7180 - val_loss: 0.5357\n",
      "Epoch 196/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5247 - val_accuracy: 0.7191 - val_loss: 0.5336\n",
      "Epoch 197/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5262 - val_accuracy: 0.7182 - val_loss: 0.5348\n",
      "Epoch 198/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5259 - val_accuracy: 0.7190 - val_loss: 0.5345\n",
      "Epoch 199/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5236 - val_accuracy: 0.7184 - val_loss: 0.5348\n",
      "Epoch 200/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5238 - val_accuracy: 0.7183 - val_loss: 0.5352\n",
      "Epoch 201/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.5250 - val_accuracy: 0.7189 - val_loss: 0.5339\n",
      "Epoch 202/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5265 - val_accuracy: 0.7187 - val_loss: 0.5350\n",
      "Epoch 203/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5250 - val_accuracy: 0.7185 - val_loss: 0.5348\n",
      "Epoch 204/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5236 - val_accuracy: 0.7189 - val_loss: 0.5337\n",
      "Epoch 205/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5226 - val_accuracy: 0.7188 - val_loss: 0.5336\n",
      "Epoch 206/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5255 - val_accuracy: 0.7183 - val_loss: 0.5351\n",
      "Epoch 207/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5244 - val_accuracy: 0.7167 - val_loss: 0.5359\n",
      "Epoch 208/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5256 - val_accuracy: 0.7160 - val_loss: 0.5371\n",
      "Epoch 209/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7221 - loss: 0.5252 - val_accuracy: 0.7198 - val_loss: 0.5336\n",
      "Epoch 210/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5234 - val_accuracy: 0.7191 - val_loss: 0.5351\n",
      "Epoch 211/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5256 - val_accuracy: 0.7183 - val_loss: 0.5356\n",
      "Epoch 212/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5257 - val_accuracy: 0.7197 - val_loss: 0.5353\n",
      "Epoch 213/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5287 - val_accuracy: 0.7192 - val_loss: 0.5359\n",
      "Epoch 214/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5262 - val_accuracy: 0.7211 - val_loss: 0.5345\n",
      "Epoch 215/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5252 - val_accuracy: 0.7192 - val_loss: 0.5334\n",
      "Epoch 216/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.5249 - val_accuracy: 0.7176 - val_loss: 0.5345\n",
      "Epoch 217/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5260 - val_accuracy: 0.7185 - val_loss: 0.5344\n",
      "Epoch 218/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5239 - val_accuracy: 0.7188 - val_loss: 0.5342\n",
      "Epoch 219/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5211 - val_accuracy: 0.7182 - val_loss: 0.5347\n",
      "Epoch 220/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5247 - val_accuracy: 0.7185 - val_loss: 0.5343\n",
      "Epoch 221/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5255 - val_accuracy: 0.7178 - val_loss: 0.5339\n",
      "Epoch 222/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5251 - val_accuracy: 0.7163 - val_loss: 0.5356\n",
      "Epoch 223/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5269 - val_accuracy: 0.7186 - val_loss: 0.5332\n",
      "Epoch 224/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5258 - val_accuracy: 0.7171 - val_loss: 0.5347\n",
      "Epoch 225/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5257 - val_accuracy: 0.7191 - val_loss: 0.5332\n",
      "Epoch 226/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5211 - val_accuracy: 0.7192 - val_loss: 0.5341\n",
      "Epoch 227/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5237 - val_accuracy: 0.7191 - val_loss: 0.5340\n",
      "Epoch 228/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5245 - val_accuracy: 0.7196 - val_loss: 0.5349\n",
      "Epoch 229/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5255 - val_accuracy: 0.7211 - val_loss: 0.5346\n",
      "Epoch 230/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5266 - val_accuracy: 0.7203 - val_loss: 0.5350\n",
      "Epoch 231/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5247 - val_accuracy: 0.7176 - val_loss: 0.5357\n",
      "Epoch 232/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.5258 - val_accuracy: 0.7207 - val_loss: 0.5341\n",
      "Epoch 233/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5247 - val_accuracy: 0.7210 - val_loss: 0.5340\n",
      "Epoch 234/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.5259 - val_accuracy: 0.7197 - val_loss: 0.5337\n",
      "Epoch 235/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5255 - val_accuracy: 0.7181 - val_loss: 0.5342\n",
      "Epoch 236/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5243 - val_accuracy: 0.7194 - val_loss: 0.5333\n",
      "Epoch 237/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5231 - val_accuracy: 0.7177 - val_loss: 0.5349\n",
      "Epoch 238/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5239 - val_accuracy: 0.7178 - val_loss: 0.5348\n",
      "Epoch 239/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5250 - val_accuracy: 0.7182 - val_loss: 0.5352\n",
      "Epoch 240/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5236 - val_accuracy: 0.7200 - val_loss: 0.5342\n",
      "Epoch 241/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5264 - val_accuracy: 0.7186 - val_loss: 0.5350\n",
      "Epoch 242/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5266 - val_accuracy: 0.7193 - val_loss: 0.5342\n",
      "Epoch 243/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.5274 - val_accuracy: 0.7179 - val_loss: 0.5340\n",
      "Epoch 244/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5264 - val_accuracy: 0.7180 - val_loss: 0.5356\n",
      "Epoch 245/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5249 - val_accuracy: 0.7192 - val_loss: 0.5353\n",
      "Epoch 246/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.5239 - val_accuracy: 0.7188 - val_loss: 0.5338\n",
      "Epoch 247/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5246 - val_accuracy: 0.7179 - val_loss: 0.5346\n",
      "Epoch 248/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5251 - val_accuracy: 0.7210 - val_loss: 0.5346\n",
      "Epoch 249/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5238 - val_accuracy: 0.7191 - val_loss: 0.5348\n",
      "Epoch 250/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5220 - val_accuracy: 0.7176 - val_loss: 0.5355\n",
      "Epoch 251/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5217 - val_accuracy: 0.7185 - val_loss: 0.5350\n",
      "Epoch 252/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5223 - val_accuracy: 0.7193 - val_loss: 0.5349\n",
      "Epoch 253/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5230 - val_accuracy: 0.7190 - val_loss: 0.5352\n",
      "Epoch 254/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5234 - val_accuracy: 0.7180 - val_loss: 0.5357\n",
      "Epoch 255/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5261 - val_accuracy: 0.7208 - val_loss: 0.5352\n",
      "Epoch 256/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5264 - val_accuracy: 0.7204 - val_loss: 0.5338\n",
      "Epoch 257/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5243 - val_accuracy: 0.7198 - val_loss: 0.5341\n",
      "Epoch 258/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5223 - val_accuracy: 0.7197 - val_loss: 0.5351\n",
      "Epoch 259/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5214 - val_accuracy: 0.7185 - val_loss: 0.5358\n",
      "Epoch 260/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5224 - val_accuracy: 0.7204 - val_loss: 0.5343\n",
      "Epoch 261/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5230 - val_accuracy: 0.7177 - val_loss: 0.5357\n",
      "Epoch 262/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5236 - val_accuracy: 0.7156 - val_loss: 0.5358\n",
      "Epoch 263/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5251 - val_accuracy: 0.7200 - val_loss: 0.5336\n",
      "Epoch 264/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5260 - val_accuracy: 0.7200 - val_loss: 0.5338\n",
      "Epoch 265/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5206 - val_accuracy: 0.7175 - val_loss: 0.5356\n",
      "Epoch 266/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5252 - val_accuracy: 0.7179 - val_loss: 0.5344\n",
      "Epoch 267/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5238 - val_accuracy: 0.7183 - val_loss: 0.5341\n",
      "Epoch 268/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5226 - val_accuracy: 0.7202 - val_loss: 0.5349\n",
      "Epoch 269/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5222 - val_accuracy: 0.7206 - val_loss: 0.5343\n",
      "Epoch 270/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5238 - val_accuracy: 0.7193 - val_loss: 0.5364\n",
      "Epoch 271/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5247 - val_accuracy: 0.7204 - val_loss: 0.5355\n",
      "Epoch 272/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5242 - val_accuracy: 0.7178 - val_loss: 0.5372\n",
      "Epoch 273/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.5240 - val_accuracy: 0.7198 - val_loss: 0.5349\n",
      "Epoch 274/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.5250 - val_accuracy: 0.7193 - val_loss: 0.5347\n",
      "Epoch 275/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5257 - val_accuracy: 0.7192 - val_loss: 0.5363\n",
      "Epoch 276/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5230 - val_accuracy: 0.7174 - val_loss: 0.5358\n",
      "Epoch 277/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5224 - val_accuracy: 0.7183 - val_loss: 0.5355\n",
      "Epoch 278/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5237 - val_accuracy: 0.7181 - val_loss: 0.5359\n",
      "Epoch 279/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5247 - val_accuracy: 0.7205 - val_loss: 0.5345\n",
      "Epoch 280/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5221 - val_accuracy: 0.7193 - val_loss: 0.5356\n",
      "Epoch 281/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5230 - val_accuracy: 0.7197 - val_loss: 0.5360\n",
      "Epoch 282/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5203 - val_accuracy: 0.7190 - val_loss: 0.5356\n",
      "Epoch 283/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5222 - val_accuracy: 0.7195 - val_loss: 0.5357\n",
      "Epoch 284/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.5213 - val_accuracy: 0.7194 - val_loss: 0.5360\n",
      "Epoch 285/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5242 - val_accuracy: 0.7198 - val_loss: 0.5362\n",
      "Epoch 286/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5220 - val_accuracy: 0.7205 - val_loss: 0.5347\n",
      "Epoch 287/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5220 - val_accuracy: 0.7212 - val_loss: 0.5341\n",
      "Epoch 288/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5235 - val_accuracy: 0.7192 - val_loss: 0.5356\n",
      "Epoch 289/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5247 - val_accuracy: 0.7192 - val_loss: 0.5352\n",
      "Epoch 290/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.5230 - val_accuracy: 0.7195 - val_loss: 0.5346\n",
      "Epoch 291/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5179 - val_accuracy: 0.7202 - val_loss: 0.5340\n",
      "Epoch 292/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5234 - val_accuracy: 0.7203 - val_loss: 0.5347\n",
      "Epoch 293/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5254 - val_accuracy: 0.7205 - val_loss: 0.5345\n",
      "Epoch 294/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5239 - val_accuracy: 0.7200 - val_loss: 0.5360\n",
      "Epoch 295/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5243 - val_accuracy: 0.7191 - val_loss: 0.5352\n",
      "Epoch 296/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5255 - val_accuracy: 0.7192 - val_loss: 0.5366\n",
      "Epoch 297/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5240 - val_accuracy: 0.7196 - val_loss: 0.5351\n",
      "Epoch 298/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5230 - val_accuracy: 0.7196 - val_loss: 0.5346\n",
      "Epoch 299/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5254 - val_accuracy: 0.7187 - val_loss: 0.5347\n",
      "Epoch 300/300\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5202 - val_accuracy: 0.7207 - val_loss: 0.5343\n",
      "Test Loss: 0.5356\n",
      "Test Accuracy: 0.7194\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_scaled, y_train, epochs=300, batch_size=100, validation_split=0.2, verbose=1)\n",
    "val_accuracies = history.history['val_accuracy']\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first epoch from which the validation accuracy does not improve for 10 epochs is: 25\n",
      "300\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the first epoch where accuracy does not improve for 5 epochs\n",
    "patience = 10  # Number of epochs to check for no improvement\n",
    "best_epoch = 0\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "for epoch in range(1, len(val_accuracies)):\n",
    "    if val_accuracies[epoch] > val_accuracies[best_epoch]:\n",
    "        best_epoch = epoch\n",
    "        no_improvement_epochs = 0  # Reset counter if accuracy improves\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        first_epoch_no_improve = epoch - patience + 1\n",
    "        break\n",
    "else:\n",
    "    # If no such epoch is found, set to None\n",
    "    first_epoch_no_improve = None\n",
    "\n",
    "if first_epoch_no_improve is not None:\n",
    "    print(f\"The first epoch from which the validation accuracy does not improve for {patience} epochs is: {first_epoch_no_improve}\")\n",
    "else:\n",
    "    print(f\"Validation accuracy improved consistently throughout the training.\")\n",
    "print(len(val_accuracies))\n",
    "# Existing code for plotting accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set accuracy does not improve after epoch 25, but we see on the graph that the curve of validation set accuracy meet the curve of train set accuracy at epoch 50, so we will take this number as the reference for next models. \n",
    "We tried different models with different number of layers and concluded that the best model contain 3 layers. \n",
    "The pyramidal construction is important in a deep learning model in order to progressively reduce the number parameters to extract the most abstract and important features, this also avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6430 - loss: 0.6249 - val_accuracy: 0.7015 - val_loss: 0.5582\n",
      "Epoch 2/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.5675 - val_accuracy: 0.7048 - val_loss: 0.5548\n",
      "Epoch 3/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.5612 - val_accuracy: 0.7062 - val_loss: 0.5492\n",
      "Epoch 4/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.5584 - val_accuracy: 0.7044 - val_loss: 0.5497\n",
      "Epoch 5/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7035 - loss: 0.5536 - val_accuracy: 0.7077 - val_loss: 0.5487\n",
      "Epoch 6/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.5496 - val_accuracy: 0.7085 - val_loss: 0.5445\n",
      "Epoch 7/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 0.5496 - val_accuracy: 0.7082 - val_loss: 0.5424\n",
      "Epoch 8/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.5464 - val_accuracy: 0.7119 - val_loss: 0.5422\n",
      "Epoch 9/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.5449 - val_accuracy: 0.7108 - val_loss: 0.5414\n",
      "Epoch 10/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.5455 - val_accuracy: 0.7117 - val_loss: 0.5415\n",
      "Epoch 11/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5446 - val_accuracy: 0.7122 - val_loss: 0.5393\n",
      "Epoch 12/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.5445 - val_accuracy: 0.7128 - val_loss: 0.5395\n",
      "Epoch 13/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.5437 - val_accuracy: 0.7150 - val_loss: 0.5391\n",
      "Epoch 14/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.5408 - val_accuracy: 0.7124 - val_loss: 0.5387\n",
      "Epoch 15/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.5400 - val_accuracy: 0.7141 - val_loss: 0.5399\n",
      "Epoch 16/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.5418 - val_accuracy: 0.7139 - val_loss: 0.5392\n",
      "Epoch 17/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.5406 - val_accuracy: 0.7157 - val_loss: 0.5383\n",
      "Epoch 18/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5403 - val_accuracy: 0.7155 - val_loss: 0.5369\n",
      "Epoch 19/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5390 - val_accuracy: 0.7171 - val_loss: 0.5360\n",
      "Epoch 20/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.5401 - val_accuracy: 0.7165 - val_loss: 0.5378\n",
      "Epoch 21/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.5400 - val_accuracy: 0.7158 - val_loss: 0.5387\n",
      "Epoch 22/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5396 - val_accuracy: 0.7153 - val_loss: 0.5364\n",
      "Epoch 23/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.5404 - val_accuracy: 0.7165 - val_loss: 0.5375\n",
      "Epoch 24/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7147 - loss: 0.5373 - val_accuracy: 0.7168 - val_loss: 0.5365\n",
      "Epoch 25/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5380 - val_accuracy: 0.7162 - val_loss: 0.5360\n",
      "Epoch 26/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.5411 - val_accuracy: 0.7139 - val_loss: 0.5375\n",
      "Epoch 27/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.5396 - val_accuracy: 0.7151 - val_loss: 0.5364\n",
      "Epoch 28/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.5371 - val_accuracy: 0.7160 - val_loss: 0.5374\n",
      "Epoch 29/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5381 - val_accuracy: 0.7161 - val_loss: 0.5360\n",
      "Epoch 30/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.5367 - val_accuracy: 0.7174 - val_loss: 0.5353\n",
      "Epoch 31/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5402 - val_accuracy: 0.7164 - val_loss: 0.5368\n",
      "Epoch 32/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.5372 - val_accuracy: 0.7145 - val_loss: 0.5361\n",
      "Epoch 33/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.5353 - val_accuracy: 0.7181 - val_loss: 0.5363\n",
      "Epoch 34/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5375 - val_accuracy: 0.7170 - val_loss: 0.5364\n",
      "Epoch 35/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5366 - val_accuracy: 0.7176 - val_loss: 0.5354\n",
      "Epoch 36/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5345 - val_accuracy: 0.7160 - val_loss: 0.5363\n",
      "Epoch 37/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5360 - val_accuracy: 0.7163 - val_loss: 0.5361\n",
      "Epoch 38/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.5376 - val_accuracy: 0.7174 - val_loss: 0.5363\n",
      "Epoch 39/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.5370 - val_accuracy: 0.7164 - val_loss: 0.5364\n",
      "Epoch 40/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5335 - val_accuracy: 0.7183 - val_loss: 0.5352\n",
      "Epoch 41/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5370 - val_accuracy: 0.7188 - val_loss: 0.5342\n",
      "Epoch 42/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.5361 - val_accuracy: 0.7193 - val_loss: 0.5357\n",
      "Epoch 43/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5325 - val_accuracy: 0.7169 - val_loss: 0.5345\n",
      "Epoch 44/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5347 - val_accuracy: 0.7191 - val_loss: 0.5344\n",
      "Epoch 45/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.5368 - val_accuracy: 0.7183 - val_loss: 0.5346\n",
      "Epoch 46/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.5329 - val_accuracy: 0.7168 - val_loss: 0.5355\n",
      "Epoch 47/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.5350 - val_accuracy: 0.7180 - val_loss: 0.5363\n",
      "Epoch 48/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.5346 - val_accuracy: 0.7199 - val_loss: 0.5345\n",
      "Epoch 49/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.5336 - val_accuracy: 0.7194 - val_loss: 0.5344\n",
      "Epoch 50/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5365 - val_accuracy: 0.7190 - val_loss: 0.5338\n",
      "Test Loss: 0.5350\n",
      "Test Accuracy: 0.7190\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor (e.g., validation loss)\n",
    "    patience=10,              # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights of the best epoch\n",
    ")\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=100, validation_split=0.2, verbose=1,callbacks=[early_stopping])\n",
    "val_accuracies = history.history['val_accuracy']\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding PCA\n",
    "\n",
    "We use the first 13 components of the data set, it keeps 96% of the variance estimation and shows better result on test set, it follows the conlusion we made in the first part of the notebook that suggest that extreme values reduce the global precision of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio for each component: [0.39409315 0.09961686 0.06898437 0.04410975 0.04373939 0.04347362\n",
      " 0.04117595 0.04089    0.04053797 0.04020227 0.0372587  0.03636626\n",
      " 0.03607781 0.03347252]\n",
      "Cumulative explained variance: [0.39409315 0.49371001 0.56269438 0.60680413 0.65054352 0.69401714\n",
      " 0.73519309 0.77608309 0.81662107 0.85682333 0.89408204 0.9304483\n",
      " 0.9665261  0.99999862]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_PATH, header=None) \n",
    "data.columns = COLUMN_NAMES\n",
    "\n",
    "X = data.drop(columns=[\"label\"])\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "n_components = 14\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)  \n",
    "X_test_pca = pca.transform(X_test_scaled)       \n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio for each component: {explained_variance_ratio}\")\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "print(f\"Cumulative explained variance: {cumulative_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.6327 - val_accuracy: 0.7028 - val_loss: 0.5615\n",
      "Epoch 2/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.5732 - val_accuracy: 0.7052 - val_loss: 0.5550\n",
      "Epoch 3/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.5608 - val_accuracy: 0.7058 - val_loss: 0.5513\n",
      "Epoch 4/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.5560 - val_accuracy: 0.7081 - val_loss: 0.5481\n",
      "Epoch 5/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.5563 - val_accuracy: 0.7078 - val_loss: 0.5476\n",
      "Epoch 6/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.5526 - val_accuracy: 0.7082 - val_loss: 0.5466\n",
      "Epoch 7/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7072 - loss: 0.5505 - val_accuracy: 0.7092 - val_loss: 0.5440\n",
      "Epoch 8/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.5479 - val_accuracy: 0.7088 - val_loss: 0.5427\n",
      "Epoch 9/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.5491 - val_accuracy: 0.7112 - val_loss: 0.5415\n",
      "Epoch 10/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.5457 - val_accuracy: 0.7095 - val_loss: 0.5428\n",
      "Epoch 11/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.5456 - val_accuracy: 0.7127 - val_loss: 0.5413\n",
      "Epoch 12/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.5451 - val_accuracy: 0.7101 - val_loss: 0.5431\n",
      "Epoch 13/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.5446 - val_accuracy: 0.7109 - val_loss: 0.5411\n",
      "Epoch 14/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.5440 - val_accuracy: 0.7129 - val_loss: 0.5407\n",
      "Epoch 15/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.5445 - val_accuracy: 0.7113 - val_loss: 0.5410\n",
      "Epoch 16/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.5434 - val_accuracy: 0.7147 - val_loss: 0.5390\n",
      "Epoch 17/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.5443 - val_accuracy: 0.7120 - val_loss: 0.5402\n",
      "Epoch 18/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5424 - val_accuracy: 0.7138 - val_loss: 0.5390\n",
      "Epoch 19/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.5428 - val_accuracy: 0.7137 - val_loss: 0.5386\n",
      "Epoch 20/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5396 - val_accuracy: 0.7126 - val_loss: 0.5391\n",
      "Epoch 21/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.5416 - val_accuracy: 0.7145 - val_loss: 0.5395\n",
      "Epoch 22/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.5388 - val_accuracy: 0.7144 - val_loss: 0.5388\n",
      "Epoch 23/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.5399 - val_accuracy: 0.7145 - val_loss: 0.5387\n",
      "Epoch 24/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.5379 - val_accuracy: 0.7153 - val_loss: 0.5375\n",
      "Epoch 25/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.5399 - val_accuracy: 0.7156 - val_loss: 0.5384\n",
      "Epoch 26/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.5391 - val_accuracy: 0.7157 - val_loss: 0.5368\n",
      "Epoch 27/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.5367 - val_accuracy: 0.7159 - val_loss: 0.5370\n",
      "Epoch 28/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.5371 - val_accuracy: 0.7151 - val_loss: 0.5365\n",
      "Epoch 29/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5355 - val_accuracy: 0.7141 - val_loss: 0.5385\n",
      "Epoch 30/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.5362 - val_accuracy: 0.7149 - val_loss: 0.5373\n",
      "Epoch 31/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.5376 - val_accuracy: 0.7166 - val_loss: 0.5366\n",
      "Epoch 32/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5357 - val_accuracy: 0.7141 - val_loss: 0.5384\n",
      "Epoch 33/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.5374 - val_accuracy: 0.7154 - val_loss: 0.5371\n",
      "Epoch 34/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.5368 - val_accuracy: 0.7172 - val_loss: 0.5366\n",
      "Epoch 35/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5373 - val_accuracy: 0.7146 - val_loss: 0.5376\n",
      "Epoch 36/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.5371 - val_accuracy: 0.7175 - val_loss: 0.5368\n",
      "Epoch 37/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.5358 - val_accuracy: 0.7162 - val_loss: 0.5377\n",
      "Epoch 38/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.5346 - val_accuracy: 0.7176 - val_loss: 0.5356\n",
      "Epoch 39/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.5361 - val_accuracy: 0.7154 - val_loss: 0.5385\n",
      "Epoch 40/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5358 - val_accuracy: 0.7169 - val_loss: 0.5354\n",
      "Epoch 41/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5359 - val_accuracy: 0.7160 - val_loss: 0.5362\n",
      "Epoch 42/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.5356 - val_accuracy: 0.7167 - val_loss: 0.5347\n",
      "Epoch 43/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5336 - val_accuracy: 0.7174 - val_loss: 0.5356\n",
      "Epoch 44/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.5346 - val_accuracy: 0.7157 - val_loss: 0.5364\n",
      "Epoch 45/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5341 - val_accuracy: 0.7167 - val_loss: 0.5370\n",
      "Epoch 46/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.5352 - val_accuracy: 0.7179 - val_loss: 0.5356\n",
      "Epoch 47/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5348 - val_accuracy: 0.7157 - val_loss: 0.5356\n",
      "Epoch 48/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5348 - val_accuracy: 0.7163 - val_loss: 0.5362\n",
      "Epoch 49/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.5346 - val_accuracy: 0.7178 - val_loss: 0.5351\n",
      "Epoch 50/50\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.5353 - val_accuracy: 0.7178 - val_loss: 0.5357\n",
      "Test Loss: 0.5360\n",
      "Test Accuracy: 0.7190\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_pca.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_pca.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor (e.g., validation loss)\n",
    "    patience=10,              # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights of the best epoch\n",
    ")\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_pca, y_train, epochs=50, batch_size=100, validation_split=0.2, verbose=1,callbacks=[early_stopping])\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pca, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the prediction on the selected data set where volume features are above 10^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in extreme test data: 931\n",
      "Remaining rows in test data after extracting extremes: 39069\n",
      "Sample of extreme test data after PCA: [[  2.56889433   5.21915254   0.49244078  -1.35509404  -2.88831554\n",
      "    2.56545973  -3.72694582   5.53830471   9.77978981  -2.10376237\n",
      "   -5.77322096  -0.51443365   1.34807162  -1.96701523]\n",
      " [ -0.02911856   4.95320425  -0.89219001  -4.96982414  -4.49442103\n",
      "    3.30785434   3.00137643  -0.29406107  -5.77366445   8.09974307\n",
      "   -6.80846177   1.07026513   1.44313394  -0.35988546]\n",
      " [  1.10605589   3.89530731   0.41522836  -1.43495473  -2.32200255\n",
      "    4.47367147  -3.84370688   3.16001289   8.33880337  -1.41031901\n",
      "   -5.46247912  -0.67346032   1.35190323  -1.54156259]\n",
      " [ -0.64443873  10.06802808  -0.78994967  -2.06650224  -1.03325489\n",
      "    1.52355322   1.99541632  -4.08342104  -6.64093322   0.59381421\n",
      "   -6.37752559  -6.27029876  -0.4266666   -4.84495502]\n",
      " [ -0.66714722   9.92284829  -0.76616731  -7.47797399  -9.62446484\n",
      "    5.27185441   4.14224725   0.93190972  -5.25464835 -13.28675993\n",
      "    6.02532056  -5.74946472 -14.82232082  12.5699688 ]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 10**4\n",
    "# Create a mask for rows in X_test where any volume feature exceeds the threshold\n",
    "extreme_test_mask = X[volume_features].gt(threshold).any(axis=1)\n",
    "\n",
    "# Extract extreme test dataset\n",
    "X_extreme_test = X[extreme_test_mask].copy()\n",
    "y_extreme_test = y[extreme_test_mask].copy()\n",
    "\n",
    "# Print information about the extreme test dataset\n",
    "print(f\"Rows in extreme test data: {len(X_extreme_test)}\")\n",
    "print(f\"Remaining rows in test data after extracting extremes: {len(X_test) - len(X_extreme_test)}\")\n",
    "\n",
    "# Optionally: scale and transform the extreme test dataset using PCA\n",
    "X_extreme_test_scaled = scaler.transform(X_extreme_test)\n",
    "X_extreme_test_pca = pca.transform(X_extreme_test_scaled)\n",
    "\n",
    "# Print a sample of the extreme test data after PCA\n",
    "print(f\"Sample of extreme test data after PCA: {X_extreme_test_pca[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5399\n",
      "Test Accuracy: 0.6917\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_extreme_test_pca, y_extreme_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep PCA and remove extreme values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed from training data: 733\n",
      "Remaining rows in training data: 159267\n",
      "Remaining rows in test data: 40000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.drop(columns=[\"label\"])\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Select volume features (columns containing \"volume\")\n",
    "volume_features = [col for col in data.columns if \"volume\" in col]\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 10**4\n",
    "\n",
    "# Delete rows in X_train where any volume feature exceeds the threshold\n",
    "train_mask = ~X_train[volume_features].gt(threshold).any(axis=1)\n",
    "X_train_filtered = X_train[train_mask].copy()\n",
    "y_train_filtered = y_train[train_mask].copy()\n",
    "\n",
    "# Print the number of rows removed\n",
    "rows_removed = len(X_train) - len(X_train_filtered)\n",
    "print(f\"Rows removed from training data: {rows_removed}\")\n",
    "print(f\"Remaining rows in training data: {len(X_train_filtered)}\")\n",
    "print(f\"Remaining rows in test data: {len(X_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the feature columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio for each component: [0.42374903 0.06904991 0.06851107 0.04454201 0.04406271 0.04267288\n",
      " 0.0410226  0.04096148 0.04010774 0.03889954 0.03781049 0.03693265\n",
      " 0.03616703 0.0355095 ]\n",
      "Cumulative explained variance: [0.42374903 0.49279894 0.56131002 0.60585203 0.64991474 0.69258762\n",
      " 0.73361022 0.7745717  0.81467944 0.85357897 0.89138946 0.92832211\n",
      " 0.96448914 0.99999863]\n"
     ]
    }
   ],
   "source": [
    "# Set the number of components to keep\n",
    "n_components = 14  # Adjust this to the number of principal components you want\n",
    "\n",
    "# Apply PCA to training data\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca_truncated = pca.fit_transform(X_train_scaled)  # Fit PCA on training data and transform it\n",
    "X_test_pca = pca.transform(X_test_scaled)        # Transform test data using the same PCA\n",
    "\n",
    "# Print explained variance ratio for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio for each component: {explained_variance_ratio}\")\n",
    "\n",
    "# Print cumulative explained variance to evaluate how much information is retained\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "print(f\"Cumulative explained variance: {cumulative_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6529 - loss: 0.6120 - val_accuracy: 0.7040 - val_loss: 0.5573\n",
      "Epoch 2/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.5656 - val_accuracy: 0.7072 - val_loss: 0.5534\n",
      "Epoch 3/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7027 - loss: 0.5584 - val_accuracy: 0.7054 - val_loss: 0.5531\n",
      "Epoch 4/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.5557 - val_accuracy: 0.7075 - val_loss: 0.5476\n",
      "Epoch 5/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.5528 - val_accuracy: 0.7084 - val_loss: 0.5457\n",
      "Epoch 6/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.5513 - val_accuracy: 0.7095 - val_loss: 0.5445\n",
      "Epoch 7/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.5506 - val_accuracy: 0.7065 - val_loss: 0.5443\n",
      "Epoch 8/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.5463 - val_accuracy: 0.7109 - val_loss: 0.5420\n",
      "Epoch 9/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.5455 - val_accuracy: 0.7093 - val_loss: 0.5437\n",
      "Epoch 10/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.5445 - val_accuracy: 0.7115 - val_loss: 0.5409\n",
      "Epoch 11/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7107 - loss: 0.5427 - val_accuracy: 0.7116 - val_loss: 0.5404\n",
      "Epoch 12/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.5427 - val_accuracy: 0.7118 - val_loss: 0.5397\n",
      "Epoch 13/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.5404 - val_accuracy: 0.7139 - val_loss: 0.5395\n",
      "Epoch 14/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.5438 - val_accuracy: 0.7134 - val_loss: 0.5414\n",
      "Epoch 15/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5404 - val_accuracy: 0.7156 - val_loss: 0.5397\n",
      "Epoch 16/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.5393 - val_accuracy: 0.7144 - val_loss: 0.5383\n",
      "Epoch 17/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.5393 - val_accuracy: 0.7154 - val_loss: 0.5382\n",
      "Epoch 18/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5391 - val_accuracy: 0.7148 - val_loss: 0.5378\n",
      "Epoch 19/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.5385 - val_accuracy: 0.7150 - val_loss: 0.5371\n",
      "Epoch 20/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.5385 - val_accuracy: 0.7156 - val_loss: 0.5392\n",
      "Epoch 21/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5385 - val_accuracy: 0.7179 - val_loss: 0.5369\n",
      "Epoch 22/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5360 - val_accuracy: 0.7164 - val_loss: 0.5364\n",
      "Epoch 23/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.5372 - val_accuracy: 0.7171 - val_loss: 0.5367\n",
      "Epoch 24/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.5377 - val_accuracy: 0.7187 - val_loss: 0.5356\n",
      "Epoch 25/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.5384 - val_accuracy: 0.7181 - val_loss: 0.5358\n",
      "Epoch 26/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.5361 - val_accuracy: 0.7159 - val_loss: 0.5359\n",
      "Epoch 27/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.5383 - val_accuracy: 0.7177 - val_loss: 0.5356\n",
      "Epoch 28/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.5358 - val_accuracy: 0.7162 - val_loss: 0.5361\n",
      "Epoch 29/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5365 - val_accuracy: 0.7175 - val_loss: 0.5358\n",
      "Epoch 30/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.5340 - val_accuracy: 0.7164 - val_loss: 0.5365\n",
      "Epoch 31/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5361 - val_accuracy: 0.7184 - val_loss: 0.5353\n",
      "Epoch 32/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.5348 - val_accuracy: 0.7166 - val_loss: 0.5361\n",
      "Epoch 33/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.5349 - val_accuracy: 0.7192 - val_loss: 0.5353\n",
      "Epoch 34/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.5371 - val_accuracy: 0.7182 - val_loss: 0.5351\n",
      "Epoch 35/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.5345 - val_accuracy: 0.7196 - val_loss: 0.5352\n",
      "Epoch 36/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.5318 - val_accuracy: 0.7177 - val_loss: 0.5362\n",
      "Epoch 37/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5319 - val_accuracy: 0.7183 - val_loss: 0.5350\n",
      "Epoch 38/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5344 - val_accuracy: 0.7192 - val_loss: 0.5351\n",
      "Epoch 39/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.5337 - val_accuracy: 0.7170 - val_loss: 0.5356\n",
      "Epoch 40/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.5351 - val_accuracy: 0.7176 - val_loss: 0.5350\n",
      "Epoch 41/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5345 - val_accuracy: 0.7169 - val_loss: 0.5345\n",
      "Epoch 42/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.5307 - val_accuracy: 0.7200 - val_loss: 0.5336\n",
      "Epoch 43/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.5336 - val_accuracy: 0.7176 - val_loss: 0.5342\n",
      "Epoch 44/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5306 - val_accuracy: 0.7185 - val_loss: 0.5341\n",
      "Epoch 45/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5330 - val_accuracy: 0.7180 - val_loss: 0.5336\n",
      "Epoch 46/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5313 - val_accuracy: 0.7180 - val_loss: 0.5341\n",
      "Epoch 47/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.5353 - val_accuracy: 0.7187 - val_loss: 0.5339\n",
      "Epoch 48/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.5331 - val_accuracy: 0.7182 - val_loss: 0.5341\n",
      "Epoch 49/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5329 - val_accuracy: 0.7202 - val_loss: 0.5330\n",
      "Epoch 50/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.5330 - val_accuracy: 0.7186 - val_loss: 0.5340\n",
      "Epoch 51/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.5320 - val_accuracy: 0.7195 - val_loss: 0.5354\n",
      "Epoch 52/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.5330 - val_accuracy: 0.7188 - val_loss: 0.5331\n",
      "Epoch 53/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5312 - val_accuracy: 0.7183 - val_loss: 0.5345\n",
      "Epoch 54/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.5333 - val_accuracy: 0.7171 - val_loss: 0.5349\n",
      "Epoch 55/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5325 - val_accuracy: 0.7180 - val_loss: 0.5338\n",
      "Epoch 56/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5320 - val_accuracy: 0.7203 - val_loss: 0.5332\n",
      "Epoch 57/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5324 - val_accuracy: 0.7189 - val_loss: 0.5337\n",
      "Epoch 58/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.5321 - val_accuracy: 0.7199 - val_loss: 0.5334\n",
      "Epoch 59/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.5318 - val_accuracy: 0.7190 - val_loss: 0.5346\n",
      "Epoch 60/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.5316 - val_accuracy: 0.7201 - val_loss: 0.5338\n",
      "Epoch 61/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.5319 - val_accuracy: 0.7198 - val_loss: 0.5330\n",
      "Epoch 62/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5295 - val_accuracy: 0.7189 - val_loss: 0.5337\n",
      "Epoch 63/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5327 - val_accuracy: 0.7199 - val_loss: 0.5334\n",
      "Epoch 64/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.5308 - val_accuracy: 0.7217 - val_loss: 0.5326\n",
      "Epoch 65/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.5320 - val_accuracy: 0.7187 - val_loss: 0.5335\n",
      "Epoch 66/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5319 - val_accuracy: 0.7182 - val_loss: 0.5330\n",
      "Epoch 67/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.5309 - val_accuracy: 0.7199 - val_loss: 0.5338\n",
      "Epoch 68/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5281 - val_accuracy: 0.7195 - val_loss: 0.5326\n",
      "Epoch 69/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.5309 - val_accuracy: 0.7215 - val_loss: 0.5334\n",
      "Epoch 70/70\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.5301 - val_accuracy: 0.7188 - val_loss: 0.5338\n",
      "Test Loss: 0.5353\n",
      "Test Accuracy: 0.7210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor (e.g., validation loss)\n",
    "    patience=15,              # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights of the best epoch\n",
    ")\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pca_truncated, y_train_filtered, epochs=70, batch_size=100, validation_split=0.2, verbose=1,callbacks=[early_stopping])\n",
    "val_accuracies = history.history['val_accuracy']\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pca, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an improved accuracy, lets build a model that uses bagging and try to capture more information in the dataset. We will keep the truncated data set as it makes improved results. \n",
    "\n",
    "the idea of bagging is to have overfit models on many part of the dataset and then make an average prediction using all models, this follows the law of large number. \n",
    "\n",
    "Intuitevely, we shall reduce the dropout in order to make the model overfit, increase the number of neurons and the number of epochs, but the more we overfit, the more we need to have models in order to remain in the assumptions of law of large numbers. \n",
    "\n",
    "We will then build two models, one using 30 models and the same parameters as before, the interpretation of this model is to have more point of view for the prediction and increase accuracy, and another one with lower dropout, no patience parameter, more neurons and more epochs. We can slightly increase then batchsize in order to increase execution speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the model on a data set that contain only the extreme values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in extreme test data: 931\n",
      "Remaining rows in test data after extracting extremes: 39069\n",
      "Sample of extreme test data after PCA: [[ -0.932318    -5.72503003  12.78664088   6.63220233  -2.36551331\n",
      "   -7.39204159  -0.31321648  -6.09697949  -4.6205176   -8.77021086\n",
      "   -7.36304726   7.26751641  -9.39105582  24.30415293]\n",
      " [ -2.35620011  -6.06738609   9.30114688   7.4215395   -3.72322073\n",
      "   -9.2320879    1.08161754  -2.38845506 -12.12701098   3.35657605\n",
      "   12.00937327 -11.96902349   9.94743478  -0.95563415]\n",
      " [ -1.70589774  -4.6480217   10.18039867   8.26528849  -2.56006661\n",
      "   -6.69905134  -2.06887054  -4.70866955  -5.27446591  -7.70917796\n",
      "   -5.41020416   6.04199444  -7.19111836  21.2441506 ]\n",
      " [ -5.83507064  -9.00720016  16.7038033    5.30007153  -2.20687738\n",
      "   -7.10592711  -3.07367703   2.84423127  13.15449373  -3.7954998\n",
      "   17.79991324 -11.07056475   7.08735675   1.8789566 ]\n",
      " [ -4.99884493  -6.78965663  14.08580148   3.86673177  -1.22453505\n",
      "  -12.25432656  -2.45238506  -5.22381115  15.50217001   1.7802058\n",
      "  -13.74013924  25.01916435  31.31578532 -13.28768844]]\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for rows in X_test where any volume feature exceeds the threshold\n",
    "extreme_test_mask = X[volume_features].gt(threshold).any(axis=1)\n",
    "\n",
    "# Extract extreme test dataset\n",
    "X_extreme_test = X[extreme_test_mask].copy()\n",
    "y_extreme_test = y[extreme_test_mask].copy()\n",
    "\n",
    "# Print information about the extreme test dataset\n",
    "print(f\"Rows in extreme test data: {len(X_extreme_test)}\")\n",
    "print(f\"Remaining rows in test data after extracting extremes: {len(X_test) - len(X_extreme_test)}\")\n",
    "\n",
    "# Optionally: scale and transform the extreme test dataset using PCA\n",
    "X_extreme_test_scaled = scaler.transform(X_extreme_test)\n",
    "X_extreme_test_pca = pca.transform(X_extreme_test_scaled)\n",
    "\n",
    "# Print a sample of the extreme test data after PCA\n",
    "print(f\"Sample of extreme test data after PCA: {X_extreme_test_pca[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6963\n",
      "Test Accuracy: 0.7003\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_extreme_test_pca, y_extreme_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is closed from the one we got withtout removing the extreme values in the model, this result shows that extreme values not useful to train the model. We decide to keep the truncated dataset for training bagging. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 0.6158 - val_accuracy: 0.7041 - val_loss: 0.5540\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7040 - loss: 0.5583 - val_accuracy: 0.7107 - val_loss: 0.5475\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5521 - val_accuracy: 0.7126 - val_loss: 0.5438\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.5486 - val_accuracy: 0.7128 - val_loss: 0.5409\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7101 - loss: 0.5476 - val_accuracy: 0.7165 - val_loss: 0.5422\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.5438 - val_accuracy: 0.7145 - val_loss: 0.5410\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7143 - loss: 0.5411 - val_accuracy: 0.7162 - val_loss: 0.5378\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7145 - loss: 0.5406 - val_accuracy: 0.7175 - val_loss: 0.5357\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: 0.5363 - val_accuracy: 0.7186 - val_loss: 0.5352\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.5378 - val_accuracy: 0.7180 - val_loss: 0.5343\n",
      "Epoch 11/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.5348 - val_accuracy: 0.7172 - val_loss: 0.5332\n",
      "Epoch 12/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5340 - val_accuracy: 0.7185 - val_loss: 0.5318\n",
      "Epoch 13/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.5342 - val_accuracy: 0.7190 - val_loss: 0.5326\n",
      "Epoch 14/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.5333 - val_accuracy: 0.7202 - val_loss: 0.5313\n",
      "Epoch 15/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.5312 - val_accuracy: 0.7192 - val_loss: 0.5302\n",
      "Epoch 16/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5291 - val_accuracy: 0.7218 - val_loss: 0.5297\n",
      "Epoch 17/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.5295 - val_accuracy: 0.7212 - val_loss: 0.5297\n",
      "Epoch 18/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.5300 - val_accuracy: 0.7197 - val_loss: 0.5286\n",
      "Epoch 19/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.5270 - val_accuracy: 0.7226 - val_loss: 0.5288\n",
      "Epoch 20/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.5272 - val_accuracy: 0.7208 - val_loss: 0.5289\n",
      "Epoch 21/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.5262 - val_accuracy: 0.7212 - val_loss: 0.5267\n",
      "Epoch 22/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5273 - val_accuracy: 0.7209 - val_loss: 0.5288\n",
      "Epoch 23/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.5239 - val_accuracy: 0.7205 - val_loss: 0.5281\n",
      "Epoch 24/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5249 - val_accuracy: 0.7230 - val_loss: 0.5254\n",
      "Epoch 25/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5225 - val_accuracy: 0.7241 - val_loss: 0.5268\n",
      "Epoch 26/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5220 - val_accuracy: 0.7254 - val_loss: 0.5251\n",
      "Epoch 27/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5217 - val_accuracy: 0.7240 - val_loss: 0.5251\n",
      "Epoch 28/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5194 - val_accuracy: 0.7233 - val_loss: 0.5246\n",
      "Epoch 29/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5215 - val_accuracy: 0.7243 - val_loss: 0.5234\n",
      "Epoch 30/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5205 - val_accuracy: 0.7244 - val_loss: 0.5240\n",
      "Epoch 31/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5217 - val_accuracy: 0.7265 - val_loss: 0.5224\n",
      "Epoch 32/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5197 - val_accuracy: 0.7237 - val_loss: 0.5242\n",
      "Epoch 33/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.5195 - val_accuracy: 0.7251 - val_loss: 0.5224\n",
      "Epoch 34/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5185 - val_accuracy: 0.7270 - val_loss: 0.5225\n",
      "Epoch 35/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5169 - val_accuracy: 0.7268 - val_loss: 0.5218\n",
      "Epoch 36/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5199 - val_accuracy: 0.7268 - val_loss: 0.5212\n",
      "Epoch 37/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5165 - val_accuracy: 0.7274 - val_loss: 0.5206\n",
      "Epoch 38/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5172 - val_accuracy: 0.7275 - val_loss: 0.5214\n",
      "Epoch 39/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5148 - val_accuracy: 0.7284 - val_loss: 0.5215\n",
      "Epoch 40/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5149 - val_accuracy: 0.7281 - val_loss: 0.5218\n",
      "Epoch 41/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5175 - val_accuracy: 0.7294 - val_loss: 0.5203\n",
      "Epoch 42/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5152 - val_accuracy: 0.7282 - val_loss: 0.5209\n",
      "Epoch 43/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5138 - val_accuracy: 0.7275 - val_loss: 0.5195\n",
      "Epoch 44/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5146 - val_accuracy: 0.7275 - val_loss: 0.5195\n",
      "Epoch 45/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.5148 - val_accuracy: 0.7291 - val_loss: 0.5199\n",
      "Epoch 46/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5137 - val_accuracy: 0.7276 - val_loss: 0.5198\n",
      "Epoch 47/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5132 - val_accuracy: 0.7296 - val_loss: 0.5187\n",
      "Epoch 48/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5130 - val_accuracy: 0.7321 - val_loss: 0.5184\n",
      "Epoch 49/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5159 - val_accuracy: 0.7288 - val_loss: 0.5179\n",
      "Epoch 50/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5096 - val_accuracy: 0.7287 - val_loss: 0.5184\n",
      "Epoch 51/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5105 - val_accuracy: 0.7322 - val_loss: 0.5173\n",
      "Epoch 52/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5115 - val_accuracy: 0.7320 - val_loss: 0.5168\n",
      "Epoch 53/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5106 - val_accuracy: 0.7318 - val_loss: 0.5174\n",
      "Epoch 54/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5106 - val_accuracy: 0.7315 - val_loss: 0.5185\n",
      "Epoch 55/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5113 - val_accuracy: 0.7293 - val_loss: 0.5182\n",
      "Epoch 56/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5083 - val_accuracy: 0.7321 - val_loss: 0.5176\n",
      "Epoch 57/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5088 - val_accuracy: 0.7315 - val_loss: 0.5157\n",
      "Epoch 58/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5091 - val_accuracy: 0.7308 - val_loss: 0.5160\n",
      "Epoch 59/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5066 - val_accuracy: 0.7326 - val_loss: 0.5165\n",
      "Epoch 60/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5103 - val_accuracy: 0.7327 - val_loss: 0.5167\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 2/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.5361 - val_accuracy: 0.7288 - val_loss: 0.5183\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.5274 - val_accuracy: 0.7308 - val_loss: 0.5168\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.5262 - val_accuracy: 0.7289 - val_loss: 0.5178\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.5220 - val_accuracy: 0.7303 - val_loss: 0.5185\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.5235 - val_accuracy: 0.7302 - val_loss: 0.5171\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7254 - loss: 0.5221 - val_accuracy: 0.7313 - val_loss: 0.5178\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5217 - val_accuracy: 0.7303 - val_loss: 0.5177\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.5214 - val_accuracy: 0.7298 - val_loss: 0.5156\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.5210 - val_accuracy: 0.7327 - val_loss: 0.5163\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.5191 - val_accuracy: 0.7320 - val_loss: 0.5169\n",
      "Epoch 11/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.5188 - val_accuracy: 0.7317 - val_loss: 0.5158\n",
      "Epoch 12/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5173 - val_accuracy: 0.7308 - val_loss: 0.5156\n",
      "Epoch 13/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5186 - val_accuracy: 0.7310 - val_loss: 0.5160\n",
      "Epoch 14/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5177 - val_accuracy: 0.7301 - val_loss: 0.5162\n",
      "Epoch 15/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5141 - val_accuracy: 0.7315 - val_loss: 0.5153\n",
      "Epoch 16/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5150 - val_accuracy: 0.7321 - val_loss: 0.5148\n",
      "Epoch 17/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.5157 - val_accuracy: 0.7311 - val_loss: 0.5142\n",
      "Epoch 18/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5145 - val_accuracy: 0.7319 - val_loss: 0.5141\n",
      "Epoch 19/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5150 - val_accuracy: 0.7342 - val_loss: 0.5126\n",
      "Epoch 20/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5152 - val_accuracy: 0.7309 - val_loss: 0.5138\n",
      "Epoch 21/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5166 - val_accuracy: 0.7322 - val_loss: 0.5157\n",
      "Epoch 22/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5133 - val_accuracy: 0.7323 - val_loss: 0.5143\n",
      "Epoch 23/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5140 - val_accuracy: 0.7334 - val_loss: 0.5143\n",
      "Epoch 24/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5108 - val_accuracy: 0.7331 - val_loss: 0.5141\n",
      "Epoch 25/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5096 - val_accuracy: 0.7330 - val_loss: 0.5133\n",
      "Epoch 26/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.5120 - val_accuracy: 0.7329 - val_loss: 0.5124\n",
      "Epoch 27/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5113 - val_accuracy: 0.7343 - val_loss: 0.5122\n",
      "Epoch 28/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5114 - val_accuracy: 0.7333 - val_loss: 0.5126\n",
      "Epoch 29/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5098 - val_accuracy: 0.7331 - val_loss: 0.5138\n",
      "Epoch 30/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5094 - val_accuracy: 0.7322 - val_loss: 0.5133\n",
      "Epoch 31/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5108 - val_accuracy: 0.7337 - val_loss: 0.5133\n",
      "Epoch 32/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5087 - val_accuracy: 0.7327 - val_loss: 0.5131\n",
      "Epoch 33/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5099 - val_accuracy: 0.7346 - val_loss: 0.5120\n",
      "Epoch 34/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5067 - val_accuracy: 0.7341 - val_loss: 0.5128\n",
      "Epoch 35/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5094 - val_accuracy: 0.7370 - val_loss: 0.5112\n",
      "Epoch 36/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5080 - val_accuracy: 0.7353 - val_loss: 0.5111\n",
      "Epoch 37/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5068 - val_accuracy: 0.7323 - val_loss: 0.5119\n",
      "Epoch 38/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5068 - val_accuracy: 0.7304 - val_loss: 0.5130\n",
      "Epoch 39/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5055 - val_accuracy: 0.7344 - val_loss: 0.5116\n",
      "Epoch 40/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5065 - val_accuracy: 0.7347 - val_loss: 0.5104\n",
      "Epoch 41/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5078 - val_accuracy: 0.7331 - val_loss: 0.5113\n",
      "Epoch 42/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5059 - val_accuracy: 0.7336 - val_loss: 0.5115\n",
      "Epoch 43/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5070 - val_accuracy: 0.7355 - val_loss: 0.5105\n",
      "Epoch 44/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5062 - val_accuracy: 0.7352 - val_loss: 0.5105\n",
      "Epoch 45/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5060 - val_accuracy: 0.7336 - val_loss: 0.5119\n",
      "Epoch 46/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.5073 - val_accuracy: 0.7346 - val_loss: 0.5107\n",
      "Epoch 47/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5059 - val_accuracy: 0.7350 - val_loss: 0.5115\n",
      "Epoch 48/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7425 - loss: 0.5016 - val_accuracy: 0.7351 - val_loss: 0.5113\n",
      "Epoch 49/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5044 - val_accuracy: 0.7336 - val_loss: 0.5120\n",
      "Epoch 50/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5070 - val_accuracy: 0.7341 - val_loss: 0.5117\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 3/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5340 - val_accuracy: 0.7308 - val_loss: 0.5141\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5235 - val_accuracy: 0.7324 - val_loss: 0.5141\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.5224 - val_accuracy: 0.7305 - val_loss: 0.5139\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5226 - val_accuracy: 0.7324 - val_loss: 0.5139\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7272 - loss: 0.5215 - val_accuracy: 0.7309 - val_loss: 0.5133\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5204 - val_accuracy: 0.7293 - val_loss: 0.5143\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.5180 - val_accuracy: 0.7313 - val_loss: 0.5120\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5195 - val_accuracy: 0.7308 - val_loss: 0.5126\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5135 - val_accuracy: 0.7312 - val_loss: 0.5136\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5167 - val_accuracy: 0.7287 - val_loss: 0.5137\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 4/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5270 - val_accuracy: 0.7336 - val_loss: 0.5151\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.5240 - val_accuracy: 0.7325 - val_loss: 0.5160\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.5209 - val_accuracy: 0.7353 - val_loss: 0.5147\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.5196 - val_accuracy: 0.7341 - val_loss: 0.5147\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5187 - val_accuracy: 0.7342 - val_loss: 0.5148\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5139 - val_accuracy: 0.7355 - val_loss: 0.5134\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5179 - val_accuracy: 0.7357 - val_loss: 0.5136\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5155 - val_accuracy: 0.7362 - val_loss: 0.5140\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5164 - val_accuracy: 0.7354 - val_loss: 0.5139\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5150 - val_accuracy: 0.7349 - val_loss: 0.5133\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 5/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5261 - val_accuracy: 0.7337 - val_loss: 0.5114\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5237 - val_accuracy: 0.7344 - val_loss: 0.5110\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5238 - val_accuracy: 0.7332 - val_loss: 0.5104\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5227 - val_accuracy: 0.7340 - val_loss: 0.5111\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5168 - val_accuracy: 0.7328 - val_loss: 0.5134\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5177 - val_accuracy: 0.7342 - val_loss: 0.5111\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5185 - val_accuracy: 0.7342 - val_loss: 0.5101\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5164 - val_accuracy: 0.7343 - val_loss: 0.5102\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.5159 - val_accuracy: 0.7332 - val_loss: 0.5112\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5138 - val_accuracy: 0.7336 - val_loss: 0.5086\n",
      "Epoch 11/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5145 - val_accuracy: 0.7356 - val_loss: 0.5096\n",
      "Epoch 12/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5139 - val_accuracy: 0.7339 - val_loss: 0.5088\n",
      "Epoch 13/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5122 - val_accuracy: 0.7349 - val_loss: 0.5095\n",
      "Epoch 14/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5110 - val_accuracy: 0.7340 - val_loss: 0.5085\n",
      "Epoch 15/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5116 - val_accuracy: 0.7359 - val_loss: 0.5091\n",
      "Epoch 16/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5094 - val_accuracy: 0.7371 - val_loss: 0.5095\n",
      "Epoch 17/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.5111 - val_accuracy: 0.7322 - val_loss: 0.5104\n",
      "Epoch 18/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5108 - val_accuracy: 0.7346 - val_loss: 0.5106\n",
      "Epoch 19/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.5095 - val_accuracy: 0.7362 - val_loss: 0.5089\n",
      "Epoch 20/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5071 - val_accuracy: 0.7355 - val_loss: 0.5092\n",
      "Epoch 21/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5067 - val_accuracy: 0.7335 - val_loss: 0.5097\n",
      "Epoch 22/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5072 - val_accuracy: 0.7338 - val_loss: 0.5099\n",
      "Epoch 23/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5110 - val_accuracy: 0.7349 - val_loss: 0.5084\n",
      "Epoch 24/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5082 - val_accuracy: 0.7361 - val_loss: 0.5093\n",
      "Epoch 25/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5072 - val_accuracy: 0.7355 - val_loss: 0.5086\n",
      "Epoch 26/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5086 - val_accuracy: 0.7350 - val_loss: 0.5085\n",
      "Epoch 27/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5066 - val_accuracy: 0.7340 - val_loss: 0.5084\n",
      "Epoch 28/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5045 - val_accuracy: 0.7319 - val_loss: 0.5088\n",
      "Epoch 29/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.5052 - val_accuracy: 0.7323 - val_loss: 0.5089\n",
      "Epoch 30/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.5065 - val_accuracy: 0.7351 - val_loss: 0.5091\n",
      "Epoch 31/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.5038 - val_accuracy: 0.7354 - val_loss: 0.5081\n",
      "Epoch 32/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5040 - val_accuracy: 0.7346 - val_loss: 0.5078\n",
      "Epoch 33/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5032 - val_accuracy: 0.7359 - val_loss: 0.5069\n",
      "Epoch 34/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5051 - val_accuracy: 0.7344 - val_loss: 0.5081\n",
      "Epoch 35/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5054 - val_accuracy: 0.7364 - val_loss: 0.5081\n",
      "Epoch 36/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5047 - val_accuracy: 0.7343 - val_loss: 0.5077\n",
      "Epoch 37/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5034 - val_accuracy: 0.7356 - val_loss: 0.5076\n",
      "Epoch 38/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.5047 - val_accuracy: 0.7331 - val_loss: 0.5088\n",
      "Epoch 39/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.5010 - val_accuracy: 0.7346 - val_loss: 0.5083\n",
      "Epoch 40/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5042 - val_accuracy: 0.7344 - val_loss: 0.5076\n",
      "Epoch 41/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5012 - val_accuracy: 0.7349 - val_loss: 0.5073\n",
      "Epoch 42/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5025 - val_accuracy: 0.7357 - val_loss: 0.5045\n",
      "Epoch 43/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.4989 - val_accuracy: 0.7346 - val_loss: 0.5069\n",
      "Epoch 44/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5026 - val_accuracy: 0.7329 - val_loss: 0.5071\n",
      "Epoch 45/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5019 - val_accuracy: 0.7352 - val_loss: 0.5064\n",
      "Epoch 46/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5004 - val_accuracy: 0.7354 - val_loss: 0.5065\n",
      "Epoch 47/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5026 - val_accuracy: 0.7347 - val_loss: 0.5064\n",
      "Epoch 48/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5034 - val_accuracy: 0.7347 - val_loss: 0.5060\n",
      "Epoch 49/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5035 - val_accuracy: 0.7347 - val_loss: 0.5057\n",
      "Epoch 50/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.4992 - val_accuracy: 0.7359 - val_loss: 0.5065\n",
      "Epoch 51/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7425 - loss: 0.4992 - val_accuracy: 0.7346 - val_loss: 0.5071\n",
      "Epoch 52/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5013 - val_accuracy: 0.7387 - val_loss: 0.5056\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step\n",
      "Training model 6/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5278 - val_accuracy: 0.7293 - val_loss: 0.5151\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.5206 - val_accuracy: 0.7328 - val_loss: 0.5138\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5167 - val_accuracy: 0.7315 - val_loss: 0.5146\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.5166 - val_accuracy: 0.7320 - val_loss: 0.5151\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5137 - val_accuracy: 0.7342 - val_loss: 0.5148\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5152 - val_accuracy: 0.7327 - val_loss: 0.5147\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5131 - val_accuracy: 0.7318 - val_loss: 0.5150\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5131 - val_accuracy: 0.7323 - val_loss: 0.5142\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.5126 - val_accuracy: 0.7327 - val_loss: 0.5144\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5113 - val_accuracy: 0.7327 - val_loss: 0.5134\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 7/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.5245 - val_accuracy: 0.7327 - val_loss: 0.5122\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.5220 - val_accuracy: 0.7348 - val_loss: 0.5112\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5202 - val_accuracy: 0.7311 - val_loss: 0.5132\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.5165 - val_accuracy: 0.7315 - val_loss: 0.5127\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5162 - val_accuracy: 0.7328 - val_loss: 0.5113\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5119 - val_accuracy: 0.7314 - val_loss: 0.5129\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5130 - val_accuracy: 0.7312 - val_loss: 0.5142\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5113 - val_accuracy: 0.7305 - val_loss: 0.5131\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5103 - val_accuracy: 0.7311 - val_loss: 0.5118\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5097 - val_accuracy: 0.7324 - val_loss: 0.5125\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 8/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5249 - val_accuracy: 0.7333 - val_loss: 0.5123\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5196 - val_accuracy: 0.7355 - val_loss: 0.5123\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5163 - val_accuracy: 0.7341 - val_loss: 0.5131\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5154 - val_accuracy: 0.7345 - val_loss: 0.5129\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5133 - val_accuracy: 0.7327 - val_loss: 0.5136\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.5134 - val_accuracy: 0.7339 - val_loss: 0.5120\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5133 - val_accuracy: 0.7331 - val_loss: 0.5121\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5089 - val_accuracy: 0.7368 - val_loss: 0.5113\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5103 - val_accuracy: 0.7358 - val_loss: 0.5106\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5119 - val_accuracy: 0.7359 - val_loss: 0.5104\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 9/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.5254 - val_accuracy: 0.7352 - val_loss: 0.5130\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5186 - val_accuracy: 0.7337 - val_loss: 0.5138\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5161 - val_accuracy: 0.7324 - val_loss: 0.5141\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5154 - val_accuracy: 0.7347 - val_loss: 0.5137\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5151 - val_accuracy: 0.7369 - val_loss: 0.5127\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5141 - val_accuracy: 0.7359 - val_loss: 0.5119\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.5147 - val_accuracy: 0.7337 - val_loss: 0.5132\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5157 - val_accuracy: 0.7349 - val_loss: 0.5129\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5132 - val_accuracy: 0.7337 - val_loss: 0.5123\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5103 - val_accuracy: 0.7352 - val_loss: 0.5121\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 10/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.5211 - val_accuracy: 0.7354 - val_loss: 0.5082\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5172 - val_accuracy: 0.7379 - val_loss: 0.5081\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5171 - val_accuracy: 0.7365 - val_loss: 0.5086\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5127 - val_accuracy: 0.7366 - val_loss: 0.5078\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5117 - val_accuracy: 0.7375 - val_loss: 0.5065\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5137 - val_accuracy: 0.7358 - val_loss: 0.5058\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5122 - val_accuracy: 0.7357 - val_loss: 0.5073\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5083 - val_accuracy: 0.7346 - val_loss: 0.5081\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5099 - val_accuracy: 0.7368 - val_loss: 0.5073\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5114 - val_accuracy: 0.7377 - val_loss: 0.5061\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 11/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.5226 - val_accuracy: 0.7331 - val_loss: 0.5136\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5205 - val_accuracy: 0.7322 - val_loss: 0.5152\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.5164 - val_accuracy: 0.7326 - val_loss: 0.5152\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5170 - val_accuracy: 0.7328 - val_loss: 0.5135\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5146 - val_accuracy: 0.7358 - val_loss: 0.5135\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5132 - val_accuracy: 0.7352 - val_loss: 0.5143\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5137 - val_accuracy: 0.7347 - val_loss: 0.5135\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5129 - val_accuracy: 0.7352 - val_loss: 0.5125\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5158 - val_accuracy: 0.7333 - val_loss: 0.5140\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5124 - val_accuracy: 0.7330 - val_loss: 0.5140\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 12/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5232 - val_accuracy: 0.7370 - val_loss: 0.5061\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5207 - val_accuracy: 0.7358 - val_loss: 0.5079\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5193 - val_accuracy: 0.7368 - val_loss: 0.5074\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.5197 - val_accuracy: 0.7356 - val_loss: 0.5095\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5187 - val_accuracy: 0.7357 - val_loss: 0.5081\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5189 - val_accuracy: 0.7360 - val_loss: 0.5077\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5139 - val_accuracy: 0.7361 - val_loss: 0.5062\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5147 - val_accuracy: 0.7362 - val_loss: 0.5057\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5152 - val_accuracy: 0.7383 - val_loss: 0.5060\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5141 - val_accuracy: 0.7359 - val_loss: 0.5058\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 13/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5184 - val_accuracy: 0.7314 - val_loss: 0.5106\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5174 - val_accuracy: 0.7331 - val_loss: 0.5107\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5155 - val_accuracy: 0.7303 - val_loss: 0.5120\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5133 - val_accuracy: 0.7307 - val_loss: 0.5111\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5134 - val_accuracy: 0.7336 - val_loss: 0.5107\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5107 - val_accuracy: 0.7309 - val_loss: 0.5111\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5129 - val_accuracy: 0.7346 - val_loss: 0.5104\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5103 - val_accuracy: 0.7347 - val_loss: 0.5098\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5090 - val_accuracy: 0.7339 - val_loss: 0.5098\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5095 - val_accuracy: 0.7336 - val_loss: 0.5094\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 14/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.5219 - val_accuracy: 0.7336 - val_loss: 0.5102\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5172 - val_accuracy: 0.7347 - val_loss: 0.5097\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5179 - val_accuracy: 0.7351 - val_loss: 0.5105\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5164 - val_accuracy: 0.7342 - val_loss: 0.5099\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5162 - val_accuracy: 0.7355 - val_loss: 0.5100\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5130 - val_accuracy: 0.7348 - val_loss: 0.5109\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5117 - val_accuracy: 0.7340 - val_loss: 0.5098\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5100 - val_accuracy: 0.7343 - val_loss: 0.5097\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5105 - val_accuracy: 0.7362 - val_loss: 0.5107\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5108 - val_accuracy: 0.7339 - val_loss: 0.5104\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 15/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.5226 - val_accuracy: 0.7357 - val_loss: 0.5113\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.5191 - val_accuracy: 0.7361 - val_loss: 0.5107\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5162 - val_accuracy: 0.7352 - val_loss: 0.5108\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5156 - val_accuracy: 0.7337 - val_loss: 0.5114\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5128 - val_accuracy: 0.7364 - val_loss: 0.5108\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.5132 - val_accuracy: 0.7346 - val_loss: 0.5112\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5143 - val_accuracy: 0.7356 - val_loss: 0.5115\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5118 - val_accuracy: 0.7348 - val_loss: 0.5118\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5109 - val_accuracy: 0.7356 - val_loss: 0.5107\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5094 - val_accuracy: 0.7371 - val_loss: 0.5102\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 16/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.5219 - val_accuracy: 0.7368 - val_loss: 0.5060\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.5214 - val_accuracy: 0.7361 - val_loss: 0.5063\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5192 - val_accuracy: 0.7347 - val_loss: 0.5069\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5165 - val_accuracy: 0.7353 - val_loss: 0.5063\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5173 - val_accuracy: 0.7359 - val_loss: 0.5075\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5161 - val_accuracy: 0.7366 - val_loss: 0.5064\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5124 - val_accuracy: 0.7346 - val_loss: 0.5074\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5161 - val_accuracy: 0.7368 - val_loss: 0.5059\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5106 - val_accuracy: 0.7372 - val_loss: 0.5058\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5102 - val_accuracy: 0.7373 - val_loss: 0.5060\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 17/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5198 - val_accuracy: 0.7334 - val_loss: 0.5109\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7272 - loss: 0.5198 - val_accuracy: 0.7358 - val_loss: 0.5110\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5173 - val_accuracy: 0.7358 - val_loss: 0.5107\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5177 - val_accuracy: 0.7358 - val_loss: 0.5113\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5116 - val_accuracy: 0.7344 - val_loss: 0.5114\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.5121 - val_accuracy: 0.7349 - val_loss: 0.5114\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5132 - val_accuracy: 0.7342 - val_loss: 0.5125\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5114 - val_accuracy: 0.7351 - val_loss: 0.5113\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5116 - val_accuracy: 0.7362 - val_loss: 0.5119\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5115 - val_accuracy: 0.7343 - val_loss: 0.5120\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 18/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5216 - val_accuracy: 0.7349 - val_loss: 0.5109\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5152 - val_accuracy: 0.7331 - val_loss: 0.5108\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5148 - val_accuracy: 0.7348 - val_loss: 0.5114\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5140 - val_accuracy: 0.7327 - val_loss: 0.5107\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5133 - val_accuracy: 0.7346 - val_loss: 0.5100\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5120 - val_accuracy: 0.7337 - val_loss: 0.5103\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5131 - val_accuracy: 0.7355 - val_loss: 0.5091\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5124 - val_accuracy: 0.7362 - val_loss: 0.5094\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5094 - val_accuracy: 0.7354 - val_loss: 0.5098\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5068 - val_accuracy: 0.7350 - val_loss: 0.5099\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 19/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5183 - val_accuracy: 0.7359 - val_loss: 0.5099\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5163 - val_accuracy: 0.7353 - val_loss: 0.5098\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5144 - val_accuracy: 0.7334 - val_loss: 0.5106\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5116 - val_accuracy: 0.7352 - val_loss: 0.5117\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5071 - val_accuracy: 0.7328 - val_loss: 0.5107\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5107 - val_accuracy: 0.7341 - val_loss: 0.5099\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5140 - val_accuracy: 0.7342 - val_loss: 0.5101\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5128 - val_accuracy: 0.7356 - val_loss: 0.5096\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5094 - val_accuracy: 0.7355 - val_loss: 0.5087\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5092 - val_accuracy: 0.7347 - val_loss: 0.5094\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 20/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.5183 - val_accuracy: 0.7372 - val_loss: 0.5068\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5146 - val_accuracy: 0.7377 - val_loss: 0.5076\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5131 - val_accuracy: 0.7371 - val_loss: 0.5067\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5134 - val_accuracy: 0.7377 - val_loss: 0.5071\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5109 - val_accuracy: 0.7386 - val_loss: 0.5059\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5125 - val_accuracy: 0.7379 - val_loss: 0.5067\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5102 - val_accuracy: 0.7375 - val_loss: 0.5066\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5102 - val_accuracy: 0.7370 - val_loss: 0.5059\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5079 - val_accuracy: 0.7389 - val_loss: 0.5067\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5050 - val_accuracy: 0.7397 - val_loss: 0.5072\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 21/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5170 - val_accuracy: 0.7384 - val_loss: 0.5089\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5160 - val_accuracy: 0.7374 - val_loss: 0.5082\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5121 - val_accuracy: 0.7375 - val_loss: 0.5081\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5129 - val_accuracy: 0.7381 - val_loss: 0.5075\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5122 - val_accuracy: 0.7374 - val_loss: 0.5077\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5122 - val_accuracy: 0.7385 - val_loss: 0.5075\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5099 - val_accuracy: 0.7368 - val_loss: 0.5068\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5068 - val_accuracy: 0.7370 - val_loss: 0.5077\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.5057 - val_accuracy: 0.7356 - val_loss: 0.5086\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5070 - val_accuracy: 0.7377 - val_loss: 0.5077\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 22/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5211 - val_accuracy: 0.7375 - val_loss: 0.5065\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5161 - val_accuracy: 0.7378 - val_loss: 0.5067\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5168 - val_accuracy: 0.7388 - val_loss: 0.5073\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5140 - val_accuracy: 0.7383 - val_loss: 0.5076\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5141 - val_accuracy: 0.7351 - val_loss: 0.5073\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5125 - val_accuracy: 0.7382 - val_loss: 0.5070\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5115 - val_accuracy: 0.7377 - val_loss: 0.5068\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5142 - val_accuracy: 0.7387 - val_loss: 0.5059\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5100 - val_accuracy: 0.7400 - val_loss: 0.5060\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5092 - val_accuracy: 0.7377 - val_loss: 0.5066\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 23/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5155 - val_accuracy: 0.7378 - val_loss: 0.5075\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5158 - val_accuracy: 0.7379 - val_loss: 0.5074\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5149 - val_accuracy: 0.7370 - val_loss: 0.5082\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5156 - val_accuracy: 0.7361 - val_loss: 0.5089\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5104 - val_accuracy: 0.7364 - val_loss: 0.5079\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5135 - val_accuracy: 0.7360 - val_loss: 0.5084\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5098 - val_accuracy: 0.7365 - val_loss: 0.5106\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5079 - val_accuracy: 0.7365 - val_loss: 0.5086\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5080 - val_accuracy: 0.7363 - val_loss: 0.5094\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5103 - val_accuracy: 0.7346 - val_loss: 0.5098\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 24/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5189 - val_accuracy: 0.7336 - val_loss: 0.5101\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5158 - val_accuracy: 0.7331 - val_loss: 0.5093\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5171 - val_accuracy: 0.7358 - val_loss: 0.5092\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5143 - val_accuracy: 0.7353 - val_loss: 0.5099\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5126 - val_accuracy: 0.7329 - val_loss: 0.5103\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5121 - val_accuracy: 0.7359 - val_loss: 0.5101\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.5126 - val_accuracy: 0.7344 - val_loss: 0.5096\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.5107 - val_accuracy: 0.7338 - val_loss: 0.5104\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5084 - val_accuracy: 0.7338 - val_loss: 0.5101\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5085 - val_accuracy: 0.7360 - val_loss: 0.5094\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 25/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.5199 - val_accuracy: 0.7388 - val_loss: 0.5038\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.5180 - val_accuracy: 0.7407 - val_loss: 0.5028\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5145 - val_accuracy: 0.7393 - val_loss: 0.5030\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5133 - val_accuracy: 0.7383 - val_loss: 0.5041\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5146 - val_accuracy: 0.7390 - val_loss: 0.5030\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5127 - val_accuracy: 0.7379 - val_loss: 0.5033\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5115 - val_accuracy: 0.7367 - val_loss: 0.5026\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5118 - val_accuracy: 0.7378 - val_loss: 0.5026\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5111 - val_accuracy: 0.7394 - val_loss: 0.5021\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5096 - val_accuracy: 0.7409 - val_loss: 0.5025\n",
      "Epoch 11/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5077 - val_accuracy: 0.7410 - val_loss: 0.5034\n",
      "Epoch 12/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5073 - val_accuracy: 0.7394 - val_loss: 0.5039\n",
      "Epoch 13/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5085 - val_accuracy: 0.7386 - val_loss: 0.5024\n",
      "Epoch 14/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5078 - val_accuracy: 0.7392 - val_loss: 0.5033\n",
      "Epoch 15/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5052 - val_accuracy: 0.7394 - val_loss: 0.5032\n",
      "Epoch 16/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.5068 - val_accuracy: 0.7395 - val_loss: 0.5039\n",
      "Epoch 17/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5039 - val_accuracy: 0.7396 - val_loss: 0.5031\n",
      "Epoch 18/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.5064 - val_accuracy: 0.7399 - val_loss: 0.5031\n",
      "Epoch 19/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5072 - val_accuracy: 0.7399 - val_loss: 0.5020\n",
      "Epoch 20/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5033 - val_accuracy: 0.7373 - val_loss: 0.5027\n",
      "Epoch 21/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5032 - val_accuracy: 0.7388 - val_loss: 0.5018\n",
      "Epoch 22/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5048 - val_accuracy: 0.7383 - val_loss: 0.5032\n",
      "Epoch 23/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5046 - val_accuracy: 0.7386 - val_loss: 0.5038\n",
      "Epoch 24/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5013 - val_accuracy: 0.7399 - val_loss: 0.5026\n",
      "Epoch 25/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5033 - val_accuracy: 0.7384 - val_loss: 0.5015\n",
      "Epoch 26/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5019 - val_accuracy: 0.7389 - val_loss: 0.5035\n",
      "Epoch 27/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5039 - val_accuracy: 0.7399 - val_loss: 0.5022\n",
      "Epoch 28/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5004 - val_accuracy: 0.7408 - val_loss: 0.5005\n",
      "Epoch 29/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5011 - val_accuracy: 0.7411 - val_loss: 0.5008\n",
      "Epoch 30/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5005 - val_accuracy: 0.7387 - val_loss: 0.5026\n",
      "Epoch 31/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5001 - val_accuracy: 0.7398 - val_loss: 0.5020\n",
      "Epoch 32/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5018 - val_accuracy: 0.7405 - val_loss: 0.5031\n",
      "Epoch 33/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5013 - val_accuracy: 0.7405 - val_loss: 0.5021\n",
      "Epoch 34/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.4988 - val_accuracy: 0.7414 - val_loss: 0.5013\n",
      "Epoch 35/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.4988 - val_accuracy: 0.7398 - val_loss: 0.5017\n",
      "Epoch 36/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.4991 - val_accuracy: 0.7415 - val_loss: 0.5013\n",
      "Epoch 37/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.4960 - val_accuracy: 0.7427 - val_loss: 0.5007\n",
      "Epoch 38/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.4971 - val_accuracy: 0.7405 - val_loss: 0.5018\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 26/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5224 - val_accuracy: 0.7369 - val_loss: 0.5077\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5174 - val_accuracy: 0.7369 - val_loss: 0.5067\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5154 - val_accuracy: 0.7386 - val_loss: 0.5057\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5117 - val_accuracy: 0.7388 - val_loss: 0.5062\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5122 - val_accuracy: 0.7386 - val_loss: 0.5050\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5094 - val_accuracy: 0.7381 - val_loss: 0.5057\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5074 - val_accuracy: 0.7382 - val_loss: 0.5047\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5102 - val_accuracy: 0.7375 - val_loss: 0.5058\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5069 - val_accuracy: 0.7385 - val_loss: 0.5052\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.5069 - val_accuracy: 0.7384 - val_loss: 0.5048\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 27/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7263 - loss: 0.5220 - val_accuracy: 0.7350 - val_loss: 0.5085\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.5171 - val_accuracy: 0.7351 - val_loss: 0.5074\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5132 - val_accuracy: 0.7358 - val_loss: 0.5074\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5135 - val_accuracy: 0.7362 - val_loss: 0.5073\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7300 - loss: 0.5148 - val_accuracy: 0.7344 - val_loss: 0.5069\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.5132 - val_accuracy: 0.7334 - val_loss: 0.5068\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5122 - val_accuracy: 0.7346 - val_loss: 0.5073\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5105 - val_accuracy: 0.7350 - val_loss: 0.5076\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5088 - val_accuracy: 0.7359 - val_loss: 0.5066\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5114 - val_accuracy: 0.7331 - val_loss: 0.5071\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 28/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.5232 - val_accuracy: 0.7341 - val_loss: 0.5108\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.5165 - val_accuracy: 0.7348 - val_loss: 0.5108\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5120 - val_accuracy: 0.7341 - val_loss: 0.5098\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.5132 - val_accuracy: 0.7354 - val_loss: 0.5110\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5120 - val_accuracy: 0.7327 - val_loss: 0.5110\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5114 - val_accuracy: 0.7336 - val_loss: 0.5103\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5110 - val_accuracy: 0.7348 - val_loss: 0.5101\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5104 - val_accuracy: 0.7335 - val_loss: 0.5104\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5094 - val_accuracy: 0.7343 - val_loss: 0.5104\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5085 - val_accuracy: 0.7343 - val_loss: 0.5104\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 29/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.5177 - val_accuracy: 0.7382 - val_loss: 0.5056\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5155 - val_accuracy: 0.7379 - val_loss: 0.5064\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.5137 - val_accuracy: 0.7373 - val_loss: 0.5064\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5162 - val_accuracy: 0.7359 - val_loss: 0.5065\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5140 - val_accuracy: 0.7383 - val_loss: 0.5060\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.5110 - val_accuracy: 0.7381 - val_loss: 0.5056\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5103 - val_accuracy: 0.7374 - val_loss: 0.5053\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5108 - val_accuracy: 0.7388 - val_loss: 0.5057\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5089 - val_accuracy: 0.7381 - val_loss: 0.5046\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5084 - val_accuracy: 0.7380 - val_loss: 0.5063\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 30/30...\n",
      "Epoch 1/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5169 - val_accuracy: 0.7386 - val_loss: 0.5054\n",
      "Epoch 2/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5136 - val_accuracy: 0.7404 - val_loss: 0.5042\n",
      "Epoch 3/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5143 - val_accuracy: 0.7406 - val_loss: 0.5037\n",
      "Epoch 4/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5115 - val_accuracy: 0.7376 - val_loss: 0.5044\n",
      "Epoch 5/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5096 - val_accuracy: 0.7389 - val_loss: 0.5056\n",
      "Epoch 6/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5060 - val_accuracy: 0.7387 - val_loss: 0.5045\n",
      "Epoch 7/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5091 - val_accuracy: 0.7383 - val_loss: 0.5042\n",
      "Epoch 8/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5082 - val_accuracy: 0.7380 - val_loss: 0.5040\n",
      "Epoch 9/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5047 - val_accuracy: 0.7362 - val_loss: 0.5045\n",
      "Epoch 10/60\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5062 - val_accuracy: 0.7383 - val_loss: 0.5045\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Bagging ensemble accuracy: 0.7223\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 30  # number of models in the ensemble\n",
    "models = []\n",
    "predictions = np.zeros((X_test_pca.shape[0], n_estimators))\n",
    "# we redefine the model because the shape of the train_set has changed since we did the PCA\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor (e.g., validation loss)\n",
    "    patience=10,              # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights of the best epoch\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "for i in range(n_estimators):\n",
    "    print(f\"Training model {i + 1}/{n_estimators}...\")\n",
    "# create bootstrap sample\n",
    "    X_train_bootstrap, y_train_bootstrap = resample(X_train_pca_truncated, y_train_filtered, n_samples=len(X_train_pca), random_state=i)\n",
    "    # train the base model on the bootstrap sample\n",
    "    model.fit(X_train_bootstrap, y_train_bootstrap, epochs=60, batch_size=200, validation_split=0.2, verbose=1,callbacks=[early_stopping])\n",
    "    # predict on test set\n",
    "    predictions[:, i] = model.predict(X_test_pca).flatten()\n",
    "# aggregate predictions (majority vote)\n",
    "final_predictions = (np.mean(predictions, axis=1) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Bagging ensemble accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy slightly increased accuracy compared to the normal model applied to the truncated training set. We now implement a model designed for overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.6118 - val_accuracy: 0.7064 - val_loss: 0.5539\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.5510 - val_accuracy: 0.7112 - val_loss: 0.5457\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7110 - loss: 0.5454 - val_accuracy: 0.7143 - val_loss: 0.5431\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7147 - loss: 0.5413 - val_accuracy: 0.7123 - val_loss: 0.5422\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.5411 - val_accuracy: 0.7155 - val_loss: 0.5396\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5382 - val_accuracy: 0.7151 - val_loss: 0.5389\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7173 - loss: 0.5363 - val_accuracy: 0.7139 - val_loss: 0.5370\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.5341 - val_accuracy: 0.7158 - val_loss: 0.5386\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7159 - loss: 0.5362 - val_accuracy: 0.7147 - val_loss: 0.5381\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.5325 - val_accuracy: 0.7173 - val_loss: 0.5352\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5306 - val_accuracy: 0.7157 - val_loss: 0.5349\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.5280 - val_accuracy: 0.7185 - val_loss: 0.5322\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5276 - val_accuracy: 0.7173 - val_loss: 0.5324\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.5249 - val_accuracy: 0.7194 - val_loss: 0.5320\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5240 - val_accuracy: 0.7178 - val_loss: 0.5324\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.5228 - val_accuracy: 0.7204 - val_loss: 0.5326\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.5215 - val_accuracy: 0.7202 - val_loss: 0.5297\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5214 - val_accuracy: 0.7213 - val_loss: 0.5302\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7300 - loss: 0.5192 - val_accuracy: 0.7200 - val_loss: 0.5297\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.5185 - val_accuracy: 0.7229 - val_loss: 0.5280\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5195 - val_accuracy: 0.7203 - val_loss: 0.5284\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5152 - val_accuracy: 0.7221 - val_loss: 0.5275\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5143 - val_accuracy: 0.7222 - val_loss: 0.5269\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5149 - val_accuracy: 0.7235 - val_loss: 0.5281\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5115 - val_accuracy: 0.7257 - val_loss: 0.5267\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7350 - loss: 0.5125 - val_accuracy: 0.7219 - val_loss: 0.5279\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5112 - val_accuracy: 0.7218 - val_loss: 0.5268\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.5074 - val_accuracy: 0.7243 - val_loss: 0.5282\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.5111 - val_accuracy: 0.7243 - val_loss: 0.5276\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5087 - val_accuracy: 0.7249 - val_loss: 0.5252\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7400 - loss: 0.5044 - val_accuracy: 0.7257 - val_loss: 0.5263\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5061 - val_accuracy: 0.7256 - val_loss: 0.5233\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5031 - val_accuracy: 0.7286 - val_loss: 0.5224\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.5017 - val_accuracy: 0.7283 - val_loss: 0.5232\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5031 - val_accuracy: 0.7279 - val_loss: 0.5236\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5016 - val_accuracy: 0.7288 - val_loss: 0.5217\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.4993 - val_accuracy: 0.7275 - val_loss: 0.5235\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.4985 - val_accuracy: 0.7287 - val_loss: 0.5236\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.4979 - val_accuracy: 0.7290 - val_loss: 0.5225\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.4975 - val_accuracy: 0.7279 - val_loss: 0.5222\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.4951 - val_accuracy: 0.7300 - val_loss: 0.5206\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.4944 - val_accuracy: 0.7297 - val_loss: 0.5217\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.4949 - val_accuracy: 0.7298 - val_loss: 0.5234\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.4953 - val_accuracy: 0.7283 - val_loss: 0.5229\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7501 - loss: 0.4919 - val_accuracy: 0.7292 - val_loss: 0.5222\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.4927 - val_accuracy: 0.7282 - val_loss: 0.5245\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7518 - loss: 0.4908 - val_accuracy: 0.7303 - val_loss: 0.5212\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.4907 - val_accuracy: 0.7295 - val_loss: 0.5208\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7506 - loss: 0.4897 - val_accuracy: 0.7329 - val_loss: 0.5204\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.4880 - val_accuracy: 0.7306 - val_loss: 0.5205\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7525 - loss: 0.4886 - val_accuracy: 0.7283 - val_loss: 0.5217\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.4876 - val_accuracy: 0.7292 - val_loss: 0.5205\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.4844 - val_accuracy: 0.7286 - val_loss: 0.5245\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.4859 - val_accuracy: 0.7308 - val_loss: 0.5222\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4815 - val_accuracy: 0.7322 - val_loss: 0.5189\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.4836 - val_accuracy: 0.7312 - val_loss: 0.5206\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.4829 - val_accuracy: 0.7321 - val_loss: 0.5233\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4815 - val_accuracy: 0.7308 - val_loss: 0.5205\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7573 - loss: 0.4808 - val_accuracy: 0.7310 - val_loss: 0.5209\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4814 - val_accuracy: 0.7298 - val_loss: 0.5207\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4827 - val_accuracy: 0.7323 - val_loss: 0.5194\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.4806 - val_accuracy: 0.7332 - val_loss: 0.5200\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4807 - val_accuracy: 0.7337 - val_loss: 0.5200\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.4741 - val_accuracy: 0.7326 - val_loss: 0.5211\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4762 - val_accuracy: 0.7327 - val_loss: 0.5176\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.4733 - val_accuracy: 0.7347 - val_loss: 0.5190\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.4765 - val_accuracy: 0.7331 - val_loss: 0.5189\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.4740 - val_accuracy: 0.7337 - val_loss: 0.5193\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7631 - loss: 0.4739 - val_accuracy: 0.7360 - val_loss: 0.5204\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.4744 - val_accuracy: 0.7370 - val_loss: 0.5202\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.4714 - val_accuracy: 0.7354 - val_loss: 0.5168\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.4707 - val_accuracy: 0.7364 - val_loss: 0.5197\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.4727 - val_accuracy: 0.7343 - val_loss: 0.5201\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.4730 - val_accuracy: 0.7366 - val_loss: 0.5196\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 0.4687 - val_accuracy: 0.7348 - val_loss: 0.5199\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.4705 - val_accuracy: 0.7386 - val_loss: 0.5165\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4684 - val_accuracy: 0.7353 - val_loss: 0.5177\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4659 - val_accuracy: 0.7381 - val_loss: 0.5180\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.4679 - val_accuracy: 0.7396 - val_loss: 0.5170\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.4698 - val_accuracy: 0.7395 - val_loss: 0.5167\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.4691 - val_accuracy: 0.7380 - val_loss: 0.5182\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.4661 - val_accuracy: 0.7394 - val_loss: 0.5175\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.4655 - val_accuracy: 0.7389 - val_loss: 0.5171\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.4639 - val_accuracy: 0.7384 - val_loss: 0.5180\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.4657 - val_accuracy: 0.7386 - val_loss: 0.5181\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.4648 - val_accuracy: 0.7387 - val_loss: 0.5172\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.4648 - val_accuracy: 0.7383 - val_loss: 0.5195\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4636 - val_accuracy: 0.7398 - val_loss: 0.5159\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.4635 - val_accuracy: 0.7394 - val_loss: 0.5162\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.4661 - val_accuracy: 0.7368 - val_loss: 0.5180\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4638 - val_accuracy: 0.7421 - val_loss: 0.5151\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4609 - val_accuracy: 0.7417 - val_loss: 0.5181\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4611 - val_accuracy: 0.7398 - val_loss: 0.5156\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4606 - val_accuracy: 0.7393 - val_loss: 0.5159\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.4584 - val_accuracy: 0.7386 - val_loss: 0.5185\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4594 - val_accuracy: 0.7388 - val_loss: 0.5173\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4621 - val_accuracy: 0.7423 - val_loss: 0.5149\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4582 - val_accuracy: 0.7387 - val_loss: 0.5169\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.4554 - val_accuracy: 0.7383 - val_loss: 0.5202\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4589 - val_accuracy: 0.7405 - val_loss: 0.5154\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.4553 - val_accuracy: 0.7414 - val_loss: 0.5159\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.4571 - val_accuracy: 0.7411 - val_loss: 0.5137\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.4553 - val_accuracy: 0.7387 - val_loss: 0.5185\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.4549 - val_accuracy: 0.7407 - val_loss: 0.5165\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.4567 - val_accuracy: 0.7411 - val_loss: 0.5158\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.4546 - val_accuracy: 0.7420 - val_loss: 0.5157\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.4551 - val_accuracy: 0.7410 - val_loss: 0.5156\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4532 - val_accuracy: 0.7407 - val_loss: 0.5180\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4532 - val_accuracy: 0.7404 - val_loss: 0.5181\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7784 - loss: 0.4525 - val_accuracy: 0.7415 - val_loss: 0.5175\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4541 - val_accuracy: 0.7408 - val_loss: 0.5151\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4513 - val_accuracy: 0.7405 - val_loss: 0.5166\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.4490 - val_accuracy: 0.7420 - val_loss: 0.5171\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4522 - val_accuracy: 0.7418 - val_loss: 0.5159\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.4528 - val_accuracy: 0.7437 - val_loss: 0.5157\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.4507 - val_accuracy: 0.7427 - val_loss: 0.5170\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.4486 - val_accuracy: 0.7412 - val_loss: 0.5175\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.4503 - val_accuracy: 0.7447 - val_loss: 0.5139\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4506 - val_accuracy: 0.7433 - val_loss: 0.5169\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.4525 - val_accuracy: 0.7416 - val_loss: 0.5169\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 2/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5313 - val_accuracy: 0.7383 - val_loss: 0.5115\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5147 - val_accuracy: 0.7390 - val_loss: 0.5102\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5069 - val_accuracy: 0.7409 - val_loss: 0.5079\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5042 - val_accuracy: 0.7414 - val_loss: 0.5058\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5009 - val_accuracy: 0.7413 - val_loss: 0.5071\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7469 - loss: 0.4983 - val_accuracy: 0.7416 - val_loss: 0.5057\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.4961 - val_accuracy: 0.7421 - val_loss: 0.5070\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.4953 - val_accuracy: 0.7422 - val_loss: 0.5051\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7508 - loss: 0.4937 - val_accuracy: 0.7438 - val_loss: 0.5034\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7532 - loss: 0.4914 - val_accuracy: 0.7418 - val_loss: 0.5051\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.4904 - val_accuracy: 0.7411 - val_loss: 0.5053\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.4883 - val_accuracy: 0.7428 - val_loss: 0.5034\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.4878 - val_accuracy: 0.7428 - val_loss: 0.5025\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.4881 - val_accuracy: 0.7452 - val_loss: 0.5017\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4851 - val_accuracy: 0.7442 - val_loss: 0.5031\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.4838 - val_accuracy: 0.7465 - val_loss: 0.5020\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.4831 - val_accuracy: 0.7449 - val_loss: 0.5029\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4825 - val_accuracy: 0.7453 - val_loss: 0.5026\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7580 - loss: 0.4815 - val_accuracy: 0.7470 - val_loss: 0.5012\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.4790 - val_accuracy: 0.7469 - val_loss: 0.5013\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.4799 - val_accuracy: 0.7489 - val_loss: 0.5014\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.4770 - val_accuracy: 0.7469 - val_loss: 0.5007\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.4760 - val_accuracy: 0.7464 - val_loss: 0.5016\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.4728 - val_accuracy: 0.7481 - val_loss: 0.4999\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.4726 - val_accuracy: 0.7459 - val_loss: 0.5021\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.4746 - val_accuracy: 0.7465 - val_loss: 0.5042\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.4750 - val_accuracy: 0.7467 - val_loss: 0.5011\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.4712 - val_accuracy: 0.7467 - val_loss: 0.5017\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.4709 - val_accuracy: 0.7484 - val_loss: 0.5009\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4706 - val_accuracy: 0.7481 - val_loss: 0.5008\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.4672 - val_accuracy: 0.7507 - val_loss: 0.5003\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4686 - val_accuracy: 0.7524 - val_loss: 0.4987\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4674 - val_accuracy: 0.7485 - val_loss: 0.5015\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.4666 - val_accuracy: 0.7488 - val_loss: 0.5019\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.4656 - val_accuracy: 0.7509 - val_loss: 0.5005\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.4628 - val_accuracy: 0.7500 - val_loss: 0.5009\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.4638 - val_accuracy: 0.7511 - val_loss: 0.4995\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4634 - val_accuracy: 0.7535 - val_loss: 0.4991\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.4612 - val_accuracy: 0.7536 - val_loss: 0.4995\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.4644 - val_accuracy: 0.7546 - val_loss: 0.4995\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4594 - val_accuracy: 0.7502 - val_loss: 0.4999\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4617 - val_accuracy: 0.7535 - val_loss: 0.4994\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.4582 - val_accuracy: 0.7522 - val_loss: 0.4997\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4590 - val_accuracy: 0.7537 - val_loss: 0.4993\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4608 - val_accuracy: 0.7533 - val_loss: 0.5011\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.4615 - val_accuracy: 0.7508 - val_loss: 0.5010\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4567 - val_accuracy: 0.7503 - val_loss: 0.5022\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7772 - loss: 0.4553 - val_accuracy: 0.7505 - val_loss: 0.5025\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4596 - val_accuracy: 0.7521 - val_loss: 0.5027\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4585 - val_accuracy: 0.7524 - val_loss: 0.5017\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.4534 - val_accuracy: 0.7519 - val_loss: 0.5007\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.4528 - val_accuracy: 0.7519 - val_loss: 0.5003\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4542 - val_accuracy: 0.7520 - val_loss: 0.5012\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.4521 - val_accuracy: 0.7545 - val_loss: 0.4991\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4536 - val_accuracy: 0.7527 - val_loss: 0.5000\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.4535 - val_accuracy: 0.7541 - val_loss: 0.5004\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.4515 - val_accuracy: 0.7504 - val_loss: 0.5033\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4524 - val_accuracy: 0.7535 - val_loss: 0.4997\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7798 - loss: 0.4500 - val_accuracy: 0.7544 - val_loss: 0.5010\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4540 - val_accuracy: 0.7542 - val_loss: 0.5000\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.4490 - val_accuracy: 0.7542 - val_loss: 0.4985\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.4480 - val_accuracy: 0.7562 - val_loss: 0.4992\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.4481 - val_accuracy: 0.7541 - val_loss: 0.5001\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4483 - val_accuracy: 0.7552 - val_loss: 0.4991\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.4472 - val_accuracy: 0.7537 - val_loss: 0.5000\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.4487 - val_accuracy: 0.7566 - val_loss: 0.4999\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.4453 - val_accuracy: 0.7538 - val_loss: 0.4994\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4471 - val_accuracy: 0.7557 - val_loss: 0.4978\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7846 - loss: 0.4450 - val_accuracy: 0.7541 - val_loss: 0.5005\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4439 - val_accuracy: 0.7539 - val_loss: 0.5002\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4460 - val_accuracy: 0.7570 - val_loss: 0.4982\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4461 - val_accuracy: 0.7559 - val_loss: 0.4991\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7810 - loss: 0.4497 - val_accuracy: 0.7569 - val_loss: 0.4999\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4436 - val_accuracy: 0.7539 - val_loss: 0.5014\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4434 - val_accuracy: 0.7568 - val_loss: 0.4994\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4452 - val_accuracy: 0.7566 - val_loss: 0.4983\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4449 - val_accuracy: 0.7571 - val_loss: 0.5000\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4426 - val_accuracy: 0.7554 - val_loss: 0.4990\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4433 - val_accuracy: 0.7560 - val_loss: 0.5016\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4433 - val_accuracy: 0.7544 - val_loss: 0.5010\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.4398 - val_accuracy: 0.7565 - val_loss: 0.4990\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4418 - val_accuracy: 0.7560 - val_loss: 0.4991\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4396 - val_accuracy: 0.7594 - val_loss: 0.4996\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4425 - val_accuracy: 0.7563 - val_loss: 0.4998\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.4415 - val_accuracy: 0.7569 - val_loss: 0.4992\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.4391 - val_accuracy: 0.7545 - val_loss: 0.5020\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.4409 - val_accuracy: 0.7545 - val_loss: 0.5011\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.4397 - val_accuracy: 0.7571 - val_loss: 0.4984\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.4411 - val_accuracy: 0.7562 - val_loss: 0.5022\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4373 - val_accuracy: 0.7576 - val_loss: 0.4989\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.4383 - val_accuracy: 0.7584 - val_loss: 0.4992\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4387 - val_accuracy: 0.7576 - val_loss: 0.4999\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4395 - val_accuracy: 0.7577 - val_loss: 0.5013\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4409 - val_accuracy: 0.7586 - val_loss: 0.4998\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.4411 - val_accuracy: 0.7556 - val_loss: 0.5024\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4351 - val_accuracy: 0.7552 - val_loss: 0.5014\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4373 - val_accuracy: 0.7577 - val_loss: 0.5010\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7892 - loss: 0.4361 - val_accuracy: 0.7590 - val_loss: 0.5011\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4358 - val_accuracy: 0.7569 - val_loss: 0.5005\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4362 - val_accuracy: 0.7560 - val_loss: 0.5002\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4400 - val_accuracy: 0.7588 - val_loss: 0.4986\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4344 - val_accuracy: 0.7551 - val_loss: 0.5015\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4357 - val_accuracy: 0.7600 - val_loss: 0.4977\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4397 - val_accuracy: 0.7610 - val_loss: 0.4974\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 0.4365 - val_accuracy: 0.7582 - val_loss: 0.5001\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4352 - val_accuracy: 0.7548 - val_loss: 0.5031\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.4348 - val_accuracy: 0.7580 - val_loss: 0.4998\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.4350 - val_accuracy: 0.7596 - val_loss: 0.4981\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4358 - val_accuracy: 0.7569 - val_loss: 0.5020\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.4347 - val_accuracy: 0.7576 - val_loss: 0.5012\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.4358 - val_accuracy: 0.7595 - val_loss: 0.4992\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4328 - val_accuracy: 0.7588 - val_loss: 0.4989\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4345 - val_accuracy: 0.7591 - val_loss: 0.4978\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4329 - val_accuracy: 0.7609 - val_loss: 0.5000\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4306 - val_accuracy: 0.7609 - val_loss: 0.4996\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4324 - val_accuracy: 0.7599 - val_loss: 0.4993\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.4335 - val_accuracy: 0.7602 - val_loss: 0.4990\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.4330 - val_accuracy: 0.7618 - val_loss: 0.5003\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4305 - val_accuracy: 0.7586 - val_loss: 0.5020\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4310 - val_accuracy: 0.7613 - val_loss: 0.4971\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 3/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.5272 - val_accuracy: 0.7472 - val_loss: 0.5039\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5038 - val_accuracy: 0.7477 - val_loss: 0.4992\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.4985 - val_accuracy: 0.7468 - val_loss: 0.5012\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.4916 - val_accuracy: 0.7511 - val_loss: 0.4971\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.4880 - val_accuracy: 0.7513 - val_loss: 0.4966\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.4857 - val_accuracy: 0.7485 - val_loss: 0.4960\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7584 - loss: 0.4843 - val_accuracy: 0.7517 - val_loss: 0.4934\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4822 - val_accuracy: 0.7508 - val_loss: 0.4960\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7582 - loss: 0.4821 - val_accuracy: 0.7507 - val_loss: 0.4960\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 0.4775 - val_accuracy: 0.7489 - val_loss: 0.4951\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.4789 - val_accuracy: 0.7525 - val_loss: 0.4951\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.4746 - val_accuracy: 0.7484 - val_loss: 0.4946\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4727 - val_accuracy: 0.7486 - val_loss: 0.4966\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.4734 - val_accuracy: 0.7465 - val_loss: 0.4975\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.4738 - val_accuracy: 0.7491 - val_loss: 0.4971\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 0.4695 - val_accuracy: 0.7501 - val_loss: 0.4964\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7703 - loss: 0.4681 - val_accuracy: 0.7484 - val_loss: 0.4969\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.4703 - val_accuracy: 0.7497 - val_loss: 0.4968\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.4644 - val_accuracy: 0.7501 - val_loss: 0.4955\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.4652 - val_accuracy: 0.7512 - val_loss: 0.4973\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.4634 - val_accuracy: 0.7493 - val_loss: 0.4969\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.4643 - val_accuracy: 0.7512 - val_loss: 0.4961\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7712 - loss: 0.4618 - val_accuracy: 0.7485 - val_loss: 0.4975\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4583 - val_accuracy: 0.7487 - val_loss: 0.4990\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4595 - val_accuracy: 0.7543 - val_loss: 0.4948\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4577 - val_accuracy: 0.7521 - val_loss: 0.4957\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.4577 - val_accuracy: 0.7520 - val_loss: 0.4968\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7754 - loss: 0.4567 - val_accuracy: 0.7515 - val_loss: 0.4975\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4581 - val_accuracy: 0.7513 - val_loss: 0.4970\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.4569 - val_accuracy: 0.7531 - val_loss: 0.4977\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.4529 - val_accuracy: 0.7521 - val_loss: 0.4958\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4542 - val_accuracy: 0.7533 - val_loss: 0.4975\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4529 - val_accuracy: 0.7541 - val_loss: 0.4952\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4552 - val_accuracy: 0.7522 - val_loss: 0.4961\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7792 - loss: 0.4515 - val_accuracy: 0.7506 - val_loss: 0.4971\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4499 - val_accuracy: 0.7522 - val_loss: 0.4963\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.4520 - val_accuracy: 0.7529 - val_loss: 0.4959\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.4486 - val_accuracy: 0.7537 - val_loss: 0.4958\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.4463 - val_accuracy: 0.7511 - val_loss: 0.4993\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4504 - val_accuracy: 0.7533 - val_loss: 0.4989\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.4503 - val_accuracy: 0.7513 - val_loss: 0.4978\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.4472 - val_accuracy: 0.7474 - val_loss: 0.4993\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.4484 - val_accuracy: 0.7511 - val_loss: 0.4982\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4455 - val_accuracy: 0.7548 - val_loss: 0.4964\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4464 - val_accuracy: 0.7541 - val_loss: 0.4971\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4471 - val_accuracy: 0.7554 - val_loss: 0.4960\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4450 - val_accuracy: 0.7550 - val_loss: 0.4986\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4447 - val_accuracy: 0.7536 - val_loss: 0.4964\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4432 - val_accuracy: 0.7562 - val_loss: 0.4995\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4418 - val_accuracy: 0.7515 - val_loss: 0.4965\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.4414 - val_accuracy: 0.7559 - val_loss: 0.4964\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.4434 - val_accuracy: 0.7545 - val_loss: 0.4979\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.4424 - val_accuracy: 0.7562 - val_loss: 0.4970\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4420 - val_accuracy: 0.7520 - val_loss: 0.4987\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7871 - loss: 0.4403 - val_accuracy: 0.7542 - val_loss: 0.4980\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4412 - val_accuracy: 0.7535 - val_loss: 0.4956\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4414 - val_accuracy: 0.7549 - val_loss: 0.4985\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4405 - val_accuracy: 0.7546 - val_loss: 0.4987\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4387 - val_accuracy: 0.7522 - val_loss: 0.4995\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4430 - val_accuracy: 0.7526 - val_loss: 0.4995\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4368 - val_accuracy: 0.7553 - val_loss: 0.4974\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.4372 - val_accuracy: 0.7517 - val_loss: 0.4972\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4399 - val_accuracy: 0.7513 - val_loss: 0.5009\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4380 - val_accuracy: 0.7549 - val_loss: 0.5000\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.4402 - val_accuracy: 0.7563 - val_loss: 0.4982\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4380 - val_accuracy: 0.7531 - val_loss: 0.4994\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4375 - val_accuracy: 0.7554 - val_loss: 0.4984\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4352 - val_accuracy: 0.7566 - val_loss: 0.4989\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4386 - val_accuracy: 0.7526 - val_loss: 0.5009\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4350 - val_accuracy: 0.7521 - val_loss: 0.4994\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.4334 - val_accuracy: 0.7534 - val_loss: 0.5002\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4352 - val_accuracy: 0.7539 - val_loss: 0.5016\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4327 - val_accuracy: 0.7564 - val_loss: 0.5003\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4351 - val_accuracy: 0.7566 - val_loss: 0.4979\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4317 - val_accuracy: 0.7559 - val_loss: 0.5000\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4335 - val_accuracy: 0.7537 - val_loss: 0.5015\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4350 - val_accuracy: 0.7560 - val_loss: 0.4989\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.4325 - val_accuracy: 0.7562 - val_loss: 0.5002\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4317 - val_accuracy: 0.7551 - val_loss: 0.5009\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4317 - val_accuracy: 0.7573 - val_loss: 0.4978\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4344 - val_accuracy: 0.7544 - val_loss: 0.5015\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4316 - val_accuracy: 0.7556 - val_loss: 0.5001\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4331 - val_accuracy: 0.7552 - val_loss: 0.5006\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4303 - val_accuracy: 0.7558 - val_loss: 0.5004\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4290 - val_accuracy: 0.7544 - val_loss: 0.5021\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4291 - val_accuracy: 0.7573 - val_loss: 0.5020\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.4262 - val_accuracy: 0.7573 - val_loss: 0.5046\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.4273 - val_accuracy: 0.7566 - val_loss: 0.5013\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4300 - val_accuracy: 0.7570 - val_loss: 0.5026\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4270 - val_accuracy: 0.7553 - val_loss: 0.5019\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.4311 - val_accuracy: 0.7538 - val_loss: 0.5032\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4285 - val_accuracy: 0.7577 - val_loss: 0.5020\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4268 - val_accuracy: 0.7573 - val_loss: 0.5046\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4250 - val_accuracy: 0.7571 - val_loss: 0.5007\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4281 - val_accuracy: 0.7554 - val_loss: 0.5019\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4279 - val_accuracy: 0.7558 - val_loss: 0.4999\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4262 - val_accuracy: 0.7573 - val_loss: 0.5011\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.4253 - val_accuracy: 0.7564 - val_loss: 0.5004\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.4271 - val_accuracy: 0.7578 - val_loss: 0.5009\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4268 - val_accuracy: 0.7575 - val_loss: 0.5019\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4287 - val_accuracy: 0.7547 - val_loss: 0.5026\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4275 - val_accuracy: 0.7568 - val_loss: 0.5010\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4260 - val_accuracy: 0.7558 - val_loss: 0.5019\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4252 - val_accuracy: 0.7582 - val_loss: 0.5022\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4269 - val_accuracy: 0.7565 - val_loss: 0.5024\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.4252 - val_accuracy: 0.7558 - val_loss: 0.5013\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4236 - val_accuracy: 0.7550 - val_loss: 0.5010\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4209 - val_accuracy: 0.7561 - val_loss: 0.5040\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4257 - val_accuracy: 0.7578 - val_loss: 0.5039\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4221 - val_accuracy: 0.7560 - val_loss: 0.5055\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4209 - val_accuracy: 0.7560 - val_loss: 0.5035\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4244 - val_accuracy: 0.7588 - val_loss: 0.5050\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4250 - val_accuracy: 0.7586 - val_loss: 0.5005\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4240 - val_accuracy: 0.7570 - val_loss: 0.5017\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4219 - val_accuracy: 0.7579 - val_loss: 0.5033\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4238 - val_accuracy: 0.7566 - val_loss: 0.5027\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4222 - val_accuracy: 0.7570 - val_loss: 0.5042\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4232 - val_accuracy: 0.7596 - val_loss: 0.5029\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.4231 - val_accuracy: 0.7595 - val_loss: 0.5026\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4204 - val_accuracy: 0.7578 - val_loss: 0.5034\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 4/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.5268 - val_accuracy: 0.7569 - val_loss: 0.4925\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.4971 - val_accuracy: 0.7583 - val_loss: 0.4899\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.4926 - val_accuracy: 0.7563 - val_loss: 0.4905\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7582 - loss: 0.4862 - val_accuracy: 0.7592 - val_loss: 0.4876\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7599 - loss: 0.4807 - val_accuracy: 0.7593 - val_loss: 0.4881\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.4762 - val_accuracy: 0.7589 - val_loss: 0.4881\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.4759 - val_accuracy: 0.7595 - val_loss: 0.4865\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.4731 - val_accuracy: 0.7574 - val_loss: 0.4862\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.4715 - val_accuracy: 0.7605 - val_loss: 0.4856\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7645 - loss: 0.4719 - val_accuracy: 0.7592 - val_loss: 0.4832\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.4676 - val_accuracy: 0.7602 - val_loss: 0.4835\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4654 - val_accuracy: 0.7603 - val_loss: 0.4856\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4653 - val_accuracy: 0.7603 - val_loss: 0.4846\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4641 - val_accuracy: 0.7593 - val_loss: 0.4836\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.4617 - val_accuracy: 0.7606 - val_loss: 0.4850\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.4635 - val_accuracy: 0.7604 - val_loss: 0.4859\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4607 - val_accuracy: 0.7597 - val_loss: 0.4854\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4613 - val_accuracy: 0.7592 - val_loss: 0.4869\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.4551 - val_accuracy: 0.7622 - val_loss: 0.4850\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.4553 - val_accuracy: 0.7586 - val_loss: 0.4859\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.4564 - val_accuracy: 0.7597 - val_loss: 0.4860\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.4564 - val_accuracy: 0.7596 - val_loss: 0.4850\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4546 - val_accuracy: 0.7597 - val_loss: 0.4857\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.4516 - val_accuracy: 0.7606 - val_loss: 0.4857\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4521 - val_accuracy: 0.7598 - val_loss: 0.4875\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.4503 - val_accuracy: 0.7611 - val_loss: 0.4863\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.4490 - val_accuracy: 0.7604 - val_loss: 0.4866\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.4493 - val_accuracy: 0.7599 - val_loss: 0.4875\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4489 - val_accuracy: 0.7599 - val_loss: 0.4871\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.4461 - val_accuracy: 0.7597 - val_loss: 0.4871\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4446 - val_accuracy: 0.7590 - val_loss: 0.4880\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4456 - val_accuracy: 0.7616 - val_loss: 0.4869\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4457 - val_accuracy: 0.7594 - val_loss: 0.4891\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.4437 - val_accuracy: 0.7596 - val_loss: 0.4878\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.4459 - val_accuracy: 0.7621 - val_loss: 0.4880\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.4435 - val_accuracy: 0.7626 - val_loss: 0.4886\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4449 - val_accuracy: 0.7628 - val_loss: 0.4872\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4401 - val_accuracy: 0.7590 - val_loss: 0.4899\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4421 - val_accuracy: 0.7617 - val_loss: 0.4881\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4376 - val_accuracy: 0.7612 - val_loss: 0.4895\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4402 - val_accuracy: 0.7621 - val_loss: 0.4873\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.4409 - val_accuracy: 0.7620 - val_loss: 0.4859\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4408 - val_accuracy: 0.7607 - val_loss: 0.4890\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4411 - val_accuracy: 0.7618 - val_loss: 0.4883\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.4376 - val_accuracy: 0.7625 - val_loss: 0.4881\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4383 - val_accuracy: 0.7611 - val_loss: 0.4873\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.4365 - val_accuracy: 0.7615 - val_loss: 0.4898\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4399 - val_accuracy: 0.7608 - val_loss: 0.4880\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4357 - val_accuracy: 0.7611 - val_loss: 0.4898\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4347 - val_accuracy: 0.7625 - val_loss: 0.4880\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4381 - val_accuracy: 0.7616 - val_loss: 0.4888\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4371 - val_accuracy: 0.7602 - val_loss: 0.4924\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4346 - val_accuracy: 0.7638 - val_loss: 0.4890\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.4353 - val_accuracy: 0.7602 - val_loss: 0.4909\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4370 - val_accuracy: 0.7612 - val_loss: 0.4926\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4348 - val_accuracy: 0.7618 - val_loss: 0.4902\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4324 - val_accuracy: 0.7604 - val_loss: 0.4906\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4336 - val_accuracy: 0.7633 - val_loss: 0.4896\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4336 - val_accuracy: 0.7622 - val_loss: 0.4900\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4351 - val_accuracy: 0.7631 - val_loss: 0.4902\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4319 - val_accuracy: 0.7595 - val_loss: 0.4946\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4326 - val_accuracy: 0.7610 - val_loss: 0.4910\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 0.4311 - val_accuracy: 0.7604 - val_loss: 0.4931\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4273 - val_accuracy: 0.7648 - val_loss: 0.4895\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4320 - val_accuracy: 0.7602 - val_loss: 0.4933\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.4309 - val_accuracy: 0.7636 - val_loss: 0.4904\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.4314 - val_accuracy: 0.7635 - val_loss: 0.4885\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7930 - loss: 0.4295 - val_accuracy: 0.7610 - val_loss: 0.4946\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4281 - val_accuracy: 0.7635 - val_loss: 0.4908\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4278 - val_accuracy: 0.7634 - val_loss: 0.4919\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.4298 - val_accuracy: 0.7625 - val_loss: 0.4917\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7939 - loss: 0.4295 - val_accuracy: 0.7622 - val_loss: 0.4917\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.4276 - val_accuracy: 0.7622 - val_loss: 0.4930\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4239 - val_accuracy: 0.7628 - val_loss: 0.4922\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4283 - val_accuracy: 0.7643 - val_loss: 0.4912\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4259 - val_accuracy: 0.7637 - val_loss: 0.4915\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.4257 - val_accuracy: 0.7607 - val_loss: 0.4923\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4220 - val_accuracy: 0.7637 - val_loss: 0.4921\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4269 - val_accuracy: 0.7626 - val_loss: 0.4911\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4261 - val_accuracy: 0.7625 - val_loss: 0.4923\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4274 - val_accuracy: 0.7631 - val_loss: 0.4905\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4246 - val_accuracy: 0.7634 - val_loss: 0.4922\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4241 - val_accuracy: 0.7614 - val_loss: 0.4939\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4239 - val_accuracy: 0.7644 - val_loss: 0.4927\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.4251 - val_accuracy: 0.7637 - val_loss: 0.4917\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4229 - val_accuracy: 0.7620 - val_loss: 0.4914\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4225 - val_accuracy: 0.7624 - val_loss: 0.4957\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4226 - val_accuracy: 0.7631 - val_loss: 0.4914\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4245 - val_accuracy: 0.7620 - val_loss: 0.4952\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4224 - val_accuracy: 0.7632 - val_loss: 0.4953\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4235 - val_accuracy: 0.7645 - val_loss: 0.4927\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4236 - val_accuracy: 0.7639 - val_loss: 0.4950\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4229 - val_accuracy: 0.7631 - val_loss: 0.4923\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4203 - val_accuracy: 0.7635 - val_loss: 0.4951\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4224 - val_accuracy: 0.7623 - val_loss: 0.4950\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4239 - val_accuracy: 0.7630 - val_loss: 0.4930\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4187 - val_accuracy: 0.7643 - val_loss: 0.4944\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4244 - val_accuracy: 0.7626 - val_loss: 0.4925\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4192 - val_accuracy: 0.7630 - val_loss: 0.4941\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4183 - val_accuracy: 0.7654 - val_loss: 0.4924\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4215 - val_accuracy: 0.7639 - val_loss: 0.4945\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4241 - val_accuracy: 0.7644 - val_loss: 0.4929\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4212 - val_accuracy: 0.7640 - val_loss: 0.4963\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4188 - val_accuracy: 0.7649 - val_loss: 0.4930\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4205 - val_accuracy: 0.7654 - val_loss: 0.4932\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4215 - val_accuracy: 0.7657 - val_loss: 0.4946\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4196 - val_accuracy: 0.7631 - val_loss: 0.4975\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4240 - val_accuracy: 0.7672 - val_loss: 0.4935\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4160 - val_accuracy: 0.7647 - val_loss: 0.4942\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7986 - loss: 0.4222 - val_accuracy: 0.7657 - val_loss: 0.4930\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4184 - val_accuracy: 0.7681 - val_loss: 0.4940\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4236 - val_accuracy: 0.7647 - val_loss: 0.4937\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4187 - val_accuracy: 0.7665 - val_loss: 0.4932\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4198 - val_accuracy: 0.7646 - val_loss: 0.4912\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4186 - val_accuracy: 0.7668 - val_loss: 0.4924\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.4169 - val_accuracy: 0.7631 - val_loss: 0.4955\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4205 - val_accuracy: 0.7635 - val_loss: 0.4977\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4173 - val_accuracy: 0.7656 - val_loss: 0.4921\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.4174 - val_accuracy: 0.7655 - val_loss: 0.4919\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4158 - val_accuracy: 0.7661 - val_loss: 0.4917\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training model 5/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7466 - loss: 0.5166 - val_accuracy: 0.7568 - val_loss: 0.4863\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7524 - loss: 0.4940 - val_accuracy: 0.7597 - val_loss: 0.4817\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.4871 - val_accuracy: 0.7616 - val_loss: 0.4810\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.4787 - val_accuracy: 0.7625 - val_loss: 0.4773\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.4757 - val_accuracy: 0.7616 - val_loss: 0.4783\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.4743 - val_accuracy: 0.7598 - val_loss: 0.4803\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.4712 - val_accuracy: 0.7575 - val_loss: 0.4814\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4688 - val_accuracy: 0.7589 - val_loss: 0.4803\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7682 - loss: 0.4672 - val_accuracy: 0.7586 - val_loss: 0.4795\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.4649 - val_accuracy: 0.7592 - val_loss: 0.4803\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.4640 - val_accuracy: 0.7608 - val_loss: 0.4801\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.4628 - val_accuracy: 0.7595 - val_loss: 0.4804\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4606 - val_accuracy: 0.7616 - val_loss: 0.4803\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4582 - val_accuracy: 0.7592 - val_loss: 0.4814\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4587 - val_accuracy: 0.7601 - val_loss: 0.4817\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.4544 - val_accuracy: 0.7600 - val_loss: 0.4789\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7740 - loss: 0.4567 - val_accuracy: 0.7584 - val_loss: 0.4802\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4567 - val_accuracy: 0.7583 - val_loss: 0.4813\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4537 - val_accuracy: 0.7608 - val_loss: 0.4808\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4532 - val_accuracy: 0.7604 - val_loss: 0.4795\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.4512 - val_accuracy: 0.7621 - val_loss: 0.4798\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 0.4481 - val_accuracy: 0.7596 - val_loss: 0.4820\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.4444 - val_accuracy: 0.7605 - val_loss: 0.4803\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4490 - val_accuracy: 0.7592 - val_loss: 0.4815\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.4489 - val_accuracy: 0.7616 - val_loss: 0.4819\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4437 - val_accuracy: 0.7600 - val_loss: 0.4814\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.4446 - val_accuracy: 0.7607 - val_loss: 0.4815\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4460 - val_accuracy: 0.7631 - val_loss: 0.4832\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4456 - val_accuracy: 0.7598 - val_loss: 0.4831\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4447 - val_accuracy: 0.7609 - val_loss: 0.4828\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4436 - val_accuracy: 0.7602 - val_loss: 0.4825\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4420 - val_accuracy: 0.7608 - val_loss: 0.4820\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4396 - val_accuracy: 0.7605 - val_loss: 0.4825\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4418 - val_accuracy: 0.7610 - val_loss: 0.4839\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.4385 - val_accuracy: 0.7619 - val_loss: 0.4823\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.4401 - val_accuracy: 0.7638 - val_loss: 0.4814\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4379 - val_accuracy: 0.7620 - val_loss: 0.4822\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4398 - val_accuracy: 0.7620 - val_loss: 0.4826\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4396 - val_accuracy: 0.7619 - val_loss: 0.4816\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4359 - val_accuracy: 0.7623 - val_loss: 0.4822\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.4350 - val_accuracy: 0.7602 - val_loss: 0.4829\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4369 - val_accuracy: 0.7619 - val_loss: 0.4844\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.4362 - val_accuracy: 0.7632 - val_loss: 0.4850\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4340 - val_accuracy: 0.7606 - val_loss: 0.4840\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4327 - val_accuracy: 0.7608 - val_loss: 0.4847\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.4334 - val_accuracy: 0.7605 - val_loss: 0.4839\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7923 - loss: 0.4320 - val_accuracy: 0.7596 - val_loss: 0.4831\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4270 - val_accuracy: 0.7643 - val_loss: 0.4840\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4310 - val_accuracy: 0.7637 - val_loss: 0.4839\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4343 - val_accuracy: 0.7619 - val_loss: 0.4854\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4317 - val_accuracy: 0.7622 - val_loss: 0.4846\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4335 - val_accuracy: 0.7629 - val_loss: 0.4836\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4313 - val_accuracy: 0.7617 - val_loss: 0.4848\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4280 - val_accuracy: 0.7604 - val_loss: 0.4862\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4315 - val_accuracy: 0.7625 - val_loss: 0.4855\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.4258 - val_accuracy: 0.7621 - val_loss: 0.4859\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.4278 - val_accuracy: 0.7606 - val_loss: 0.4869\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.4278 - val_accuracy: 0.7630 - val_loss: 0.4835\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.4292 - val_accuracy: 0.7625 - val_loss: 0.4854\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4240 - val_accuracy: 0.7616 - val_loss: 0.4865\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4265 - val_accuracy: 0.7626 - val_loss: 0.4881\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4264 - val_accuracy: 0.7642 - val_loss: 0.4849\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4255 - val_accuracy: 0.7609 - val_loss: 0.4871\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4269 - val_accuracy: 0.7625 - val_loss: 0.4872\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4234 - val_accuracy: 0.7606 - val_loss: 0.4897\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4255 - val_accuracy: 0.7621 - val_loss: 0.4885\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4237 - val_accuracy: 0.7602 - val_loss: 0.4877\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4282 - val_accuracy: 0.7614 - val_loss: 0.4875\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4210 - val_accuracy: 0.7624 - val_loss: 0.4878\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4225 - val_accuracy: 0.7584 - val_loss: 0.4914\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4201 - val_accuracy: 0.7613 - val_loss: 0.4883\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4215 - val_accuracy: 0.7619 - val_loss: 0.4885\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4189 - val_accuracy: 0.7600 - val_loss: 0.4906\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4238 - val_accuracy: 0.7626 - val_loss: 0.4891\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.4209 - val_accuracy: 0.7619 - val_loss: 0.4892\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4212 - val_accuracy: 0.7608 - val_loss: 0.4887\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4221 - val_accuracy: 0.7620 - val_loss: 0.4889\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.4206 - val_accuracy: 0.7631 - val_loss: 0.4881\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4199 - val_accuracy: 0.7628 - val_loss: 0.4892\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4192 - val_accuracy: 0.7635 - val_loss: 0.4890\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4182 - val_accuracy: 0.7616 - val_loss: 0.4901\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4165 - val_accuracy: 0.7622 - val_loss: 0.4906\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4173 - val_accuracy: 0.7631 - val_loss: 0.4906\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.4191 - val_accuracy: 0.7623 - val_loss: 0.4904\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4185 - val_accuracy: 0.7607 - val_loss: 0.4916\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4187 - val_accuracy: 0.7610 - val_loss: 0.4905\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4203 - val_accuracy: 0.7610 - val_loss: 0.4893\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4176 - val_accuracy: 0.7626 - val_loss: 0.4888\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4120 - val_accuracy: 0.7625 - val_loss: 0.4922\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4211 - val_accuracy: 0.7611 - val_loss: 0.4906\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4137 - val_accuracy: 0.7645 - val_loss: 0.4904\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4172 - val_accuracy: 0.7651 - val_loss: 0.4880\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4148 - val_accuracy: 0.7619 - val_loss: 0.4896\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4177 - val_accuracy: 0.7633 - val_loss: 0.4910\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4142 - val_accuracy: 0.7612 - val_loss: 0.4913\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4182 - val_accuracy: 0.7596 - val_loss: 0.4934\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4193 - val_accuracy: 0.7631 - val_loss: 0.4902\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.4147 - val_accuracy: 0.7615 - val_loss: 0.4900\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4173 - val_accuracy: 0.7617 - val_loss: 0.4916\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4173 - val_accuracy: 0.7626 - val_loss: 0.4902\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4181 - val_accuracy: 0.7626 - val_loss: 0.4911\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4149 - val_accuracy: 0.7644 - val_loss: 0.4915\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4145 - val_accuracy: 0.7632 - val_loss: 0.4911\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4151 - val_accuracy: 0.7626 - val_loss: 0.4935\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4154 - val_accuracy: 0.7621 - val_loss: 0.4931\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4112 - val_accuracy: 0.7626 - val_loss: 0.4909\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4133 - val_accuracy: 0.7636 - val_loss: 0.4907\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4130 - val_accuracy: 0.7623 - val_loss: 0.4924\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4144 - val_accuracy: 0.7629 - val_loss: 0.4916\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4131 - val_accuracy: 0.7634 - val_loss: 0.4920\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4098 - val_accuracy: 0.7633 - val_loss: 0.4926\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4134 - val_accuracy: 0.7627 - val_loss: 0.4924\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4090 - val_accuracy: 0.7617 - val_loss: 0.4942\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4115 - val_accuracy: 0.7626 - val_loss: 0.4923\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4087 - val_accuracy: 0.7641 - val_loss: 0.4922\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.4098 - val_accuracy: 0.7619 - val_loss: 0.4941\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.4081 - val_accuracy: 0.7631 - val_loss: 0.4935\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8059 - loss: 0.4094 - val_accuracy: 0.7630 - val_loss: 0.4919\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4150 - val_accuracy: 0.7627 - val_loss: 0.4916\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4134 - val_accuracy: 0.7635 - val_loss: 0.4927\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 6/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.5212 - val_accuracy: 0.7528 - val_loss: 0.4932\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.4935 - val_accuracy: 0.7552 - val_loss: 0.4894\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.4842 - val_accuracy: 0.7553 - val_loss: 0.4875\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4818 - val_accuracy: 0.7537 - val_loss: 0.4872\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.4739 - val_accuracy: 0.7551 - val_loss: 0.4864\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7634 - loss: 0.4744 - val_accuracy: 0.7558 - val_loss: 0.4843\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.4696 - val_accuracy: 0.7573 - val_loss: 0.4841\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4661 - val_accuracy: 0.7570 - val_loss: 0.4836\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4648 - val_accuracy: 0.7591 - val_loss: 0.4820\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4608 - val_accuracy: 0.7605 - val_loss: 0.4826\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.4608 - val_accuracy: 0.7586 - val_loss: 0.4831\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.4613 - val_accuracy: 0.7583 - val_loss: 0.4845\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7729 - loss: 0.4593 - val_accuracy: 0.7576 - val_loss: 0.4840\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4572 - val_accuracy: 0.7551 - val_loss: 0.4857\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.4560 - val_accuracy: 0.7538 - val_loss: 0.4858\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4573 - val_accuracy: 0.7550 - val_loss: 0.4849\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.4533 - val_accuracy: 0.7570 - val_loss: 0.4841\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4515 - val_accuracy: 0.7579 - val_loss: 0.4839\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4512 - val_accuracy: 0.7574 - val_loss: 0.4836\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4480 - val_accuracy: 0.7598 - val_loss: 0.4832\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.4506 - val_accuracy: 0.7582 - val_loss: 0.4846\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.4486 - val_accuracy: 0.7563 - val_loss: 0.4858\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4494 - val_accuracy: 0.7573 - val_loss: 0.4852\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4468 - val_accuracy: 0.7597 - val_loss: 0.4838\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4488 - val_accuracy: 0.7586 - val_loss: 0.4858\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.4461 - val_accuracy: 0.7586 - val_loss: 0.4846\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.4440 - val_accuracy: 0.7585 - val_loss: 0.4866\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.4445 - val_accuracy: 0.7594 - val_loss: 0.4859\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4429 - val_accuracy: 0.7580 - val_loss: 0.4844\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7862 - loss: 0.4408 - val_accuracy: 0.7585 - val_loss: 0.4853\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4423 - val_accuracy: 0.7588 - val_loss: 0.4858\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.4400 - val_accuracy: 0.7609 - val_loss: 0.4839\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4403 - val_accuracy: 0.7598 - val_loss: 0.4862\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.4411 - val_accuracy: 0.7599 - val_loss: 0.4846\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.4395 - val_accuracy: 0.7607 - val_loss: 0.4836\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.4389 - val_accuracy: 0.7593 - val_loss: 0.4853\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4401 - val_accuracy: 0.7612 - val_loss: 0.4837\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4370 - val_accuracy: 0.7608 - val_loss: 0.4852\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4354 - val_accuracy: 0.7610 - val_loss: 0.4840\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.4347 - val_accuracy: 0.7598 - val_loss: 0.4864\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4348 - val_accuracy: 0.7620 - val_loss: 0.4857\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4379 - val_accuracy: 0.7593 - val_loss: 0.4866\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.4342 - val_accuracy: 0.7592 - val_loss: 0.4867\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 0.4346 - val_accuracy: 0.7601 - val_loss: 0.4864\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4334 - val_accuracy: 0.7582 - val_loss: 0.4859\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4315 - val_accuracy: 0.7604 - val_loss: 0.4855\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4308 - val_accuracy: 0.7597 - val_loss: 0.4873\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4344 - val_accuracy: 0.7600 - val_loss: 0.4860\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.4318 - val_accuracy: 0.7602 - val_loss: 0.4869\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4291 - val_accuracy: 0.7608 - val_loss: 0.4868\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4319 - val_accuracy: 0.7627 - val_loss: 0.4860\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.4311 - val_accuracy: 0.7622 - val_loss: 0.4885\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4318 - val_accuracy: 0.7598 - val_loss: 0.4862\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4293 - val_accuracy: 0.7593 - val_loss: 0.4878\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4287 - val_accuracy: 0.7618 - val_loss: 0.4876\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4288 - val_accuracy: 0.7604 - val_loss: 0.4859\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4286 - val_accuracy: 0.7610 - val_loss: 0.4876\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.4274 - val_accuracy: 0.7605 - val_loss: 0.4891\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4290 - val_accuracy: 0.7590 - val_loss: 0.4884\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4267 - val_accuracy: 0.7619 - val_loss: 0.4879\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4263 - val_accuracy: 0.7628 - val_loss: 0.4855\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.4259 - val_accuracy: 0.7598 - val_loss: 0.4873\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4252 - val_accuracy: 0.7620 - val_loss: 0.4864\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4234 - val_accuracy: 0.7606 - val_loss: 0.4894\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.4255 - val_accuracy: 0.7623 - val_loss: 0.4862\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4271 - val_accuracy: 0.7610 - val_loss: 0.4870\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4223 - val_accuracy: 0.7621 - val_loss: 0.4875\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4249 - val_accuracy: 0.7618 - val_loss: 0.4875\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4222 - val_accuracy: 0.7598 - val_loss: 0.4918\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4221 - val_accuracy: 0.7599 - val_loss: 0.4898\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4243 - val_accuracy: 0.7610 - val_loss: 0.4890\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4244 - val_accuracy: 0.7620 - val_loss: 0.4890\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4230 - val_accuracy: 0.7617 - val_loss: 0.4873\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4208 - val_accuracy: 0.7607 - val_loss: 0.4888\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4231 - val_accuracy: 0.7607 - val_loss: 0.4900\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4243 - val_accuracy: 0.7611 - val_loss: 0.4880\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4207 - val_accuracy: 0.7609 - val_loss: 0.4895\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4204 - val_accuracy: 0.7588 - val_loss: 0.4921\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4237 - val_accuracy: 0.7630 - val_loss: 0.4877\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.4158 - val_accuracy: 0.7623 - val_loss: 0.4893\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4211 - val_accuracy: 0.7610 - val_loss: 0.4887\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4194 - val_accuracy: 0.7613 - val_loss: 0.4907\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4194 - val_accuracy: 0.7630 - val_loss: 0.4877\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4193 - val_accuracy: 0.7635 - val_loss: 0.4881\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4178 - val_accuracy: 0.7622 - val_loss: 0.4899\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4202 - val_accuracy: 0.7617 - val_loss: 0.4900\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4225 - val_accuracy: 0.7600 - val_loss: 0.4925\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4194 - val_accuracy: 0.7631 - val_loss: 0.4905\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4158 - val_accuracy: 0.7652 - val_loss: 0.4897\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4168 - val_accuracy: 0.7623 - val_loss: 0.4932\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4180 - val_accuracy: 0.7620 - val_loss: 0.4922\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4179 - val_accuracy: 0.7636 - val_loss: 0.4886\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4184 - val_accuracy: 0.7601 - val_loss: 0.4923\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4173 - val_accuracy: 0.7611 - val_loss: 0.4913\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4191 - val_accuracy: 0.7636 - val_loss: 0.4897\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.4170 - val_accuracy: 0.7604 - val_loss: 0.4902\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4162 - val_accuracy: 0.7630 - val_loss: 0.4914\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.4164 - val_accuracy: 0.7620 - val_loss: 0.4910\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4159 - val_accuracy: 0.7624 - val_loss: 0.4906\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4169 - val_accuracy: 0.7624 - val_loss: 0.4906\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4170 - val_accuracy: 0.7621 - val_loss: 0.4901\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4135 - val_accuracy: 0.7590 - val_loss: 0.4926\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.4136 - val_accuracy: 0.7630 - val_loss: 0.4922\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4193 - val_accuracy: 0.7610 - val_loss: 0.4917\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4155 - val_accuracy: 0.7626 - val_loss: 0.4899\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4131 - val_accuracy: 0.7636 - val_loss: 0.4905\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4165 - val_accuracy: 0.7622 - val_loss: 0.4914\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4134 - val_accuracy: 0.7635 - val_loss: 0.4910\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4120 - val_accuracy: 0.7635 - val_loss: 0.4895\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4143 - val_accuracy: 0.7629 - val_loss: 0.4916\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4111 - val_accuracy: 0.7624 - val_loss: 0.4905\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4122 - val_accuracy: 0.7609 - val_loss: 0.4941\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4145 - val_accuracy: 0.7621 - val_loss: 0.4919\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4124 - val_accuracy: 0.7633 - val_loss: 0.4918\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4107 - val_accuracy: 0.7626 - val_loss: 0.4926\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4160 - val_accuracy: 0.7625 - val_loss: 0.4932\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4131 - val_accuracy: 0.7632 - val_loss: 0.4931\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4131 - val_accuracy: 0.7603 - val_loss: 0.4969\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4124 - val_accuracy: 0.7612 - val_loss: 0.4930\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4157 - val_accuracy: 0.7653 - val_loss: 0.4902\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 7/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.5098 - val_accuracy: 0.7598 - val_loss: 0.4838\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.4913 - val_accuracy: 0.7616 - val_loss: 0.4807\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.4821 - val_accuracy: 0.7624 - val_loss: 0.4781\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.4767 - val_accuracy: 0.7614 - val_loss: 0.4775\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7649 - loss: 0.4749 - val_accuracy: 0.7600 - val_loss: 0.4779\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 0.4685 - val_accuracy: 0.7628 - val_loss: 0.4776\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7691 - loss: 0.4663 - val_accuracy: 0.7626 - val_loss: 0.4776\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.4638 - val_accuracy: 0.7607 - val_loss: 0.4769\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7710 - loss: 0.4621 - val_accuracy: 0.7653 - val_loss: 0.4760\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.4619 - val_accuracy: 0.7640 - val_loss: 0.4753\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4621 - val_accuracy: 0.7648 - val_loss: 0.4758\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4567 - val_accuracy: 0.7633 - val_loss: 0.4766\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.4581 - val_accuracy: 0.7632 - val_loss: 0.4752\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7751 - loss: 0.4559 - val_accuracy: 0.7644 - val_loss: 0.4774\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4552 - val_accuracy: 0.7630 - val_loss: 0.4781\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.4505 - val_accuracy: 0.7616 - val_loss: 0.4780\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.4514 - val_accuracy: 0.7625 - val_loss: 0.4781\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4521 - val_accuracy: 0.7631 - val_loss: 0.4769\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4488 - val_accuracy: 0.7637 - val_loss: 0.4786\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4455 - val_accuracy: 0.7618 - val_loss: 0.4793\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4457 - val_accuracy: 0.7649 - val_loss: 0.4783\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.4452 - val_accuracy: 0.7616 - val_loss: 0.4819\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.4456 - val_accuracy: 0.7619 - val_loss: 0.4821\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.4433 - val_accuracy: 0.7643 - val_loss: 0.4805\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4427 - val_accuracy: 0.7613 - val_loss: 0.4808\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7862 - loss: 0.4389 - val_accuracy: 0.7627 - val_loss: 0.4802\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4428 - val_accuracy: 0.7624 - val_loss: 0.4811\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.4396 - val_accuracy: 0.7626 - val_loss: 0.4807\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4390 - val_accuracy: 0.7614 - val_loss: 0.4832\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4368 - val_accuracy: 0.7635 - val_loss: 0.4830\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.4378 - val_accuracy: 0.7636 - val_loss: 0.4819\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4362 - val_accuracy: 0.7618 - val_loss: 0.4842\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.4351 - val_accuracy: 0.7626 - val_loss: 0.4838\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4392 - val_accuracy: 0.7642 - val_loss: 0.4819\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4350 - val_accuracy: 0.7643 - val_loss: 0.4841\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4357 - val_accuracy: 0.7632 - val_loss: 0.4834\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4305 - val_accuracy: 0.7636 - val_loss: 0.4835\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4321 - val_accuracy: 0.7623 - val_loss: 0.4843\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4333 - val_accuracy: 0.7638 - val_loss: 0.4831\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4316 - val_accuracy: 0.7646 - val_loss: 0.4839\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4314 - val_accuracy: 0.7644 - val_loss: 0.4838\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4332 - val_accuracy: 0.7625 - val_loss: 0.4851\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.4306 - val_accuracy: 0.7636 - val_loss: 0.4851\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4340 - val_accuracy: 0.7649 - val_loss: 0.4823\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4287 - val_accuracy: 0.7637 - val_loss: 0.4846\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4273 - val_accuracy: 0.7648 - val_loss: 0.4828\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4281 - val_accuracy: 0.7668 - val_loss: 0.4828\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4271 - val_accuracy: 0.7641 - val_loss: 0.4835\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4254 - val_accuracy: 0.7649 - val_loss: 0.4846\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4260 - val_accuracy: 0.7652 - val_loss: 0.4844\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4272 - val_accuracy: 0.7652 - val_loss: 0.4850\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4262 - val_accuracy: 0.7676 - val_loss: 0.4833\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.4238 - val_accuracy: 0.7636 - val_loss: 0.4850\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4273 - val_accuracy: 0.7634 - val_loss: 0.4864\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4258 - val_accuracy: 0.7660 - val_loss: 0.4847\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4262 - val_accuracy: 0.7651 - val_loss: 0.4828\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4207 - val_accuracy: 0.7664 - val_loss: 0.4842\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4253 - val_accuracy: 0.7652 - val_loss: 0.4855\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4233 - val_accuracy: 0.7623 - val_loss: 0.4874\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4238 - val_accuracy: 0.7632 - val_loss: 0.4860\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4226 - val_accuracy: 0.7659 - val_loss: 0.4857\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4230 - val_accuracy: 0.7648 - val_loss: 0.4843\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4224 - val_accuracy: 0.7626 - val_loss: 0.4883\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4216 - val_accuracy: 0.7658 - val_loss: 0.4859\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4211 - val_accuracy: 0.7639 - val_loss: 0.4857\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4197 - val_accuracy: 0.7639 - val_loss: 0.4861\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4234 - val_accuracy: 0.7658 - val_loss: 0.4852\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.4194 - val_accuracy: 0.7634 - val_loss: 0.4888\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4209 - val_accuracy: 0.7637 - val_loss: 0.4869\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4205 - val_accuracy: 0.7660 - val_loss: 0.4876\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4203 - val_accuracy: 0.7666 - val_loss: 0.4874\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4202 - val_accuracy: 0.7646 - val_loss: 0.4874\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4174 - val_accuracy: 0.7624 - val_loss: 0.4882\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.4197 - val_accuracy: 0.7666 - val_loss: 0.4863\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4178 - val_accuracy: 0.7655 - val_loss: 0.4882\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4162 - val_accuracy: 0.7661 - val_loss: 0.4885\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4190 - val_accuracy: 0.7632 - val_loss: 0.4894\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4177 - val_accuracy: 0.7649 - val_loss: 0.4864\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.4144 - val_accuracy: 0.7643 - val_loss: 0.4878\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4137 - val_accuracy: 0.7652 - val_loss: 0.4891\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4169 - val_accuracy: 0.7622 - val_loss: 0.4891\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4161 - val_accuracy: 0.7658 - val_loss: 0.4878\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4148 - val_accuracy: 0.7667 - val_loss: 0.4874\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4181 - val_accuracy: 0.7652 - val_loss: 0.4881\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4159 - val_accuracy: 0.7648 - val_loss: 0.4895\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4123 - val_accuracy: 0.7649 - val_loss: 0.4877\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4137 - val_accuracy: 0.7643 - val_loss: 0.4884\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.4135 - val_accuracy: 0.7644 - val_loss: 0.4896\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4140 - val_accuracy: 0.7655 - val_loss: 0.4870\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4144 - val_accuracy: 0.7661 - val_loss: 0.4891\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4112 - val_accuracy: 0.7641 - val_loss: 0.4907\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4124 - val_accuracy: 0.7639 - val_loss: 0.4883\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.4141 - val_accuracy: 0.7663 - val_loss: 0.4905\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4139 - val_accuracy: 0.7651 - val_loss: 0.4883\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4165 - val_accuracy: 0.7660 - val_loss: 0.4886\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4114 - val_accuracy: 0.7658 - val_loss: 0.4892\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4156 - val_accuracy: 0.7660 - val_loss: 0.4898\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4127 - val_accuracy: 0.7654 - val_loss: 0.4907\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4125 - val_accuracy: 0.7655 - val_loss: 0.4887\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4121 - val_accuracy: 0.7672 - val_loss: 0.4897\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4127 - val_accuracy: 0.7657 - val_loss: 0.4886\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4093 - val_accuracy: 0.7646 - val_loss: 0.4910\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4129 - val_accuracy: 0.7657 - val_loss: 0.4904\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4126 - val_accuracy: 0.7664 - val_loss: 0.4923\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4072 - val_accuracy: 0.7648 - val_loss: 0.4924\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4103 - val_accuracy: 0.7658 - val_loss: 0.4918\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4144 - val_accuracy: 0.7659 - val_loss: 0.4896\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4115 - val_accuracy: 0.7650 - val_loss: 0.4903\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4089 - val_accuracy: 0.7657 - val_loss: 0.4891\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4086 - val_accuracy: 0.7675 - val_loss: 0.4918\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4112 - val_accuracy: 0.7661 - val_loss: 0.4916\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4103 - val_accuracy: 0.7682 - val_loss: 0.4893\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4089 - val_accuracy: 0.7665 - val_loss: 0.4917\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4096 - val_accuracy: 0.7652 - val_loss: 0.4922\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4116 - val_accuracy: 0.7662 - val_loss: 0.4931\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4096 - val_accuracy: 0.7671 - val_loss: 0.4906\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4093 - val_accuracy: 0.7668 - val_loss: 0.4920\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4110 - val_accuracy: 0.7668 - val_loss: 0.4932\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4082 - val_accuracy: 0.7673 - val_loss: 0.4933\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4098 - val_accuracy: 0.7654 - val_loss: 0.4913\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 8/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7537 - loss: 0.5063 - val_accuracy: 0.7636 - val_loss: 0.4811\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4868 - val_accuracy: 0.7652 - val_loss: 0.4786\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.4809 - val_accuracy: 0.7668 - val_loss: 0.4754\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.4703 - val_accuracy: 0.7665 - val_loss: 0.4735\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.4710 - val_accuracy: 0.7673 - val_loss: 0.4740\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4654 - val_accuracy: 0.7659 - val_loss: 0.4733\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.4616 - val_accuracy: 0.7668 - val_loss: 0.4724\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4605 - val_accuracy: 0.7652 - val_loss: 0.4731\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4594 - val_accuracy: 0.7661 - val_loss: 0.4714\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4562 - val_accuracy: 0.7649 - val_loss: 0.4725\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4583 - val_accuracy: 0.7652 - val_loss: 0.4734\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.4555 - val_accuracy: 0.7658 - val_loss: 0.4731\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7792 - loss: 0.4507 - val_accuracy: 0.7649 - val_loss: 0.4722\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.4536 - val_accuracy: 0.7672 - val_loss: 0.4725\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4503 - val_accuracy: 0.7675 - val_loss: 0.4731\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4503 - val_accuracy: 0.7657 - val_loss: 0.4737\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.4501 - val_accuracy: 0.7664 - val_loss: 0.4737\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4445 - val_accuracy: 0.7686 - val_loss: 0.4738\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4460 - val_accuracy: 0.7663 - val_loss: 0.4732\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4432 - val_accuracy: 0.7670 - val_loss: 0.4735\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.4424 - val_accuracy: 0.7659 - val_loss: 0.4725\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4391 - val_accuracy: 0.7676 - val_loss: 0.4748\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4441 - val_accuracy: 0.7650 - val_loss: 0.4773\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4403 - val_accuracy: 0.7676 - val_loss: 0.4731\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.4378 - val_accuracy: 0.7671 - val_loss: 0.4748\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.4382 - val_accuracy: 0.7673 - val_loss: 0.4742\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4370 - val_accuracy: 0.7660 - val_loss: 0.4744\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4366 - val_accuracy: 0.7664 - val_loss: 0.4744\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4358 - val_accuracy: 0.7681 - val_loss: 0.4742\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4375 - val_accuracy: 0.7648 - val_loss: 0.4757\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4324 - val_accuracy: 0.7656 - val_loss: 0.4756\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4332 - val_accuracy: 0.7661 - val_loss: 0.4768\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4328 - val_accuracy: 0.7667 - val_loss: 0.4747\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4370 - val_accuracy: 0.7658 - val_loss: 0.4783\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4331 - val_accuracy: 0.7679 - val_loss: 0.4758\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4345 - val_accuracy: 0.7667 - val_loss: 0.4757\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4315 - val_accuracy: 0.7644 - val_loss: 0.4785\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4294 - val_accuracy: 0.7657 - val_loss: 0.4768\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4322 - val_accuracy: 0.7642 - val_loss: 0.4774\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4300 - val_accuracy: 0.7663 - val_loss: 0.4762\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4290 - val_accuracy: 0.7660 - val_loss: 0.4778\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4268 - val_accuracy: 0.7674 - val_loss: 0.4770\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4289 - val_accuracy: 0.7644 - val_loss: 0.4802\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4280 - val_accuracy: 0.7650 - val_loss: 0.4780\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4261 - val_accuracy: 0.7673 - val_loss: 0.4771\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4277 - val_accuracy: 0.7642 - val_loss: 0.4799\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4258 - val_accuracy: 0.7666 - val_loss: 0.4784\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4262 - val_accuracy: 0.7674 - val_loss: 0.4778\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4267 - val_accuracy: 0.7660 - val_loss: 0.4788\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4253 - val_accuracy: 0.7652 - val_loss: 0.4824\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.4258 - val_accuracy: 0.7647 - val_loss: 0.4789\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4226 - val_accuracy: 0.7659 - val_loss: 0.4821\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4232 - val_accuracy: 0.7689 - val_loss: 0.4778\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4226 - val_accuracy: 0.7669 - val_loss: 0.4790\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4201 - val_accuracy: 0.7663 - val_loss: 0.4817\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4223 - val_accuracy: 0.7684 - val_loss: 0.4806\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4227 - val_accuracy: 0.7671 - val_loss: 0.4818\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4202 - val_accuracy: 0.7655 - val_loss: 0.4814\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4197 - val_accuracy: 0.7661 - val_loss: 0.4801\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.4216 - val_accuracy: 0.7665 - val_loss: 0.4814\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4229 - val_accuracy: 0.7650 - val_loss: 0.4828\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4217 - val_accuracy: 0.7658 - val_loss: 0.4800\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4217 - val_accuracy: 0.7662 - val_loss: 0.4803\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4175 - val_accuracy: 0.7645 - val_loss: 0.4807\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4183 - val_accuracy: 0.7689 - val_loss: 0.4797\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4178 - val_accuracy: 0.7672 - val_loss: 0.4832\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4176 - val_accuracy: 0.7679 - val_loss: 0.4809\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4220 - val_accuracy: 0.7667 - val_loss: 0.4824\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4187 - val_accuracy: 0.7678 - val_loss: 0.4815\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4166 - val_accuracy: 0.7689 - val_loss: 0.4828\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4150 - val_accuracy: 0.7671 - val_loss: 0.4824\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4190 - val_accuracy: 0.7691 - val_loss: 0.4827\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4181 - val_accuracy: 0.7658 - val_loss: 0.4844\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4204 - val_accuracy: 0.7674 - val_loss: 0.4836\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4132 - val_accuracy: 0.7666 - val_loss: 0.4834\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4166 - val_accuracy: 0.7682 - val_loss: 0.4820\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4160 - val_accuracy: 0.7680 - val_loss: 0.4828\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4146 - val_accuracy: 0.7659 - val_loss: 0.4839\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4160 - val_accuracy: 0.7678 - val_loss: 0.4844\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4111 - val_accuracy: 0.7693 - val_loss: 0.4816\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4131 - val_accuracy: 0.7684 - val_loss: 0.4836\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4126 - val_accuracy: 0.7666 - val_loss: 0.4833\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4172 - val_accuracy: 0.7663 - val_loss: 0.4858\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4150 - val_accuracy: 0.7679 - val_loss: 0.4834\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4145 - val_accuracy: 0.7664 - val_loss: 0.4855\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4119 - val_accuracy: 0.7680 - val_loss: 0.4850\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4131 - val_accuracy: 0.7699 - val_loss: 0.4835\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4129 - val_accuracy: 0.7679 - val_loss: 0.4833\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4129 - val_accuracy: 0.7687 - val_loss: 0.4839\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4123 - val_accuracy: 0.7670 - val_loss: 0.4868\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4129 - val_accuracy: 0.7665 - val_loss: 0.4862\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.4101 - val_accuracy: 0.7669 - val_loss: 0.4852\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4138 - val_accuracy: 0.7662 - val_loss: 0.4844\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4120 - val_accuracy: 0.7657 - val_loss: 0.4853\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4122 - val_accuracy: 0.7679 - val_loss: 0.4848\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4108 - val_accuracy: 0.7670 - val_loss: 0.4862\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4104 - val_accuracy: 0.7675 - val_loss: 0.4847\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4129 - val_accuracy: 0.7682 - val_loss: 0.4860\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4129 - val_accuracy: 0.7675 - val_loss: 0.4846\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4116 - val_accuracy: 0.7675 - val_loss: 0.4861\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4098 - val_accuracy: 0.7683 - val_loss: 0.4851\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4083 - val_accuracy: 0.7692 - val_loss: 0.4852\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4064 - val_accuracy: 0.7690 - val_loss: 0.4848\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4102 - val_accuracy: 0.7668 - val_loss: 0.4851\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4098 - val_accuracy: 0.7691 - val_loss: 0.4852\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4107 - val_accuracy: 0.7688 - val_loss: 0.4860\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4080 - val_accuracy: 0.7681 - val_loss: 0.4862\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4103 - val_accuracy: 0.7669 - val_loss: 0.4878\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4075 - val_accuracy: 0.7682 - val_loss: 0.4855\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.4082 - val_accuracy: 0.7671 - val_loss: 0.4850\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4085 - val_accuracy: 0.7682 - val_loss: 0.4853\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4093 - val_accuracy: 0.7677 - val_loss: 0.4856\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4065 - val_accuracy: 0.7676 - val_loss: 0.4856\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4102 - val_accuracy: 0.7669 - val_loss: 0.4863\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4070 - val_accuracy: 0.7678 - val_loss: 0.4864\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4035 - val_accuracy: 0.7695 - val_loss: 0.4838\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4062 - val_accuracy: 0.7675 - val_loss: 0.4876\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4069 - val_accuracy: 0.7668 - val_loss: 0.4870\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4080 - val_accuracy: 0.7685 - val_loss: 0.4859\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4077 - val_accuracy: 0.7664 - val_loss: 0.4860\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 9/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7532 - loss: 0.5096 - val_accuracy: 0.7669 - val_loss: 0.4786\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.4881 - val_accuracy: 0.7673 - val_loss: 0.4756\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7679 - loss: 0.4714 - val_accuracy: 0.7677 - val_loss: 0.4735\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4690 - val_accuracy: 0.7654 - val_loss: 0.4746\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4663 - val_accuracy: 0.7669 - val_loss: 0.4730\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4650 - val_accuracy: 0.7678 - val_loss: 0.4719\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7742 - loss: 0.4629 - val_accuracy: 0.7654 - val_loss: 0.4729\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4603 - val_accuracy: 0.7678 - val_loss: 0.4725\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.4573 - val_accuracy: 0.7668 - val_loss: 0.4718\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4562 - val_accuracy: 0.7692 - val_loss: 0.4718\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4536 - val_accuracy: 0.7685 - val_loss: 0.4717\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4548 - val_accuracy: 0.7669 - val_loss: 0.4727\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4527 - val_accuracy: 0.7697 - val_loss: 0.4718\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7807 - loss: 0.4500 - val_accuracy: 0.7669 - val_loss: 0.4716\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.4477 - val_accuracy: 0.7657 - val_loss: 0.4729\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4493 - val_accuracy: 0.7670 - val_loss: 0.4720\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4445 - val_accuracy: 0.7656 - val_loss: 0.4734\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4460 - val_accuracy: 0.7689 - val_loss: 0.4724\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4448 - val_accuracy: 0.7670 - val_loss: 0.4719\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4418 - val_accuracy: 0.7682 - val_loss: 0.4735\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4421 - val_accuracy: 0.7672 - val_loss: 0.4735\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4407 - val_accuracy: 0.7672 - val_loss: 0.4744\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.4397 - val_accuracy: 0.7687 - val_loss: 0.4734\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4407 - val_accuracy: 0.7670 - val_loss: 0.4744\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4391 - val_accuracy: 0.7675 - val_loss: 0.4729\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.4381 - val_accuracy: 0.7683 - val_loss: 0.4730\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.4384 - val_accuracy: 0.7695 - val_loss: 0.4718\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.4370 - val_accuracy: 0.7691 - val_loss: 0.4723\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.4358 - val_accuracy: 0.7673 - val_loss: 0.4754\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7905 - loss: 0.4348 - val_accuracy: 0.7669 - val_loss: 0.4731\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4305 - val_accuracy: 0.7671 - val_loss: 0.4748\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.4327 - val_accuracy: 0.7666 - val_loss: 0.4752\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4312 - val_accuracy: 0.7664 - val_loss: 0.4759\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4299 - val_accuracy: 0.7663 - val_loss: 0.4751\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.4341 - val_accuracy: 0.7667 - val_loss: 0.4749\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4315 - val_accuracy: 0.7678 - val_loss: 0.4740\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4306 - val_accuracy: 0.7681 - val_loss: 0.4760\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4327 - val_accuracy: 0.7680 - val_loss: 0.4755\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.4254 - val_accuracy: 0.7673 - val_loss: 0.4744\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4298 - val_accuracy: 0.7675 - val_loss: 0.4754\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4288 - val_accuracy: 0.7689 - val_loss: 0.4746\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4268 - val_accuracy: 0.7691 - val_loss: 0.4743\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4287 - val_accuracy: 0.7692 - val_loss: 0.4753\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4251 - val_accuracy: 0.7685 - val_loss: 0.4765\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4270 - val_accuracy: 0.7677 - val_loss: 0.4752\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4260 - val_accuracy: 0.7673 - val_loss: 0.4774\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4240 - val_accuracy: 0.7679 - val_loss: 0.4750\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4232 - val_accuracy: 0.7684 - val_loss: 0.4762\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4261 - val_accuracy: 0.7695 - val_loss: 0.4756\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.4261 - val_accuracy: 0.7679 - val_loss: 0.4769\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4227 - val_accuracy: 0.7684 - val_loss: 0.4749\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4252 - val_accuracy: 0.7679 - val_loss: 0.4778\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4268 - val_accuracy: 0.7663 - val_loss: 0.4775\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.4239 - val_accuracy: 0.7691 - val_loss: 0.4779\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4233 - val_accuracy: 0.7681 - val_loss: 0.4769\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4202 - val_accuracy: 0.7676 - val_loss: 0.4760\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4174 - val_accuracy: 0.7671 - val_loss: 0.4771\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4217 - val_accuracy: 0.7702 - val_loss: 0.4759\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4225 - val_accuracy: 0.7681 - val_loss: 0.4775\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4199 - val_accuracy: 0.7668 - val_loss: 0.4786\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4176 - val_accuracy: 0.7669 - val_loss: 0.4773\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4211 - val_accuracy: 0.7688 - val_loss: 0.4756\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4208 - val_accuracy: 0.7697 - val_loss: 0.4759\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4179 - val_accuracy: 0.7666 - val_loss: 0.4767\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4167 - val_accuracy: 0.7664 - val_loss: 0.4770\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.4170 - val_accuracy: 0.7703 - val_loss: 0.4765\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4174 - val_accuracy: 0.7692 - val_loss: 0.4776\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4178 - val_accuracy: 0.7693 - val_loss: 0.4773\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4168 - val_accuracy: 0.7711 - val_loss: 0.4753\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4178 - val_accuracy: 0.7690 - val_loss: 0.4782\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4153 - val_accuracy: 0.7690 - val_loss: 0.4776\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4181 - val_accuracy: 0.7698 - val_loss: 0.4782\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4151 - val_accuracy: 0.7716 - val_loss: 0.4751\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4162 - val_accuracy: 0.7691 - val_loss: 0.4784\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4145 - val_accuracy: 0.7688 - val_loss: 0.4777\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.4161 - val_accuracy: 0.7692 - val_loss: 0.4774\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4120 - val_accuracy: 0.7656 - val_loss: 0.4794\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4147 - val_accuracy: 0.7690 - val_loss: 0.4776\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4172 - val_accuracy: 0.7683 - val_loss: 0.4779\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4178 - val_accuracy: 0.7702 - val_loss: 0.4793\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4121 - val_accuracy: 0.7718 - val_loss: 0.4776\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4119 - val_accuracy: 0.7679 - val_loss: 0.4797\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4121 - val_accuracy: 0.7697 - val_loss: 0.4790\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.4128 - val_accuracy: 0.7710 - val_loss: 0.4779\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4116 - val_accuracy: 0.7678 - val_loss: 0.4810\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4120 - val_accuracy: 0.7692 - val_loss: 0.4792\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4143 - val_accuracy: 0.7696 - val_loss: 0.4772\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4117 - val_accuracy: 0.7703 - val_loss: 0.4787\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4143 - val_accuracy: 0.7683 - val_loss: 0.4787\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4099 - val_accuracy: 0.7705 - val_loss: 0.4802\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4114 - val_accuracy: 0.7688 - val_loss: 0.4794\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4113 - val_accuracy: 0.7706 - val_loss: 0.4787\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4098 - val_accuracy: 0.7679 - val_loss: 0.4814\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4112 - val_accuracy: 0.7678 - val_loss: 0.4801\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.4120 - val_accuracy: 0.7680 - val_loss: 0.4829\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4119 - val_accuracy: 0.7675 - val_loss: 0.4808\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4095 - val_accuracy: 0.7688 - val_loss: 0.4790\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4119 - val_accuracy: 0.7679 - val_loss: 0.4817\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4102 - val_accuracy: 0.7687 - val_loss: 0.4802\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4119 - val_accuracy: 0.7696 - val_loss: 0.4798\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4088 - val_accuracy: 0.7712 - val_loss: 0.4788\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4088 - val_accuracy: 0.7683 - val_loss: 0.4777\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4074 - val_accuracy: 0.7706 - val_loss: 0.4792\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4104 - val_accuracy: 0.7680 - val_loss: 0.4789\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4102 - val_accuracy: 0.7708 - val_loss: 0.4794\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4107 - val_accuracy: 0.7701 - val_loss: 0.4783\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4120 - val_accuracy: 0.7703 - val_loss: 0.4802\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4091 - val_accuracy: 0.7685 - val_loss: 0.4792\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4063 - val_accuracy: 0.7699 - val_loss: 0.4798\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4064 - val_accuracy: 0.7693 - val_loss: 0.4801\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4080 - val_accuracy: 0.7702 - val_loss: 0.4793\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4091 - val_accuracy: 0.7706 - val_loss: 0.4794\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.4084 - val_accuracy: 0.7705 - val_loss: 0.4794\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4066 - val_accuracy: 0.7703 - val_loss: 0.4816\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4045 - val_accuracy: 0.7709 - val_loss: 0.4791\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4068 - val_accuracy: 0.7700 - val_loss: 0.4819\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4077 - val_accuracy: 0.7715 - val_loss: 0.4805\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4044 - val_accuracy: 0.7713 - val_loss: 0.4799\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.4067 - val_accuracy: 0.7698 - val_loss: 0.4808\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4075 - val_accuracy: 0.7701 - val_loss: 0.4806\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 10/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.5036 - val_accuracy: 0.7689 - val_loss: 0.4712\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 0.4820 - val_accuracy: 0.7703 - val_loss: 0.4675\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7682 - loss: 0.4728 - val_accuracy: 0.7716 - val_loss: 0.4659\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.4674 - val_accuracy: 0.7724 - val_loss: 0.4643\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.4637 - val_accuracy: 0.7711 - val_loss: 0.4650\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4599 - val_accuracy: 0.7713 - val_loss: 0.4640\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4607 - val_accuracy: 0.7706 - val_loss: 0.4639\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4554 - val_accuracy: 0.7699 - val_loss: 0.4634\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4557 - val_accuracy: 0.7726 - val_loss: 0.4634\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4548 - val_accuracy: 0.7738 - val_loss: 0.4621\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.4527 - val_accuracy: 0.7712 - val_loss: 0.4648\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4454 - val_accuracy: 0.7729 - val_loss: 0.4644\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.4497 - val_accuracy: 0.7724 - val_loss: 0.4661\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.4446 - val_accuracy: 0.7739 - val_loss: 0.4642\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4462 - val_accuracy: 0.7714 - val_loss: 0.4658\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7855 - loss: 0.4420 - val_accuracy: 0.7709 - val_loss: 0.4655\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 0.4413 - val_accuracy: 0.7704 - val_loss: 0.4649\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4416 - val_accuracy: 0.7708 - val_loss: 0.4680\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4400 - val_accuracy: 0.7740 - val_loss: 0.4652\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4414 - val_accuracy: 0.7698 - val_loss: 0.4660\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4391 - val_accuracy: 0.7704 - val_loss: 0.4674\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4395 - val_accuracy: 0.7717 - val_loss: 0.4663\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.4367 - val_accuracy: 0.7710 - val_loss: 0.4690\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4335 - val_accuracy: 0.7722 - val_loss: 0.4680\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.4378 - val_accuracy: 0.7718 - val_loss: 0.4687\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.4343 - val_accuracy: 0.7727 - val_loss: 0.4687\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4328 - val_accuracy: 0.7703 - val_loss: 0.4699\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4335 - val_accuracy: 0.7746 - val_loss: 0.4658\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7906 - loss: 0.4329 - val_accuracy: 0.7733 - val_loss: 0.4686\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4318 - val_accuracy: 0.7733 - val_loss: 0.4673\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4284 - val_accuracy: 0.7715 - val_loss: 0.4672\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4285 - val_accuracy: 0.7716 - val_loss: 0.4694\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 0.4314 - val_accuracy: 0.7718 - val_loss: 0.4695\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4290 - val_accuracy: 0.7723 - val_loss: 0.4682\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4285 - val_accuracy: 0.7713 - val_loss: 0.4693\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4277 - val_accuracy: 0.7697 - val_loss: 0.4714\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4264 - val_accuracy: 0.7708 - val_loss: 0.4698\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4261 - val_accuracy: 0.7724 - val_loss: 0.4706\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.4269 - val_accuracy: 0.7709 - val_loss: 0.4704\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.4267 - val_accuracy: 0.7719 - val_loss: 0.4715\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4251 - val_accuracy: 0.7704 - val_loss: 0.4721\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4244 - val_accuracy: 0.7703 - val_loss: 0.4711\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4216 - val_accuracy: 0.7713 - val_loss: 0.4715\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4228 - val_accuracy: 0.7715 - val_loss: 0.4718\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4188 - val_accuracy: 0.7704 - val_loss: 0.4729\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4211 - val_accuracy: 0.7730 - val_loss: 0.4734\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4208 - val_accuracy: 0.7710 - val_loss: 0.4735\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4198 - val_accuracy: 0.7691 - val_loss: 0.4728\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4198 - val_accuracy: 0.7721 - val_loss: 0.4731\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4206 - val_accuracy: 0.7733 - val_loss: 0.4737\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4212 - val_accuracy: 0.7709 - val_loss: 0.4726\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4204 - val_accuracy: 0.7705 - val_loss: 0.4763\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4186 - val_accuracy: 0.7702 - val_loss: 0.4744\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4176 - val_accuracy: 0.7697 - val_loss: 0.4747\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4185 - val_accuracy: 0.7733 - val_loss: 0.4736\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4156 - val_accuracy: 0.7721 - val_loss: 0.4745\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4147 - val_accuracy: 0.7694 - val_loss: 0.4763\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4167 - val_accuracy: 0.7706 - val_loss: 0.4740\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4204 - val_accuracy: 0.7721 - val_loss: 0.4727\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4172 - val_accuracy: 0.7721 - val_loss: 0.4745\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4130 - val_accuracy: 0.7706 - val_loss: 0.4746\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.4155 - val_accuracy: 0.7712 - val_loss: 0.4757\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4123 - val_accuracy: 0.7716 - val_loss: 0.4747\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4135 - val_accuracy: 0.7707 - val_loss: 0.4760\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.4132 - val_accuracy: 0.7718 - val_loss: 0.4763\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4158 - val_accuracy: 0.7719 - val_loss: 0.4753\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4151 - val_accuracy: 0.7712 - val_loss: 0.4745\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4137 - val_accuracy: 0.7705 - val_loss: 0.4767\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4121 - val_accuracy: 0.7681 - val_loss: 0.4757\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4127 - val_accuracy: 0.7727 - val_loss: 0.4749\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4130 - val_accuracy: 0.7703 - val_loss: 0.4781\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4107 - val_accuracy: 0.7702 - val_loss: 0.4764\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4128 - val_accuracy: 0.7704 - val_loss: 0.4749\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4115 - val_accuracy: 0.7696 - val_loss: 0.4770\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4147 - val_accuracy: 0.7726 - val_loss: 0.4755\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4114 - val_accuracy: 0.7714 - val_loss: 0.4754\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4107 - val_accuracy: 0.7703 - val_loss: 0.4772\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4112 - val_accuracy: 0.7707 - val_loss: 0.4772\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4102 - val_accuracy: 0.7717 - val_loss: 0.4770\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.4083 - val_accuracy: 0.7706 - val_loss: 0.4754\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4106 - val_accuracy: 0.7709 - val_loss: 0.4790\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4123 - val_accuracy: 0.7699 - val_loss: 0.4774\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4090 - val_accuracy: 0.7692 - val_loss: 0.4789\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4083 - val_accuracy: 0.7717 - val_loss: 0.4777\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4109 - val_accuracy: 0.7721 - val_loss: 0.4777\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4084 - val_accuracy: 0.7707 - val_loss: 0.4794\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4061 - val_accuracy: 0.7694 - val_loss: 0.4796\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4076 - val_accuracy: 0.7707 - val_loss: 0.4776\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4069 - val_accuracy: 0.7723 - val_loss: 0.4799\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4080 - val_accuracy: 0.7713 - val_loss: 0.4801\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4062 - val_accuracy: 0.7721 - val_loss: 0.4792\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4047 - val_accuracy: 0.7711 - val_loss: 0.4815\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4046 - val_accuracy: 0.7703 - val_loss: 0.4795\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4050 - val_accuracy: 0.7719 - val_loss: 0.4811\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4060 - val_accuracy: 0.7705 - val_loss: 0.4801\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.4039 - val_accuracy: 0.7722 - val_loss: 0.4799\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4077 - val_accuracy: 0.7725 - val_loss: 0.4800\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4044 - val_accuracy: 0.7702 - val_loss: 0.4809\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4045 - val_accuracy: 0.7702 - val_loss: 0.4827\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.4036 - val_accuracy: 0.7692 - val_loss: 0.4838\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4039 - val_accuracy: 0.7713 - val_loss: 0.4806\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4044 - val_accuracy: 0.7713 - val_loss: 0.4800\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4031 - val_accuracy: 0.7701 - val_loss: 0.4796\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4036 - val_accuracy: 0.7707 - val_loss: 0.4815\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4057 - val_accuracy: 0.7706 - val_loss: 0.4839\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4067 - val_accuracy: 0.7698 - val_loss: 0.4820\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4028 - val_accuracy: 0.7707 - val_loss: 0.4812\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.4046 - val_accuracy: 0.7712 - val_loss: 0.4800\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4025 - val_accuracy: 0.7717 - val_loss: 0.4814\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4046 - val_accuracy: 0.7715 - val_loss: 0.4821\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4017 - val_accuracy: 0.7698 - val_loss: 0.4852\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4039 - val_accuracy: 0.7721 - val_loss: 0.4817\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4033 - val_accuracy: 0.7732 - val_loss: 0.4823\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.4021 - val_accuracy: 0.7714 - val_loss: 0.4821\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4034 - val_accuracy: 0.7733 - val_loss: 0.4821\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4028 - val_accuracy: 0.7711 - val_loss: 0.4845\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4014 - val_accuracy: 0.7718 - val_loss: 0.4815\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4015 - val_accuracy: 0.7716 - val_loss: 0.4800\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.4042 - val_accuracy: 0.7708 - val_loss: 0.4833\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4007 - val_accuracy: 0.7709 - val_loss: 0.4850\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 11/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.5080 - val_accuracy: 0.7662 - val_loss: 0.4796\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4819 - val_accuracy: 0.7654 - val_loss: 0.4738\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.4726 - val_accuracy: 0.7645 - val_loss: 0.4723\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7688 - loss: 0.4681 - val_accuracy: 0.7648 - val_loss: 0.4736\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4627 - val_accuracy: 0.7693 - val_loss: 0.4702\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4605 - val_accuracy: 0.7683 - val_loss: 0.4703\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4587 - val_accuracy: 0.7653 - val_loss: 0.4715\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4557 - val_accuracy: 0.7682 - val_loss: 0.4700\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4571 - val_accuracy: 0.7667 - val_loss: 0.4705\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4506 - val_accuracy: 0.7645 - val_loss: 0.4720\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4497 - val_accuracy: 0.7661 - val_loss: 0.4707\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.4488 - val_accuracy: 0.7678 - val_loss: 0.4708\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.4465 - val_accuracy: 0.7676 - val_loss: 0.4714\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.4468 - val_accuracy: 0.7707 - val_loss: 0.4695\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.4453 - val_accuracy: 0.7679 - val_loss: 0.4703\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7832 - loss: 0.4433 - val_accuracy: 0.7684 - val_loss: 0.4710\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4438 - val_accuracy: 0.7683 - val_loss: 0.4708\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4438 - val_accuracy: 0.7678 - val_loss: 0.4714\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.4417 - val_accuracy: 0.7658 - val_loss: 0.4740\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4403 - val_accuracy: 0.7662 - val_loss: 0.4727\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.4371 - val_accuracy: 0.7669 - val_loss: 0.4721\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.4370 - val_accuracy: 0.7682 - val_loss: 0.4724\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4358 - val_accuracy: 0.7669 - val_loss: 0.4714\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.4309 - val_accuracy: 0.7681 - val_loss: 0.4735\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4348 - val_accuracy: 0.7692 - val_loss: 0.4738\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4345 - val_accuracy: 0.7680 - val_loss: 0.4738\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4336 - val_accuracy: 0.7667 - val_loss: 0.4734\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.4319 - val_accuracy: 0.7676 - val_loss: 0.4751\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.4320 - val_accuracy: 0.7694 - val_loss: 0.4734\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4287 - val_accuracy: 0.7687 - val_loss: 0.4738\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.4308 - val_accuracy: 0.7669 - val_loss: 0.4736\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4304 - val_accuracy: 0.7679 - val_loss: 0.4742\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4277 - val_accuracy: 0.7686 - val_loss: 0.4743\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4255 - val_accuracy: 0.7687 - val_loss: 0.4746\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4286 - val_accuracy: 0.7667 - val_loss: 0.4755\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4287 - val_accuracy: 0.7682 - val_loss: 0.4756\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4271 - val_accuracy: 0.7659 - val_loss: 0.4765\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4257 - val_accuracy: 0.7673 - val_loss: 0.4755\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4252 - val_accuracy: 0.7665 - val_loss: 0.4762\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4264 - val_accuracy: 0.7682 - val_loss: 0.4776\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4252 - val_accuracy: 0.7685 - val_loss: 0.4767\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4264 - val_accuracy: 0.7674 - val_loss: 0.4781\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4237 - val_accuracy: 0.7667 - val_loss: 0.4781\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4228 - val_accuracy: 0.7708 - val_loss: 0.4744\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4229 - val_accuracy: 0.7680 - val_loss: 0.4776\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4223 - val_accuracy: 0.7677 - val_loss: 0.4774\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4223 - val_accuracy: 0.7673 - val_loss: 0.4763\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4217 - val_accuracy: 0.7691 - val_loss: 0.4776\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.4211 - val_accuracy: 0.7692 - val_loss: 0.4786\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4232 - val_accuracy: 0.7682 - val_loss: 0.4760\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4212 - val_accuracy: 0.7684 - val_loss: 0.4781\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4215 - val_accuracy: 0.7689 - val_loss: 0.4786\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4159 - val_accuracy: 0.7657 - val_loss: 0.4809\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4190 - val_accuracy: 0.7675 - val_loss: 0.4791\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4180 - val_accuracy: 0.7679 - val_loss: 0.4795\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 0.4195 - val_accuracy: 0.7686 - val_loss: 0.4793\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4171 - val_accuracy: 0.7697 - val_loss: 0.4780\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4184 - val_accuracy: 0.7714 - val_loss: 0.4771\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4183 - val_accuracy: 0.7696 - val_loss: 0.4789\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4162 - val_accuracy: 0.7690 - val_loss: 0.4776\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4167 - val_accuracy: 0.7693 - val_loss: 0.4770\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4135 - val_accuracy: 0.7685 - val_loss: 0.4776\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4160 - val_accuracy: 0.7690 - val_loss: 0.4796\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4158 - val_accuracy: 0.7684 - val_loss: 0.4809\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4178 - val_accuracy: 0.7703 - val_loss: 0.4801\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4120 - val_accuracy: 0.7690 - val_loss: 0.4800\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4144 - val_accuracy: 0.7677 - val_loss: 0.4805\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4141 - val_accuracy: 0.7685 - val_loss: 0.4802\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4145 - val_accuracy: 0.7688 - val_loss: 0.4810\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4112 - val_accuracy: 0.7693 - val_loss: 0.4810\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4139 - val_accuracy: 0.7692 - val_loss: 0.4818\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4133 - val_accuracy: 0.7683 - val_loss: 0.4817\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4131 - val_accuracy: 0.7686 - val_loss: 0.4826\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.4134 - val_accuracy: 0.7686 - val_loss: 0.4828\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4132 - val_accuracy: 0.7666 - val_loss: 0.4820\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4106 - val_accuracy: 0.7693 - val_loss: 0.4831\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4123 - val_accuracy: 0.7701 - val_loss: 0.4822\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4089 - val_accuracy: 0.7717 - val_loss: 0.4829\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4140 - val_accuracy: 0.7699 - val_loss: 0.4811\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4109 - val_accuracy: 0.7686 - val_loss: 0.4817\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4087 - val_accuracy: 0.7682 - val_loss: 0.4845\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4106 - val_accuracy: 0.7672 - val_loss: 0.4852\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4112 - val_accuracy: 0.7697 - val_loss: 0.4831\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4098 - val_accuracy: 0.7678 - val_loss: 0.4828\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4141 - val_accuracy: 0.7693 - val_loss: 0.4839\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4110 - val_accuracy: 0.7678 - val_loss: 0.4838\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4104 - val_accuracy: 0.7680 - val_loss: 0.4820\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4085 - val_accuracy: 0.7712 - val_loss: 0.4841\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4122 - val_accuracy: 0.7696 - val_loss: 0.4838\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4070 - val_accuracy: 0.7681 - val_loss: 0.4863\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4107 - val_accuracy: 0.7694 - val_loss: 0.4850\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4057 - val_accuracy: 0.7682 - val_loss: 0.4845\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4067 - val_accuracy: 0.7693 - val_loss: 0.4866\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4062 - val_accuracy: 0.7690 - val_loss: 0.4862\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.4116 - val_accuracy: 0.7690 - val_loss: 0.4839\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4067 - val_accuracy: 0.7679 - val_loss: 0.4840\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4059 - val_accuracy: 0.7684 - val_loss: 0.4866\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4070 - val_accuracy: 0.7688 - val_loss: 0.4866\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4089 - val_accuracy: 0.7686 - val_loss: 0.4866\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4073 - val_accuracy: 0.7724 - val_loss: 0.4855\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.4065 - val_accuracy: 0.7700 - val_loss: 0.4861\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4097 - val_accuracy: 0.7698 - val_loss: 0.4858\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4087 - val_accuracy: 0.7698 - val_loss: 0.4842\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4067 - val_accuracy: 0.7683 - val_loss: 0.4876\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4039 - val_accuracy: 0.7686 - val_loss: 0.4846\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4062 - val_accuracy: 0.7684 - val_loss: 0.4854\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4046 - val_accuracy: 0.7693 - val_loss: 0.4854\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4075 - val_accuracy: 0.7689 - val_loss: 0.4866\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4062 - val_accuracy: 0.7703 - val_loss: 0.4856\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4091 - val_accuracy: 0.7699 - val_loss: 0.4880\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4062 - val_accuracy: 0.7662 - val_loss: 0.4881\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4042 - val_accuracy: 0.7691 - val_loss: 0.4876\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.4081 - val_accuracy: 0.7683 - val_loss: 0.4882\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4070 - val_accuracy: 0.7688 - val_loss: 0.4901\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4061 - val_accuracy: 0.7689 - val_loss: 0.4875\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4070 - val_accuracy: 0.7692 - val_loss: 0.4870\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.4026 - val_accuracy: 0.7693 - val_loss: 0.4859\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4036 - val_accuracy: 0.7669 - val_loss: 0.4860\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4042 - val_accuracy: 0.7687 - val_loss: 0.4881\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4031 - val_accuracy: 0.7690 - val_loss: 0.4865\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 12/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.5044 - val_accuracy: 0.7728 - val_loss: 0.4708\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.4839 - val_accuracy: 0.7716 - val_loss: 0.4681\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.4690 - val_accuracy: 0.7741 - val_loss: 0.4646\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4665 - val_accuracy: 0.7730 - val_loss: 0.4619\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7710 - loss: 0.4653 - val_accuracy: 0.7730 - val_loss: 0.4633\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4615 - val_accuracy: 0.7732 - val_loss: 0.4618\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7753 - loss: 0.4559 - val_accuracy: 0.7719 - val_loss: 0.4638\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4579 - val_accuracy: 0.7747 - val_loss: 0.4625\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4595 - val_accuracy: 0.7728 - val_loss: 0.4640\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.4548 - val_accuracy: 0.7755 - val_loss: 0.4622\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4533 - val_accuracy: 0.7722 - val_loss: 0.4630\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.4477 - val_accuracy: 0.7720 - val_loss: 0.4636\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4501 - val_accuracy: 0.7736 - val_loss: 0.4631\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.4467 - val_accuracy: 0.7747 - val_loss: 0.4628\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.4465 - val_accuracy: 0.7747 - val_loss: 0.4619\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.4466 - val_accuracy: 0.7742 - val_loss: 0.4615\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4476 - val_accuracy: 0.7735 - val_loss: 0.4616\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4437 - val_accuracy: 0.7730 - val_loss: 0.4633\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4425 - val_accuracy: 0.7737 - val_loss: 0.4636\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4414 - val_accuracy: 0.7716 - val_loss: 0.4629\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4408 - val_accuracy: 0.7717 - val_loss: 0.4643\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.4381 - val_accuracy: 0.7728 - val_loss: 0.4636\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.4387 - val_accuracy: 0.7725 - val_loss: 0.4635\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4386 - val_accuracy: 0.7729 - val_loss: 0.4640\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4356 - val_accuracy: 0.7739 - val_loss: 0.4636\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4364 - val_accuracy: 0.7724 - val_loss: 0.4650\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.4358 - val_accuracy: 0.7740 - val_loss: 0.4647\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4360 - val_accuracy: 0.7713 - val_loss: 0.4657\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.4328 - val_accuracy: 0.7732 - val_loss: 0.4640\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.4356 - val_accuracy: 0.7743 - val_loss: 0.4639\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4305 - val_accuracy: 0.7730 - val_loss: 0.4632\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4291 - val_accuracy: 0.7741 - val_loss: 0.4634\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4303 - val_accuracy: 0.7722 - val_loss: 0.4654\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4296 - val_accuracy: 0.7751 - val_loss: 0.4644\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4311 - val_accuracy: 0.7732 - val_loss: 0.4654\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4308 - val_accuracy: 0.7736 - val_loss: 0.4647\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4290 - val_accuracy: 0.7738 - val_loss: 0.4662\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4272 - val_accuracy: 0.7742 - val_loss: 0.4644\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4286 - val_accuracy: 0.7735 - val_loss: 0.4659\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4294 - val_accuracy: 0.7735 - val_loss: 0.4665\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4264 - val_accuracy: 0.7725 - val_loss: 0.4649\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4283 - val_accuracy: 0.7740 - val_loss: 0.4664\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4247 - val_accuracy: 0.7745 - val_loss: 0.4652\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4234 - val_accuracy: 0.7753 - val_loss: 0.4654\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4253 - val_accuracy: 0.7743 - val_loss: 0.4649\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7955 - loss: 0.4250 - val_accuracy: 0.7731 - val_loss: 0.4648\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4268 - val_accuracy: 0.7735 - val_loss: 0.4661\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4232 - val_accuracy: 0.7729 - val_loss: 0.4662\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4227 - val_accuracy: 0.7747 - val_loss: 0.4651\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4221 - val_accuracy: 0.7723 - val_loss: 0.4675\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4240 - val_accuracy: 0.7726 - val_loss: 0.4647\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4221 - val_accuracy: 0.7738 - val_loss: 0.4653\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4209 - val_accuracy: 0.7744 - val_loss: 0.4664\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4202 - val_accuracy: 0.7738 - val_loss: 0.4664\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4258 - val_accuracy: 0.7747 - val_loss: 0.4650\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4203 - val_accuracy: 0.7732 - val_loss: 0.4670\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4188 - val_accuracy: 0.7709 - val_loss: 0.4667\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4229 - val_accuracy: 0.7750 - val_loss: 0.4653\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4204 - val_accuracy: 0.7735 - val_loss: 0.4676\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4247 - val_accuracy: 0.7740 - val_loss: 0.4657\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.4209 - val_accuracy: 0.7745 - val_loss: 0.4672\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4199 - val_accuracy: 0.7741 - val_loss: 0.4671\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4210 - val_accuracy: 0.7748 - val_loss: 0.4663\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4197 - val_accuracy: 0.7730 - val_loss: 0.4689\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4193 - val_accuracy: 0.7728 - val_loss: 0.4675\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4193 - val_accuracy: 0.7734 - val_loss: 0.4675\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4171 - val_accuracy: 0.7735 - val_loss: 0.4678\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4193 - val_accuracy: 0.7746 - val_loss: 0.4674\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4189 - val_accuracy: 0.7736 - val_loss: 0.4681\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4168 - val_accuracy: 0.7744 - val_loss: 0.4690\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4157 - val_accuracy: 0.7751 - val_loss: 0.4686\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4168 - val_accuracy: 0.7739 - val_loss: 0.4679\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4174 - val_accuracy: 0.7744 - val_loss: 0.4692\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4163 - val_accuracy: 0.7726 - val_loss: 0.4692\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4167 - val_accuracy: 0.7720 - val_loss: 0.4707\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4162 - val_accuracy: 0.7732 - val_loss: 0.4693\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4170 - val_accuracy: 0.7736 - val_loss: 0.4685\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4177 - val_accuracy: 0.7757 - val_loss: 0.4685\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4156 - val_accuracy: 0.7752 - val_loss: 0.4704\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4116 - val_accuracy: 0.7722 - val_loss: 0.4715\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4148 - val_accuracy: 0.7738 - val_loss: 0.4718\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4131 - val_accuracy: 0.7746 - val_loss: 0.4697\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4127 - val_accuracy: 0.7731 - val_loss: 0.4688\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4115 - val_accuracy: 0.7742 - val_loss: 0.4697\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4116 - val_accuracy: 0.7723 - val_loss: 0.4713\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4124 - val_accuracy: 0.7724 - val_loss: 0.4699\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4121 - val_accuracy: 0.7745 - val_loss: 0.4695\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4144 - val_accuracy: 0.7748 - val_loss: 0.4689\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4123 - val_accuracy: 0.7725 - val_loss: 0.4723\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4147 - val_accuracy: 0.7743 - val_loss: 0.4703\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4104 - val_accuracy: 0.7734 - val_loss: 0.4705\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4102 - val_accuracy: 0.7743 - val_loss: 0.4688\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4117 - val_accuracy: 0.7736 - val_loss: 0.4692\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4121 - val_accuracy: 0.7728 - val_loss: 0.4706\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4105 - val_accuracy: 0.7722 - val_loss: 0.4708\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4126 - val_accuracy: 0.7732 - val_loss: 0.4697\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4115 - val_accuracy: 0.7751 - val_loss: 0.4710\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.4102 - val_accuracy: 0.7739 - val_loss: 0.4697\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4135 - val_accuracy: 0.7723 - val_loss: 0.4727\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4115 - val_accuracy: 0.7733 - val_loss: 0.4692\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.4110 - val_accuracy: 0.7729 - val_loss: 0.4729\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8059 - loss: 0.4113 - val_accuracy: 0.7747 - val_loss: 0.4714\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4088 - val_accuracy: 0.7721 - val_loss: 0.4715\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4081 - val_accuracy: 0.7733 - val_loss: 0.4715\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4080 - val_accuracy: 0.7757 - val_loss: 0.4717\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4103 - val_accuracy: 0.7741 - val_loss: 0.4718\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4104 - val_accuracy: 0.7738 - val_loss: 0.4732\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4127 - val_accuracy: 0.7747 - val_loss: 0.4737\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4073 - val_accuracy: 0.7744 - val_loss: 0.4732\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4065 - val_accuracy: 0.7742 - val_loss: 0.4724\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8085 - loss: 0.4057 - val_accuracy: 0.7715 - val_loss: 0.4737\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4065 - val_accuracy: 0.7725 - val_loss: 0.4742\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4101 - val_accuracy: 0.7749 - val_loss: 0.4730\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4082 - val_accuracy: 0.7720 - val_loss: 0.4731\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4085 - val_accuracy: 0.7749 - val_loss: 0.4736\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4061 - val_accuracy: 0.7733 - val_loss: 0.4731\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4038 - val_accuracy: 0.7725 - val_loss: 0.4757\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4094 - val_accuracy: 0.7731 - val_loss: 0.4750\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4080 - val_accuracy: 0.7731 - val_loss: 0.4756\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4048 - val_accuracy: 0.7725 - val_loss: 0.4759\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 13/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4968 - val_accuracy: 0.7737 - val_loss: 0.4694\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4744 - val_accuracy: 0.7736 - val_loss: 0.4668\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7708 - loss: 0.4657 - val_accuracy: 0.7742 - val_loss: 0.4627\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.4630 - val_accuracy: 0.7732 - val_loss: 0.4645\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.4569 - val_accuracy: 0.7759 - val_loss: 0.4634\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.4568 - val_accuracy: 0.7728 - val_loss: 0.4631\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4544 - val_accuracy: 0.7732 - val_loss: 0.4635\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.4536 - val_accuracy: 0.7743 - val_loss: 0.4646\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.4471 - val_accuracy: 0.7756 - val_loss: 0.4625\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.4465 - val_accuracy: 0.7735 - val_loss: 0.4638\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.4470 - val_accuracy: 0.7749 - val_loss: 0.4629\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.4443 - val_accuracy: 0.7753 - val_loss: 0.4621\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4450 - val_accuracy: 0.7745 - val_loss: 0.4631\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4438 - val_accuracy: 0.7735 - val_loss: 0.4637\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7870 - loss: 0.4411 - val_accuracy: 0.7749 - val_loss: 0.4636\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4419 - val_accuracy: 0.7732 - val_loss: 0.4644\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4388 - val_accuracy: 0.7750 - val_loss: 0.4631\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4358 - val_accuracy: 0.7761 - val_loss: 0.4628\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7905 - loss: 0.4345 - val_accuracy: 0.7752 - val_loss: 0.4642\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4360 - val_accuracy: 0.7747 - val_loss: 0.4654\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4354 - val_accuracy: 0.7746 - val_loss: 0.4647\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4335 - val_accuracy: 0.7758 - val_loss: 0.4651\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4341 - val_accuracy: 0.7751 - val_loss: 0.4648\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.4347 - val_accuracy: 0.7746 - val_loss: 0.4663\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4320 - val_accuracy: 0.7766 - val_loss: 0.4658\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4287 - val_accuracy: 0.7747 - val_loss: 0.4650\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4302 - val_accuracy: 0.7750 - val_loss: 0.4656\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4281 - val_accuracy: 0.7771 - val_loss: 0.4652\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4286 - val_accuracy: 0.7786 - val_loss: 0.4662\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4264 - val_accuracy: 0.7747 - val_loss: 0.4662\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4295 - val_accuracy: 0.7750 - val_loss: 0.4680\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4267 - val_accuracy: 0.7754 - val_loss: 0.4670\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.4241 - val_accuracy: 0.7757 - val_loss: 0.4657\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4260 - val_accuracy: 0.7750 - val_loss: 0.4675\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4275 - val_accuracy: 0.7747 - val_loss: 0.4686\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4241 - val_accuracy: 0.7732 - val_loss: 0.4665\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4238 - val_accuracy: 0.7753 - val_loss: 0.4672\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4256 - val_accuracy: 0.7745 - val_loss: 0.4668\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4210 - val_accuracy: 0.7759 - val_loss: 0.4670\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4240 - val_accuracy: 0.7743 - val_loss: 0.4680\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4236 - val_accuracy: 0.7733 - val_loss: 0.4673\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4190 - val_accuracy: 0.7742 - val_loss: 0.4676\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4226 - val_accuracy: 0.7770 - val_loss: 0.4655\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4207 - val_accuracy: 0.7733 - val_loss: 0.4672\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4224 - val_accuracy: 0.7763 - val_loss: 0.4669\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.4197 - val_accuracy: 0.7747 - val_loss: 0.4697\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.4216 - val_accuracy: 0.7740 - val_loss: 0.4698\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4194 - val_accuracy: 0.7741 - val_loss: 0.4694\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7995 - loss: 0.4206 - val_accuracy: 0.7742 - val_loss: 0.4676\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4149 - val_accuracy: 0.7740 - val_loss: 0.4689\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4167 - val_accuracy: 0.7749 - val_loss: 0.4683\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.4150 - val_accuracy: 0.7739 - val_loss: 0.4695\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4180 - val_accuracy: 0.7755 - val_loss: 0.4683\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4159 - val_accuracy: 0.7759 - val_loss: 0.4683\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4159 - val_accuracy: 0.7758 - val_loss: 0.4689\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4151 - val_accuracy: 0.7753 - val_loss: 0.4683\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4167 - val_accuracy: 0.7743 - val_loss: 0.4708\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4157 - val_accuracy: 0.7753 - val_loss: 0.4691\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4157 - val_accuracy: 0.7753 - val_loss: 0.4701\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4146 - val_accuracy: 0.7753 - val_loss: 0.4710\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4136 - val_accuracy: 0.7764 - val_loss: 0.4712\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4182 - val_accuracy: 0.7753 - val_loss: 0.4704\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4145 - val_accuracy: 0.7761 - val_loss: 0.4686\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4129 - val_accuracy: 0.7745 - val_loss: 0.4706\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4116 - val_accuracy: 0.7765 - val_loss: 0.4690\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4158 - val_accuracy: 0.7756 - val_loss: 0.4693\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4150 - val_accuracy: 0.7737 - val_loss: 0.4712\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4146 - val_accuracy: 0.7749 - val_loss: 0.4694\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4095 - val_accuracy: 0.7748 - val_loss: 0.4702\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4132 - val_accuracy: 0.7755 - val_loss: 0.4697\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4121 - val_accuracy: 0.7740 - val_loss: 0.4716\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4119 - val_accuracy: 0.7751 - val_loss: 0.4710\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4156 - val_accuracy: 0.7752 - val_loss: 0.4709\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4102 - val_accuracy: 0.7771 - val_loss: 0.4719\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4108 - val_accuracy: 0.7763 - val_loss: 0.4713\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4105 - val_accuracy: 0.7748 - val_loss: 0.4713\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4127 - val_accuracy: 0.7750 - val_loss: 0.4716\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4100 - val_accuracy: 0.7763 - val_loss: 0.4724\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4085 - val_accuracy: 0.7760 - val_loss: 0.4706\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4098 - val_accuracy: 0.7742 - val_loss: 0.4736\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4093 - val_accuracy: 0.7763 - val_loss: 0.4710\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4094 - val_accuracy: 0.7735 - val_loss: 0.4717\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4109 - val_accuracy: 0.7762 - val_loss: 0.4737\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4089 - val_accuracy: 0.7768 - val_loss: 0.4710\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4100 - val_accuracy: 0.7756 - val_loss: 0.4726\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4115 - val_accuracy: 0.7753 - val_loss: 0.4716\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4090 - val_accuracy: 0.7754 - val_loss: 0.4722\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4089 - val_accuracy: 0.7778 - val_loss: 0.4721\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4057 - val_accuracy: 0.7755 - val_loss: 0.4727\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4084 - val_accuracy: 0.7752 - val_loss: 0.4733\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4075 - val_accuracy: 0.7754 - val_loss: 0.4728\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.4050 - val_accuracy: 0.7750 - val_loss: 0.4725\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4102 - val_accuracy: 0.7751 - val_loss: 0.4744\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4042 - val_accuracy: 0.7750 - val_loss: 0.4730\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4075 - val_accuracy: 0.7771 - val_loss: 0.4716\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.4069 - val_accuracy: 0.7758 - val_loss: 0.4731\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4039 - val_accuracy: 0.7753 - val_loss: 0.4715\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.4033 - val_accuracy: 0.7771 - val_loss: 0.4724\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4048 - val_accuracy: 0.7759 - val_loss: 0.4726\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4084 - val_accuracy: 0.7745 - val_loss: 0.4747\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4070 - val_accuracy: 0.7745 - val_loss: 0.4749\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4062 - val_accuracy: 0.7790 - val_loss: 0.4717\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.4051 - val_accuracy: 0.7733 - val_loss: 0.4739\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4054 - val_accuracy: 0.7755 - val_loss: 0.4737\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4053 - val_accuracy: 0.7769 - val_loss: 0.4737\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4067 - val_accuracy: 0.7765 - val_loss: 0.4725\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4050 - val_accuracy: 0.7738 - val_loss: 0.4779\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4039 - val_accuracy: 0.7757 - val_loss: 0.4739\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4026 - val_accuracy: 0.7741 - val_loss: 0.4762\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4035 - val_accuracy: 0.7761 - val_loss: 0.4752\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4016 - val_accuracy: 0.7753 - val_loss: 0.4764\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4035 - val_accuracy: 0.7756 - val_loss: 0.4743\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4042 - val_accuracy: 0.7752 - val_loss: 0.4741\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4026 - val_accuracy: 0.7741 - val_loss: 0.4744\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4051 - val_accuracy: 0.7746 - val_loss: 0.4734\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.4045 - val_accuracy: 0.7762 - val_loss: 0.4741\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4010 - val_accuracy: 0.7751 - val_loss: 0.4760\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4043 - val_accuracy: 0.7748 - val_loss: 0.4755\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4044 - val_accuracy: 0.7750 - val_loss: 0.4776\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.4019 - val_accuracy: 0.7740 - val_loss: 0.4755\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 14/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.5048 - val_accuracy: 0.7731 - val_loss: 0.4647\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.4754 - val_accuracy: 0.7723 - val_loss: 0.4624\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.4679 - val_accuracy: 0.7719 - val_loss: 0.4625\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7734 - loss: 0.4620 - val_accuracy: 0.7745 - val_loss: 0.4603\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4585 - val_accuracy: 0.7711 - val_loss: 0.4615\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4601 - val_accuracy: 0.7728 - val_loss: 0.4622\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.4540 - val_accuracy: 0.7712 - val_loss: 0.4615\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4520 - val_accuracy: 0.7731 - val_loss: 0.4603\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4510 - val_accuracy: 0.7713 - val_loss: 0.4635\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.4477 - val_accuracy: 0.7720 - val_loss: 0.4620\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.4496 - val_accuracy: 0.7729 - val_loss: 0.4616\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4480 - val_accuracy: 0.7724 - val_loss: 0.4622\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4434 - val_accuracy: 0.7719 - val_loss: 0.4616\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4425 - val_accuracy: 0.7727 - val_loss: 0.4611\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4414 - val_accuracy: 0.7715 - val_loss: 0.4634\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4400 - val_accuracy: 0.7715 - val_loss: 0.4606\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.4412 - val_accuracy: 0.7713 - val_loss: 0.4615\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.4395 - val_accuracy: 0.7718 - val_loss: 0.4616\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4378 - val_accuracy: 0.7726 - val_loss: 0.4624\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.4346 - val_accuracy: 0.7737 - val_loss: 0.4621\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.4346 - val_accuracy: 0.7730 - val_loss: 0.4627\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7913 - loss: 0.4356 - val_accuracy: 0.7746 - val_loss: 0.4617\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7935 - loss: 0.4342 - val_accuracy: 0.7744 - val_loss: 0.4610\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4337 - val_accuracy: 0.7727 - val_loss: 0.4641\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.4315 - val_accuracy: 0.7725 - val_loss: 0.4630\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7906 - loss: 0.4331 - val_accuracy: 0.7702 - val_loss: 0.4633\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.4288 - val_accuracy: 0.7726 - val_loss: 0.4627\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.4282 - val_accuracy: 0.7738 - val_loss: 0.4618\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4292 - val_accuracy: 0.7734 - val_loss: 0.4638\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7937 - loss: 0.4280 - val_accuracy: 0.7719 - val_loss: 0.4625\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.4269 - val_accuracy: 0.7736 - val_loss: 0.4642\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4261 - val_accuracy: 0.7732 - val_loss: 0.4642\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.4268 - val_accuracy: 0.7729 - val_loss: 0.4672\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4250 - val_accuracy: 0.7718 - val_loss: 0.4651\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4268 - val_accuracy: 0.7733 - val_loss: 0.4641\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4238 - val_accuracy: 0.7724 - val_loss: 0.4670\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4246 - val_accuracy: 0.7733 - val_loss: 0.4654\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4206 - val_accuracy: 0.7740 - val_loss: 0.4660\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.4235 - val_accuracy: 0.7722 - val_loss: 0.4674\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4251 - val_accuracy: 0.7718 - val_loss: 0.4670\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4210 - val_accuracy: 0.7740 - val_loss: 0.4662\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4205 - val_accuracy: 0.7726 - val_loss: 0.4667\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.4228 - val_accuracy: 0.7717 - val_loss: 0.4678\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4198 - val_accuracy: 0.7734 - val_loss: 0.4668\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.4210 - val_accuracy: 0.7744 - val_loss: 0.4660\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.4175 - val_accuracy: 0.7739 - val_loss: 0.4669\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4216 - val_accuracy: 0.7718 - val_loss: 0.4679\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4188 - val_accuracy: 0.7703 - val_loss: 0.4691\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.4187 - val_accuracy: 0.7724 - val_loss: 0.4671\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.4181 - val_accuracy: 0.7745 - val_loss: 0.4669\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4183 - val_accuracy: 0.7728 - val_loss: 0.4675\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4170 - val_accuracy: 0.7724 - val_loss: 0.4686\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4179 - val_accuracy: 0.7749 - val_loss: 0.4678\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4149 - val_accuracy: 0.7711 - val_loss: 0.4675\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.4174 - val_accuracy: 0.7723 - val_loss: 0.4676\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4157 - val_accuracy: 0.7734 - val_loss: 0.4678\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4149 - val_accuracy: 0.7741 - val_loss: 0.4679\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4149 - val_accuracy: 0.7748 - val_loss: 0.4690\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8016 - loss: 0.4144 - val_accuracy: 0.7752 - val_loss: 0.4692\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8027 - loss: 0.4162 - val_accuracy: 0.7722 - val_loss: 0.4697\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4159 - val_accuracy: 0.7742 - val_loss: 0.4688\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4127 - val_accuracy: 0.7739 - val_loss: 0.4682\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4147 - val_accuracy: 0.7755 - val_loss: 0.4689\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4126 - val_accuracy: 0.7732 - val_loss: 0.4702\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4147 - val_accuracy: 0.7744 - val_loss: 0.4686\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 0.4145 - val_accuracy: 0.7747 - val_loss: 0.4695\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4101 - val_accuracy: 0.7734 - val_loss: 0.4703\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.4144 - val_accuracy: 0.7733 - val_loss: 0.4703\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4097 - val_accuracy: 0.7745 - val_loss: 0.4702\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4101 - val_accuracy: 0.7752 - val_loss: 0.4699\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.4069 - val_accuracy: 0.7716 - val_loss: 0.4704\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4120 - val_accuracy: 0.7731 - val_loss: 0.4698\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4112 - val_accuracy: 0.7741 - val_loss: 0.4688\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4120 - val_accuracy: 0.7722 - val_loss: 0.4713\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4096 - val_accuracy: 0.7739 - val_loss: 0.4717\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4075 - val_accuracy: 0.7732 - val_loss: 0.4695\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4120 - val_accuracy: 0.7739 - val_loss: 0.4709\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4121 - val_accuracy: 0.7732 - val_loss: 0.4703\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4124 - val_accuracy: 0.7738 - val_loss: 0.4702\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4099 - val_accuracy: 0.7747 - val_loss: 0.4707\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4092 - val_accuracy: 0.7719 - val_loss: 0.4714\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4079 - val_accuracy: 0.7719 - val_loss: 0.4702\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4100 - val_accuracy: 0.7739 - val_loss: 0.4695\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4078 - val_accuracy: 0.7751 - val_loss: 0.4708\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.4101 - val_accuracy: 0.7745 - val_loss: 0.4698\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4052 - val_accuracy: 0.7747 - val_loss: 0.4696\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4089 - val_accuracy: 0.7759 - val_loss: 0.4697\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4044 - val_accuracy: 0.7738 - val_loss: 0.4721\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4063 - val_accuracy: 0.7723 - val_loss: 0.4716\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4080 - val_accuracy: 0.7733 - val_loss: 0.4729\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4101 - val_accuracy: 0.7741 - val_loss: 0.4715\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4075 - val_accuracy: 0.7733 - val_loss: 0.4711\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4036 - val_accuracy: 0.7712 - val_loss: 0.4733\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4063 - val_accuracy: 0.7736 - val_loss: 0.4712\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4036 - val_accuracy: 0.7750 - val_loss: 0.4725\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4059 - val_accuracy: 0.7738 - val_loss: 0.4722\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4042 - val_accuracy: 0.7729 - val_loss: 0.4734\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4027 - val_accuracy: 0.7738 - val_loss: 0.4729\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4015 - val_accuracy: 0.7744 - val_loss: 0.4710\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.4034 - val_accuracy: 0.7720 - val_loss: 0.4743\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4045 - val_accuracy: 0.7740 - val_loss: 0.4742\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4039 - val_accuracy: 0.7753 - val_loss: 0.4714\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4012 - val_accuracy: 0.7747 - val_loss: 0.4725\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4044 - val_accuracy: 0.7751 - val_loss: 0.4736\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4029 - val_accuracy: 0.7748 - val_loss: 0.4716\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.4038 - val_accuracy: 0.7739 - val_loss: 0.4722\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4026 - val_accuracy: 0.7757 - val_loss: 0.4735\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4014 - val_accuracy: 0.7748 - val_loss: 0.4740\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 0.4006 - val_accuracy: 0.7747 - val_loss: 0.4725\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4047 - val_accuracy: 0.7746 - val_loss: 0.4744\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8104 - loss: 0.4024 - val_accuracy: 0.7748 - val_loss: 0.4731\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.4023 - val_accuracy: 0.7733 - val_loss: 0.4737\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.4009 - val_accuracy: 0.7746 - val_loss: 0.4738\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.3997 - val_accuracy: 0.7734 - val_loss: 0.4744\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.3989 - val_accuracy: 0.7739 - val_loss: 0.4742\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4006 - val_accuracy: 0.7740 - val_loss: 0.4735\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4043 - val_accuracy: 0.7741 - val_loss: 0.4741\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.3994 - val_accuracy: 0.7732 - val_loss: 0.4742\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.3992 - val_accuracy: 0.7733 - val_loss: 0.4742\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4000 - val_accuracy: 0.7746 - val_loss: 0.4744\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 15/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.4949 - val_accuracy: 0.7696 - val_loss: 0.4696\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.4697 - val_accuracy: 0.7735 - val_loss: 0.4659\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4658 - val_accuracy: 0.7760 - val_loss: 0.4633\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.4604 - val_accuracy: 0.7733 - val_loss: 0.4641\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7757 - loss: 0.4581 - val_accuracy: 0.7746 - val_loss: 0.4627\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7751 - loss: 0.4569 - val_accuracy: 0.7733 - val_loss: 0.4639\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7790 - loss: 0.4524 - val_accuracy: 0.7743 - val_loss: 0.4620\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.4518 - val_accuracy: 0.7739 - val_loss: 0.4629\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4478 - val_accuracy: 0.7739 - val_loss: 0.4623\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4448 - val_accuracy: 0.7740 - val_loss: 0.4625\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7850 - loss: 0.4424 - val_accuracy: 0.7737 - val_loss: 0.4621\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.4434 - val_accuracy: 0.7726 - val_loss: 0.4633\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4418 - val_accuracy: 0.7727 - val_loss: 0.4614\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4394 - val_accuracy: 0.7742 - val_loss: 0.4627\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.4397 - val_accuracy: 0.7744 - val_loss: 0.4621\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.4370 - val_accuracy: 0.7744 - val_loss: 0.4615\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4374 - val_accuracy: 0.7755 - val_loss: 0.4620\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4345 - val_accuracy: 0.7743 - val_loss: 0.4615\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4366 - val_accuracy: 0.7740 - val_loss: 0.4631\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.4346 - val_accuracy: 0.7742 - val_loss: 0.4633\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4352 - val_accuracy: 0.7746 - val_loss: 0.4643\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4346 - val_accuracy: 0.7747 - val_loss: 0.4633\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.4314 - val_accuracy: 0.7742 - val_loss: 0.4640\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4313 - val_accuracy: 0.7730 - val_loss: 0.4626\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4324 - val_accuracy: 0.7733 - val_loss: 0.4631\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4307 - val_accuracy: 0.7759 - val_loss: 0.4631\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7924 - loss: 0.4304 - val_accuracy: 0.7721 - val_loss: 0.4637\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4272 - val_accuracy: 0.7741 - val_loss: 0.4644\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.4290 - val_accuracy: 0.7739 - val_loss: 0.4641\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7940 - loss: 0.4291 - val_accuracy: 0.7764 - val_loss: 0.4623\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.4270 - val_accuracy: 0.7755 - val_loss: 0.4636\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4244 - val_accuracy: 0.7757 - val_loss: 0.4632\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4270 - val_accuracy: 0.7744 - val_loss: 0.4642\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4233 - val_accuracy: 0.7757 - val_loss: 0.4642\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4270 - val_accuracy: 0.7751 - val_loss: 0.4644\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4220 - val_accuracy: 0.7757 - val_loss: 0.4646\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4250 - val_accuracy: 0.7772 - val_loss: 0.4633\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4203 - val_accuracy: 0.7755 - val_loss: 0.4638\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.4186 - val_accuracy: 0.7744 - val_loss: 0.4654\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4205 - val_accuracy: 0.7763 - val_loss: 0.4642\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4229 - val_accuracy: 0.7764 - val_loss: 0.4640\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 0.4217 - val_accuracy: 0.7762 - val_loss: 0.4654\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4197 - val_accuracy: 0.7765 - val_loss: 0.4644\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4228 - val_accuracy: 0.7753 - val_loss: 0.4654\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4176 - val_accuracy: 0.7760 - val_loss: 0.4642\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4177 - val_accuracy: 0.7758 - val_loss: 0.4663\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4179 - val_accuracy: 0.7769 - val_loss: 0.4663\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.4152 - val_accuracy: 0.7788 - val_loss: 0.4648\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4152 - val_accuracy: 0.7768 - val_loss: 0.4666\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.4221 - val_accuracy: 0.7764 - val_loss: 0.4647\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.4156 - val_accuracy: 0.7781 - val_loss: 0.4647\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4179 - val_accuracy: 0.7770 - val_loss: 0.4671\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4193 - val_accuracy: 0.7767 - val_loss: 0.4646\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4155 - val_accuracy: 0.7769 - val_loss: 0.4649\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.4158 - val_accuracy: 0.7774 - val_loss: 0.4660\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4145 - val_accuracy: 0.7782 - val_loss: 0.4658\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4180 - val_accuracy: 0.7774 - val_loss: 0.4666\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 0.4120 - val_accuracy: 0.7761 - val_loss: 0.4679\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4126 - val_accuracy: 0.7776 - val_loss: 0.4682\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4143 - val_accuracy: 0.7786 - val_loss: 0.4684\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4157 - val_accuracy: 0.7788 - val_loss: 0.4669\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4119 - val_accuracy: 0.7788 - val_loss: 0.4649\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.4146 - val_accuracy: 0.7788 - val_loss: 0.4681\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4110 - val_accuracy: 0.7765 - val_loss: 0.4662\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4110 - val_accuracy: 0.7795 - val_loss: 0.4648\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4142 - val_accuracy: 0.7783 - val_loss: 0.4660\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.4118 - val_accuracy: 0.7769 - val_loss: 0.4663\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4102 - val_accuracy: 0.7784 - val_loss: 0.4663\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4087 - val_accuracy: 0.7784 - val_loss: 0.4657\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4077 - val_accuracy: 0.7792 - val_loss: 0.4672\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4098 - val_accuracy: 0.7782 - val_loss: 0.4676\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4107 - val_accuracy: 0.7797 - val_loss: 0.4658\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.4127 - val_accuracy: 0.7784 - val_loss: 0.4660\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.4105 - val_accuracy: 0.7778 - val_loss: 0.4679\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4086 - val_accuracy: 0.7781 - val_loss: 0.4677\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4095 - val_accuracy: 0.7779 - val_loss: 0.4673\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4051 - val_accuracy: 0.7766 - val_loss: 0.4691\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4099 - val_accuracy: 0.7781 - val_loss: 0.4681\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4074 - val_accuracy: 0.7777 - val_loss: 0.4683\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4076 - val_accuracy: 0.7794 - val_loss: 0.4674\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4057 - val_accuracy: 0.7776 - val_loss: 0.4680\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4057 - val_accuracy: 0.7758 - val_loss: 0.4703\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4063 - val_accuracy: 0.7766 - val_loss: 0.4707\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4040 - val_accuracy: 0.7771 - val_loss: 0.4713\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4111 - val_accuracy: 0.7766 - val_loss: 0.4711\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4052 - val_accuracy: 0.7786 - val_loss: 0.4712\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4045 - val_accuracy: 0.7774 - val_loss: 0.4698\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4050 - val_accuracy: 0.7791 - val_loss: 0.4687\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4065 - val_accuracy: 0.7784 - val_loss: 0.4706\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4054 - val_accuracy: 0.7765 - val_loss: 0.4705\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4058 - val_accuracy: 0.7765 - val_loss: 0.4713\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4059 - val_accuracy: 0.7758 - val_loss: 0.4706\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4061 - val_accuracy: 0.7777 - val_loss: 0.4712\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.4059 - val_accuracy: 0.7733 - val_loss: 0.4731\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4050 - val_accuracy: 0.7761 - val_loss: 0.4722\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4049 - val_accuracy: 0.7772 - val_loss: 0.4701\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4059 - val_accuracy: 0.7776 - val_loss: 0.4714\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4041 - val_accuracy: 0.7782 - val_loss: 0.4699\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4068 - val_accuracy: 0.7786 - val_loss: 0.4699\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4040 - val_accuracy: 0.7766 - val_loss: 0.4715\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4029 - val_accuracy: 0.7785 - val_loss: 0.4702\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4058 - val_accuracy: 0.7765 - val_loss: 0.4708\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4030 - val_accuracy: 0.7760 - val_loss: 0.4724\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.4050 - val_accuracy: 0.7770 - val_loss: 0.4700\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4026 - val_accuracy: 0.7778 - val_loss: 0.4711\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4022 - val_accuracy: 0.7760 - val_loss: 0.4716\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4041 - val_accuracy: 0.7750 - val_loss: 0.4738\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4016 - val_accuracy: 0.7775 - val_loss: 0.4702\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4012 - val_accuracy: 0.7798 - val_loss: 0.4704\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4046 - val_accuracy: 0.7756 - val_loss: 0.4724\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4005 - val_accuracy: 0.7767 - val_loss: 0.4710\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4039 - val_accuracy: 0.7762 - val_loss: 0.4726\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8126 - loss: 0.4001 - val_accuracy: 0.7773 - val_loss: 0.4728\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.4038 - val_accuracy: 0.7777 - val_loss: 0.4714\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8113 - loss: 0.4018 - val_accuracy: 0.7784 - val_loss: 0.4705\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.3998 - val_accuracy: 0.7780 - val_loss: 0.4703\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4042 - val_accuracy: 0.7771 - val_loss: 0.4719\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4005 - val_accuracy: 0.7753 - val_loss: 0.4740\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4022 - val_accuracy: 0.7773 - val_loss: 0.4734\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4015 - val_accuracy: 0.7783 - val_loss: 0.4716\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 16/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.5000 - val_accuracy: 0.7757 - val_loss: 0.4574\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4785 - val_accuracy: 0.7776 - val_loss: 0.4551\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4657 - val_accuracy: 0.7796 - val_loss: 0.4539\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.4657 - val_accuracy: 0.7777 - val_loss: 0.4534\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.4605 - val_accuracy: 0.7792 - val_loss: 0.4517\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.4584 - val_accuracy: 0.7785 - val_loss: 0.4533\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.4559 - val_accuracy: 0.7758 - val_loss: 0.4541\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.4521 - val_accuracy: 0.7749 - val_loss: 0.4542\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4508 - val_accuracy: 0.7758 - val_loss: 0.4536\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.4460 - val_accuracy: 0.7764 - val_loss: 0.4545\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4468 - val_accuracy: 0.7774 - val_loss: 0.4541\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4456 - val_accuracy: 0.7745 - val_loss: 0.4563\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4459 - val_accuracy: 0.7774 - val_loss: 0.4544\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4413 - val_accuracy: 0.7775 - val_loss: 0.4563\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4426 - val_accuracy: 0.7785 - val_loss: 0.4527\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.4408 - val_accuracy: 0.7769 - val_loss: 0.4534\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4419 - val_accuracy: 0.7762 - val_loss: 0.4554\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7890 - loss: 0.4348 - val_accuracy: 0.7766 - val_loss: 0.4556\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7897 - loss: 0.4373 - val_accuracy: 0.7782 - val_loss: 0.4559\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4369 - val_accuracy: 0.7762 - val_loss: 0.4558\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.4333 - val_accuracy: 0.7750 - val_loss: 0.4574\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4374 - val_accuracy: 0.7784 - val_loss: 0.4549\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7894 - loss: 0.4372 - val_accuracy: 0.7774 - val_loss: 0.4547\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7902 - loss: 0.4337 - val_accuracy: 0.7785 - val_loss: 0.4553\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4340 - val_accuracy: 0.7772 - val_loss: 0.4585\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.4311 - val_accuracy: 0.7775 - val_loss: 0.4551\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4308 - val_accuracy: 0.7783 - val_loss: 0.4555\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.4323 - val_accuracy: 0.7783 - val_loss: 0.4547\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4295 - val_accuracy: 0.7781 - val_loss: 0.4560\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.4286 - val_accuracy: 0.7772 - val_loss: 0.4557\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.4279 - val_accuracy: 0.7792 - val_loss: 0.4555\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4277 - val_accuracy: 0.7770 - val_loss: 0.4563\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.4280 - val_accuracy: 0.7784 - val_loss: 0.4551\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4244 - val_accuracy: 0.7786 - val_loss: 0.4551\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4275 - val_accuracy: 0.7791 - val_loss: 0.4548\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4244 - val_accuracy: 0.7788 - val_loss: 0.4574\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7953 - loss: 0.4278 - val_accuracy: 0.7777 - val_loss: 0.4562\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4261 - val_accuracy: 0.7769 - val_loss: 0.4561\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4271 - val_accuracy: 0.7786 - val_loss: 0.4580\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4248 - val_accuracy: 0.7788 - val_loss: 0.4567\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4217 - val_accuracy: 0.7800 - val_loss: 0.4560\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4206 - val_accuracy: 0.7775 - val_loss: 0.4584\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4209 - val_accuracy: 0.7787 - val_loss: 0.4570\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4197 - val_accuracy: 0.7794 - val_loss: 0.4571\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4224 - val_accuracy: 0.7786 - val_loss: 0.4576\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4208 - val_accuracy: 0.7802 - val_loss: 0.4569\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.4212 - val_accuracy: 0.7810 - val_loss: 0.4570\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4252 - val_accuracy: 0.7808 - val_loss: 0.4566\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4181 - val_accuracy: 0.7788 - val_loss: 0.4571\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4212 - val_accuracy: 0.7781 - val_loss: 0.4593\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4199 - val_accuracy: 0.7792 - val_loss: 0.4581\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4186 - val_accuracy: 0.7782 - val_loss: 0.4581\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4175 - val_accuracy: 0.7771 - val_loss: 0.4585\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4177 - val_accuracy: 0.7780 - val_loss: 0.4599\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4159 - val_accuracy: 0.7797 - val_loss: 0.4585\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4171 - val_accuracy: 0.7783 - val_loss: 0.4591\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.4152 - val_accuracy: 0.7776 - val_loss: 0.4595\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4179 - val_accuracy: 0.7821 - val_loss: 0.4573\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4121 - val_accuracy: 0.7782 - val_loss: 0.4580\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4151 - val_accuracy: 0.7787 - val_loss: 0.4609\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.4150 - val_accuracy: 0.7805 - val_loss: 0.4576\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4144 - val_accuracy: 0.7797 - val_loss: 0.4598\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4136 - val_accuracy: 0.7805 - val_loss: 0.4583\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4130 - val_accuracy: 0.7795 - val_loss: 0.4590\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4128 - val_accuracy: 0.7809 - val_loss: 0.4591\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4166 - val_accuracy: 0.7779 - val_loss: 0.4586\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4159 - val_accuracy: 0.7802 - val_loss: 0.4610\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4116 - val_accuracy: 0.7784 - val_loss: 0.4599\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4126 - val_accuracy: 0.7818 - val_loss: 0.4583\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4130 - val_accuracy: 0.7793 - val_loss: 0.4599\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4110 - val_accuracy: 0.7812 - val_loss: 0.4588\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4105 - val_accuracy: 0.7805 - val_loss: 0.4584\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8052 - loss: 0.4119 - val_accuracy: 0.7805 - val_loss: 0.4596\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4094 - val_accuracy: 0.7811 - val_loss: 0.4598\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.4129 - val_accuracy: 0.7811 - val_loss: 0.4611\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4096 - val_accuracy: 0.7815 - val_loss: 0.4595\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4101 - val_accuracy: 0.7793 - val_loss: 0.4618\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4129 - val_accuracy: 0.7791 - val_loss: 0.4619\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4115 - val_accuracy: 0.7816 - val_loss: 0.4605\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4084 - val_accuracy: 0.7817 - val_loss: 0.4607\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4117 - val_accuracy: 0.7817 - val_loss: 0.4623\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4098 - val_accuracy: 0.7806 - val_loss: 0.4609\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4099 - val_accuracy: 0.7798 - val_loss: 0.4617\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4096 - val_accuracy: 0.7810 - val_loss: 0.4629\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4086 - val_accuracy: 0.7798 - val_loss: 0.4611\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.4095 - val_accuracy: 0.7805 - val_loss: 0.4622\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4111 - val_accuracy: 0.7802 - val_loss: 0.4617\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8077 - loss: 0.4086 - val_accuracy: 0.7793 - val_loss: 0.4626\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4089 - val_accuracy: 0.7806 - val_loss: 0.4625\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4091 - val_accuracy: 0.7826 - val_loss: 0.4621\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4052 - val_accuracy: 0.7819 - val_loss: 0.4627\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4090 - val_accuracy: 0.7801 - val_loss: 0.4617\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.4056 - val_accuracy: 0.7791 - val_loss: 0.4638\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4062 - val_accuracy: 0.7803 - val_loss: 0.4634\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4068 - val_accuracy: 0.7819 - val_loss: 0.4617\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4062 - val_accuracy: 0.7820 - val_loss: 0.4608\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4056 - val_accuracy: 0.7809 - val_loss: 0.4625\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4051 - val_accuracy: 0.7815 - val_loss: 0.4627\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8089 - loss: 0.4063 - val_accuracy: 0.7792 - val_loss: 0.4633\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4059 - val_accuracy: 0.7796 - val_loss: 0.4637\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4088 - val_accuracy: 0.7820 - val_loss: 0.4628\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4022 - val_accuracy: 0.7801 - val_loss: 0.4654\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4074 - val_accuracy: 0.7832 - val_loss: 0.4634\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4068 - val_accuracy: 0.7827 - val_loss: 0.4629\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4072 - val_accuracy: 0.7814 - val_loss: 0.4621\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.4043 - val_accuracy: 0.7812 - val_loss: 0.4630\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4055 - val_accuracy: 0.7812 - val_loss: 0.4638\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4051 - val_accuracy: 0.7800 - val_loss: 0.4631\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4025 - val_accuracy: 0.7837 - val_loss: 0.4611\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4039 - val_accuracy: 0.7797 - val_loss: 0.4648\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4038 - val_accuracy: 0.7806 - val_loss: 0.4633\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4039 - val_accuracy: 0.7821 - val_loss: 0.4627\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4041 - val_accuracy: 0.7821 - val_loss: 0.4615\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4050 - val_accuracy: 0.7807 - val_loss: 0.4632\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4058 - val_accuracy: 0.7832 - val_loss: 0.4635\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.4028 - val_accuracy: 0.7816 - val_loss: 0.4626\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4042 - val_accuracy: 0.7815 - val_loss: 0.4646\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4004 - val_accuracy: 0.7809 - val_loss: 0.4639\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4031 - val_accuracy: 0.7817 - val_loss: 0.4625\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4027 - val_accuracy: 0.7806 - val_loss: 0.4652\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 17/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.5001 - val_accuracy: 0.7745 - val_loss: 0.4620\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4775 - val_accuracy: 0.7744 - val_loss: 0.4576\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.4651 - val_accuracy: 0.7753 - val_loss: 0.4570\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.4637 - val_accuracy: 0.7786 - val_loss: 0.4568\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7742 - loss: 0.4627 - val_accuracy: 0.7773 - val_loss: 0.4554\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7802 - loss: 0.4530 - val_accuracy: 0.7770 - val_loss: 0.4571\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.4554 - val_accuracy: 0.7773 - val_loss: 0.4550\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4537 - val_accuracy: 0.7783 - val_loss: 0.4542\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4488 - val_accuracy: 0.7755 - val_loss: 0.4560\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7804 - loss: 0.4507 - val_accuracy: 0.7757 - val_loss: 0.4557\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.4470 - val_accuracy: 0.7757 - val_loss: 0.4559\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.4488 - val_accuracy: 0.7773 - val_loss: 0.4540\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.4445 - val_accuracy: 0.7792 - val_loss: 0.4550\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.4439 - val_accuracy: 0.7780 - val_loss: 0.4541\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 0.4427 - val_accuracy: 0.7781 - val_loss: 0.4565\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.4403 - val_accuracy: 0.7761 - val_loss: 0.4552\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4366 - val_accuracy: 0.7763 - val_loss: 0.4545\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.4395 - val_accuracy: 0.7767 - val_loss: 0.4556\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7887 - loss: 0.4382 - val_accuracy: 0.7768 - val_loss: 0.4570\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 0.4371 - val_accuracy: 0.7772 - val_loss: 0.4554\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4334 - val_accuracy: 0.7766 - val_loss: 0.4561\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4340 - val_accuracy: 0.7763 - val_loss: 0.4568\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4345 - val_accuracy: 0.7766 - val_loss: 0.4566\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4344 - val_accuracy: 0.7772 - val_loss: 0.4574\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4309 - val_accuracy: 0.7769 - val_loss: 0.4588\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7939 - loss: 0.4295 - val_accuracy: 0.7764 - val_loss: 0.4588\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7922 - loss: 0.4319 - val_accuracy: 0.7755 - val_loss: 0.4605\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.4290 - val_accuracy: 0.7767 - val_loss: 0.4608\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7958 - loss: 0.4271 - val_accuracy: 0.7767 - val_loss: 0.4586\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7946 - loss: 0.4280 - val_accuracy: 0.7767 - val_loss: 0.4610\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.4254 - val_accuracy: 0.7761 - val_loss: 0.4604\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7947 - loss: 0.4279 - val_accuracy: 0.7756 - val_loss: 0.4599\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7953 - loss: 0.4255 - val_accuracy: 0.7762 - val_loss: 0.4590\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.4278 - val_accuracy: 0.7773 - val_loss: 0.4599\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.4252 - val_accuracy: 0.7777 - val_loss: 0.4598\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7970 - loss: 0.4256 - val_accuracy: 0.7765 - val_loss: 0.4615\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7964 - loss: 0.4261 - val_accuracy: 0.7773 - val_loss: 0.4613\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.4214 - val_accuracy: 0.7786 - val_loss: 0.4593\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.4226 - val_accuracy: 0.7758 - val_loss: 0.4608\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.4221 - val_accuracy: 0.7787 - val_loss: 0.4594\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.4223 - val_accuracy: 0.7778 - val_loss: 0.4605\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.4234 - val_accuracy: 0.7778 - val_loss: 0.4611\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 0.4210 - val_accuracy: 0.7780 - val_loss: 0.4604\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7977 - loss: 0.4212 - val_accuracy: 0.7788 - val_loss: 0.4615\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4204 - val_accuracy: 0.7773 - val_loss: 0.4617\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8011 - loss: 0.4193 - val_accuracy: 0.7776 - val_loss: 0.4612\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8014 - loss: 0.4191 - val_accuracy: 0.7785 - val_loss: 0.4613\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7973 - loss: 0.4226 - val_accuracy: 0.7778 - val_loss: 0.4616\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.4172 - val_accuracy: 0.7789 - val_loss: 0.4613\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8001 - loss: 0.4192 - val_accuracy: 0.7774 - val_loss: 0.4608\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8006 - loss: 0.4178 - val_accuracy: 0.7763 - val_loss: 0.4624\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4176 - val_accuracy: 0.7764 - val_loss: 0.4618\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4153 - val_accuracy: 0.7758 - val_loss: 0.4635\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8023 - loss: 0.4174 - val_accuracy: 0.7774 - val_loss: 0.4621\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8025 - loss: 0.4178 - val_accuracy: 0.7775 - val_loss: 0.4638\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8018 - loss: 0.4163 - val_accuracy: 0.7780 - val_loss: 0.4618\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4159 - val_accuracy: 0.7791 - val_loss: 0.4621\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4159 - val_accuracy: 0.7786 - val_loss: 0.4605\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.4139 - val_accuracy: 0.7774 - val_loss: 0.4608\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8034 - loss: 0.4149 - val_accuracy: 0.7782 - val_loss: 0.4611\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.4117 - val_accuracy: 0.7759 - val_loss: 0.4625\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 0.4123 - val_accuracy: 0.7780 - val_loss: 0.4615\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4150 - val_accuracy: 0.7763 - val_loss: 0.4644\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4115 - val_accuracy: 0.7774 - val_loss: 0.4622\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4121 - val_accuracy: 0.7791 - val_loss: 0.4634\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4138 - val_accuracy: 0.7779 - val_loss: 0.4642\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4112 - val_accuracy: 0.7782 - val_loss: 0.4642\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.4140 - val_accuracy: 0.7782 - val_loss: 0.4637\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.4110 - val_accuracy: 0.7782 - val_loss: 0.4631\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8065 - loss: 0.4096 - val_accuracy: 0.7794 - val_loss: 0.4619\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4118 - val_accuracy: 0.7784 - val_loss: 0.4650\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.4094 - val_accuracy: 0.7781 - val_loss: 0.4647\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.4080 - val_accuracy: 0.7781 - val_loss: 0.4639\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4106 - val_accuracy: 0.7796 - val_loss: 0.4637\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4099 - val_accuracy: 0.7796 - val_loss: 0.4619\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8075 - loss: 0.4108 - val_accuracy: 0.7766 - val_loss: 0.4637\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8088 - loss: 0.4066 - val_accuracy: 0.7780 - val_loss: 0.4640\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4076 - val_accuracy: 0.7784 - val_loss: 0.4658\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 0.4064 - val_accuracy: 0.7777 - val_loss: 0.4655\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4066 - val_accuracy: 0.7783 - val_loss: 0.4628\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4080 - val_accuracy: 0.7785 - val_loss: 0.4638\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4098 - val_accuracy: 0.7798 - val_loss: 0.4642\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4111 - val_accuracy: 0.7797 - val_loss: 0.4643\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.4078 - val_accuracy: 0.7783 - val_loss: 0.4659\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8084 - loss: 0.4069 - val_accuracy: 0.7787 - val_loss: 0.4639\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.4095 - val_accuracy: 0.7787 - val_loss: 0.4647\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8093 - loss: 0.4074 - val_accuracy: 0.7790 - val_loss: 0.4655\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4040 - val_accuracy: 0.7778 - val_loss: 0.4648\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4052 - val_accuracy: 0.7807 - val_loss: 0.4641\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8095 - loss: 0.4070 - val_accuracy: 0.7789 - val_loss: 0.4642\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8095 - loss: 0.4068 - val_accuracy: 0.7791 - val_loss: 0.4655\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8089 - loss: 0.4071 - val_accuracy: 0.7798 - val_loss: 0.4661\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8116 - loss: 0.4038 - val_accuracy: 0.7778 - val_loss: 0.4673\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8102 - loss: 0.4038 - val_accuracy: 0.7793 - val_loss: 0.4656\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.3997 - val_accuracy: 0.7791 - val_loss: 0.4661\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4070 - val_accuracy: 0.7798 - val_loss: 0.4666\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4066 - val_accuracy: 0.7773 - val_loss: 0.4674\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8110 - loss: 0.4040 - val_accuracy: 0.7786 - val_loss: 0.4682\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4044 - val_accuracy: 0.7782 - val_loss: 0.4662\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8092 - loss: 0.4041 - val_accuracy: 0.7785 - val_loss: 0.4677\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.4072 - val_accuracy: 0.7773 - val_loss: 0.4681\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4084 - val_accuracy: 0.7788 - val_loss: 0.4677\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4012 - val_accuracy: 0.7802 - val_loss: 0.4649\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8112 - loss: 0.4051 - val_accuracy: 0.7788 - val_loss: 0.4672\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.4035 - val_accuracy: 0.7788 - val_loss: 0.4671\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8112 - loss: 0.4048 - val_accuracy: 0.7778 - val_loss: 0.4676\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4042 - val_accuracy: 0.7807 - val_loss: 0.4666\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4077 - val_accuracy: 0.7786 - val_loss: 0.4650\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4060 - val_accuracy: 0.7810 - val_loss: 0.4658\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4046 - val_accuracy: 0.7797 - val_loss: 0.4654\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.4028 - val_accuracy: 0.7782 - val_loss: 0.4661\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.4017 - val_accuracy: 0.7779 - val_loss: 0.4679\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8129 - loss: 0.3997 - val_accuracy: 0.7783 - val_loss: 0.4661\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.4026 - val_accuracy: 0.7787 - val_loss: 0.4664\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8109 - loss: 0.4029 - val_accuracy: 0.7784 - val_loss: 0.4678\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.3980 - val_accuracy: 0.7773 - val_loss: 0.4683\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.4012 - val_accuracy: 0.7803 - val_loss: 0.4658\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4031 - val_accuracy: 0.7805 - val_loss: 0.4659\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.4001 - val_accuracy: 0.7796 - val_loss: 0.4663\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.3997 - val_accuracy: 0.7803 - val_loss: 0.4655\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Training model 18/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.4916 - val_accuracy: 0.7761 - val_loss: 0.4632\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.4690 - val_accuracy: 0.7750 - val_loss: 0.4624\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.4633 - val_accuracy: 0.7745 - val_loss: 0.4604\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7766 - loss: 0.4572 - val_accuracy: 0.7764 - val_loss: 0.4592\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.4575 - val_accuracy: 0.7764 - val_loss: 0.4580\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.4552 - val_accuracy: 0.7752 - val_loss: 0.4583\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.4523 - val_accuracy: 0.7767 - val_loss: 0.4583\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4473 - val_accuracy: 0.7759 - val_loss: 0.4591\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4454 - val_accuracy: 0.7745 - val_loss: 0.4599\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4472 - val_accuracy: 0.7747 - val_loss: 0.4584\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4441 - val_accuracy: 0.7761 - val_loss: 0.4582\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7860 - loss: 0.4421 - val_accuracy: 0.7749 - val_loss: 0.4587\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7848 - loss: 0.4431 - val_accuracy: 0.7748 - val_loss: 0.4594\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.4387 - val_accuracy: 0.7748 - val_loss: 0.4598\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7868 - loss: 0.4394 - val_accuracy: 0.7738 - val_loss: 0.4599\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.4343 - val_accuracy: 0.7762 - val_loss: 0.4596\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.4365 - val_accuracy: 0.7759 - val_loss: 0.4592\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7918 - loss: 0.4345 - val_accuracy: 0.7762 - val_loss: 0.4588\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.4321 - val_accuracy: 0.7779 - val_loss: 0.4591\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.4320 - val_accuracy: 0.7765 - val_loss: 0.4599\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7908 - loss: 0.4344 - val_accuracy: 0.7768 - val_loss: 0.4597\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.4312 - val_accuracy: 0.7762 - val_loss: 0.4607\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 0.4307 - val_accuracy: 0.7763 - val_loss: 0.4598\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.4281 - val_accuracy: 0.7735 - val_loss: 0.4612\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7937 - loss: 0.4271 - val_accuracy: 0.7758 - val_loss: 0.4608\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.4284 - val_accuracy: 0.7760 - val_loss: 0.4625\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.4303 - val_accuracy: 0.7761 - val_loss: 0.4608\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.4278 - val_accuracy: 0.7747 - val_loss: 0.4616\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4276 - val_accuracy: 0.7739 - val_loss: 0.4621\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4265 - val_accuracy: 0.7759 - val_loss: 0.4624\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.4219 - val_accuracy: 0.7762 - val_loss: 0.4636\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4271 - val_accuracy: 0.7738 - val_loss: 0.4628\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.4245 - val_accuracy: 0.7759 - val_loss: 0.4651\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7967 - loss: 0.4234 - val_accuracy: 0.7756 - val_loss: 0.4633\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8006 - loss: 0.4195 - val_accuracy: 0.7769 - val_loss: 0.4635\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7979 - loss: 0.4224 - val_accuracy: 0.7752 - val_loss: 0.4651\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7958 - loss: 0.4237 - val_accuracy: 0.7765 - val_loss: 0.4633\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4212 - val_accuracy: 0.7776 - val_loss: 0.4624\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7985 - loss: 0.4212 - val_accuracy: 0.7758 - val_loss: 0.4640\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4170 - val_accuracy: 0.7752 - val_loss: 0.4644\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7991 - loss: 0.4202 - val_accuracy: 0.7740 - val_loss: 0.4655\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7999 - loss: 0.4201 - val_accuracy: 0.7744 - val_loss: 0.4648\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4201 - val_accuracy: 0.7752 - val_loss: 0.4641\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.4166 - val_accuracy: 0.7758 - val_loss: 0.4632\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.4176 - val_accuracy: 0.7764 - val_loss: 0.4644\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8020 - loss: 0.4155 - val_accuracy: 0.7744 - val_loss: 0.4660\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4194 - val_accuracy: 0.7771 - val_loss: 0.4659\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.4160 - val_accuracy: 0.7749 - val_loss: 0.4650\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8014 - loss: 0.4167 - val_accuracy: 0.7767 - val_loss: 0.4646\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4148 - val_accuracy: 0.7746 - val_loss: 0.4671\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.4158 - val_accuracy: 0.7745 - val_loss: 0.4668\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8009 - loss: 0.4189 - val_accuracy: 0.7741 - val_loss: 0.4659\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4148 - val_accuracy: 0.7737 - val_loss: 0.4668\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8014 - loss: 0.4187 - val_accuracy: 0.7749 - val_loss: 0.4664\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.4135 - val_accuracy: 0.7761 - val_loss: 0.4662\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.4148 - val_accuracy: 0.7754 - val_loss: 0.4672\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8062 - loss: 0.4105 - val_accuracy: 0.7756 - val_loss: 0.4661\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8060 - loss: 0.4112 - val_accuracy: 0.7757 - val_loss: 0.4673\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8045 - loss: 0.4133 - val_accuracy: 0.7735 - val_loss: 0.4686\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4116 - val_accuracy: 0.7732 - val_loss: 0.4687\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4116 - val_accuracy: 0.7735 - val_loss: 0.4692\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4091 - val_accuracy: 0.7732 - val_loss: 0.4694\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4117 - val_accuracy: 0.7730 - val_loss: 0.4692\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4104 - val_accuracy: 0.7759 - val_loss: 0.4680\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4106 - val_accuracy: 0.7736 - val_loss: 0.4698\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4104 - val_accuracy: 0.7746 - val_loss: 0.4685\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4138 - val_accuracy: 0.7746 - val_loss: 0.4683\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4081 - val_accuracy: 0.7722 - val_loss: 0.4702\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4095 - val_accuracy: 0.7727 - val_loss: 0.4682\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4078 - val_accuracy: 0.7733 - val_loss: 0.4699\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4094 - val_accuracy: 0.7754 - val_loss: 0.4686\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8092 - loss: 0.4034 - val_accuracy: 0.7732 - val_loss: 0.4699\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4101 - val_accuracy: 0.7746 - val_loss: 0.4689\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4068 - val_accuracy: 0.7735 - val_loss: 0.4688\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4043 - val_accuracy: 0.7761 - val_loss: 0.4676\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4060 - val_accuracy: 0.7753 - val_loss: 0.4681\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4061 - val_accuracy: 0.7753 - val_loss: 0.4688\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4080 - val_accuracy: 0.7758 - val_loss: 0.4678\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4054 - val_accuracy: 0.7745 - val_loss: 0.4679\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4081 - val_accuracy: 0.7749 - val_loss: 0.4686\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4052 - val_accuracy: 0.7736 - val_loss: 0.4707\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4028 - val_accuracy: 0.7742 - val_loss: 0.4706\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4053 - val_accuracy: 0.7745 - val_loss: 0.4710\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.4023 - val_accuracy: 0.7759 - val_loss: 0.4707\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4052 - val_accuracy: 0.7749 - val_loss: 0.4699\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.4036 - val_accuracy: 0.7732 - val_loss: 0.4721\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.4014 - val_accuracy: 0.7758 - val_loss: 0.4715\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4041 - val_accuracy: 0.7732 - val_loss: 0.4704\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.4048 - val_accuracy: 0.7749 - val_loss: 0.4723\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4047 - val_accuracy: 0.7756 - val_loss: 0.4713\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4049 - val_accuracy: 0.7754 - val_loss: 0.4702\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4032 - val_accuracy: 0.7750 - val_loss: 0.4719\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4049 - val_accuracy: 0.7753 - val_loss: 0.4724\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4038 - val_accuracy: 0.7765 - val_loss: 0.4690\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.4024 - val_accuracy: 0.7751 - val_loss: 0.4722\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4020 - val_accuracy: 0.7755 - val_loss: 0.4716\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4025 - val_accuracy: 0.7753 - val_loss: 0.4721\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4027 - val_accuracy: 0.7753 - val_loss: 0.4712\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4042 - val_accuracy: 0.7735 - val_loss: 0.4724\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4011 - val_accuracy: 0.7759 - val_loss: 0.4714\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4038 - val_accuracy: 0.7761 - val_loss: 0.4719\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.3993 - val_accuracy: 0.7744 - val_loss: 0.4721\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.4005 - val_accuracy: 0.7764 - val_loss: 0.4715\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4027 - val_accuracy: 0.7748 - val_loss: 0.4725\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4020 - val_accuracy: 0.7742 - val_loss: 0.4732\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4015 - val_accuracy: 0.7757 - val_loss: 0.4708\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8119 - loss: 0.4008 - val_accuracy: 0.7752 - val_loss: 0.4721\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4042 - val_accuracy: 0.7769 - val_loss: 0.4715\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4014 - val_accuracy: 0.7761 - val_loss: 0.4715\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.3983 - val_accuracy: 0.7760 - val_loss: 0.4727\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4007 - val_accuracy: 0.7772 - val_loss: 0.4716\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4006 - val_accuracy: 0.7759 - val_loss: 0.4706\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4006 - val_accuracy: 0.7753 - val_loss: 0.4727\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4014 - val_accuracy: 0.7763 - val_loss: 0.4722\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.3984 - val_accuracy: 0.7754 - val_loss: 0.4719\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4017 - val_accuracy: 0.7782 - val_loss: 0.4711\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3992 - val_accuracy: 0.7767 - val_loss: 0.4747\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.3998 - val_accuracy: 0.7765 - val_loss: 0.4733\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3968 - val_accuracy: 0.7772 - val_loss: 0.4707\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.3979 - val_accuracy: 0.7735 - val_loss: 0.4726\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 19/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.4973 - val_accuracy: 0.7762 - val_loss: 0.4630\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4687 - val_accuracy: 0.7768 - val_loss: 0.4603\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.4632 - val_accuracy: 0.7763 - val_loss: 0.4610\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7748 - loss: 0.4624 - val_accuracy: 0.7771 - val_loss: 0.4581\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.4573 - val_accuracy: 0.7757 - val_loss: 0.4593\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7785 - loss: 0.4538 - val_accuracy: 0.7760 - val_loss: 0.4591\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4489 - val_accuracy: 0.7767 - val_loss: 0.4587\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7806 - loss: 0.4480 - val_accuracy: 0.7738 - val_loss: 0.4592\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7836 - loss: 0.4447 - val_accuracy: 0.7753 - val_loss: 0.4583\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7851 - loss: 0.4415 - val_accuracy: 0.7757 - val_loss: 0.4589\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4442 - val_accuracy: 0.7752 - val_loss: 0.4583\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.4388 - val_accuracy: 0.7742 - val_loss: 0.4595\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4401 - val_accuracy: 0.7757 - val_loss: 0.4588\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4375 - val_accuracy: 0.7738 - val_loss: 0.4593\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4370 - val_accuracy: 0.7756 - val_loss: 0.4586\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4345 - val_accuracy: 0.7748 - val_loss: 0.4587\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.4330 - val_accuracy: 0.7770 - val_loss: 0.4590\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4333 - val_accuracy: 0.7756 - val_loss: 0.4584\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4321 - val_accuracy: 0.7767 - val_loss: 0.4612\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.4313 - val_accuracy: 0.7741 - val_loss: 0.4589\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4251 - val_accuracy: 0.7763 - val_loss: 0.4594\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.4277 - val_accuracy: 0.7763 - val_loss: 0.4589\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4286 - val_accuracy: 0.7760 - val_loss: 0.4587\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.4257 - val_accuracy: 0.7756 - val_loss: 0.4596\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.4290 - val_accuracy: 0.7730 - val_loss: 0.4594\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4236 - val_accuracy: 0.7747 - val_loss: 0.4597\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4268 - val_accuracy: 0.7761 - val_loss: 0.4595\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4234 - val_accuracy: 0.7772 - val_loss: 0.4608\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.4243 - val_accuracy: 0.7758 - val_loss: 0.4600\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4235 - val_accuracy: 0.7770 - val_loss: 0.4607\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4270 - val_accuracy: 0.7757 - val_loss: 0.4606\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.4225 - val_accuracy: 0.7782 - val_loss: 0.4602\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4223 - val_accuracy: 0.7754 - val_loss: 0.4604\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4250 - val_accuracy: 0.7782 - val_loss: 0.4606\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.4208 - val_accuracy: 0.7759 - val_loss: 0.4619\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7981 - loss: 0.4210 - val_accuracy: 0.7751 - val_loss: 0.4617\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4177 - val_accuracy: 0.7753 - val_loss: 0.4617\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4192 - val_accuracy: 0.7776 - val_loss: 0.4606\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4162 - val_accuracy: 0.7786 - val_loss: 0.4619\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4176 - val_accuracy: 0.7773 - val_loss: 0.4626\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4166 - val_accuracy: 0.7774 - val_loss: 0.4631\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4191 - val_accuracy: 0.7780 - val_loss: 0.4632\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8018 - loss: 0.4177 - val_accuracy: 0.7784 - val_loss: 0.4615\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4175 - val_accuracy: 0.7751 - val_loss: 0.4628\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4179 - val_accuracy: 0.7759 - val_loss: 0.4642\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8026 - loss: 0.4162 - val_accuracy: 0.7788 - val_loss: 0.4630\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4150 - val_accuracy: 0.7794 - val_loss: 0.4630\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4171 - val_accuracy: 0.7780 - val_loss: 0.4632\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4147 - val_accuracy: 0.7765 - val_loss: 0.4637\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.4143 - val_accuracy: 0.7759 - val_loss: 0.4637\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4147 - val_accuracy: 0.7769 - val_loss: 0.4618\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4158 - val_accuracy: 0.7791 - val_loss: 0.4625\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4111 - val_accuracy: 0.7777 - val_loss: 0.4628\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4125 - val_accuracy: 0.7772 - val_loss: 0.4631\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4121 - val_accuracy: 0.7769 - val_loss: 0.4655\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4113 - val_accuracy: 0.7759 - val_loss: 0.4655\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4124 - val_accuracy: 0.7772 - val_loss: 0.4640\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4126 - val_accuracy: 0.7775 - val_loss: 0.4645\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4101 - val_accuracy: 0.7767 - val_loss: 0.4669\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4106 - val_accuracy: 0.7767 - val_loss: 0.4649\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4129 - val_accuracy: 0.7763 - val_loss: 0.4678\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4091 - val_accuracy: 0.7752 - val_loss: 0.4678\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4082 - val_accuracy: 0.7762 - val_loss: 0.4664\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4090 - val_accuracy: 0.7760 - val_loss: 0.4665\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4085 - val_accuracy: 0.7772 - val_loss: 0.4664\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4094 - val_accuracy: 0.7778 - val_loss: 0.4662\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4099 - val_accuracy: 0.7792 - val_loss: 0.4659\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4096 - val_accuracy: 0.7766 - val_loss: 0.4649\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4088 - val_accuracy: 0.7757 - val_loss: 0.4660\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4093 - val_accuracy: 0.7782 - val_loss: 0.4655\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4087 - val_accuracy: 0.7766 - val_loss: 0.4656\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4056 - val_accuracy: 0.7768 - val_loss: 0.4691\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4084 - val_accuracy: 0.7756 - val_loss: 0.4664\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4049 - val_accuracy: 0.7757 - val_loss: 0.4652\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4078 - val_accuracy: 0.7758 - val_loss: 0.4677\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4092 - val_accuracy: 0.7776 - val_loss: 0.4679\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4061 - val_accuracy: 0.7761 - val_loss: 0.4686\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4016 - val_accuracy: 0.7760 - val_loss: 0.4687\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4060 - val_accuracy: 0.7763 - val_loss: 0.4652\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4067 - val_accuracy: 0.7757 - val_loss: 0.4689\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4069 - val_accuracy: 0.7776 - val_loss: 0.4680\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.4039 - val_accuracy: 0.7768 - val_loss: 0.4679\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4077 - val_accuracy: 0.7771 - val_loss: 0.4683\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4051 - val_accuracy: 0.7770 - val_loss: 0.4675\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4028 - val_accuracy: 0.7760 - val_loss: 0.4702\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8098 - loss: 0.4048 - val_accuracy: 0.7763 - val_loss: 0.4694\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4057 - val_accuracy: 0.7794 - val_loss: 0.4699\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.4051 - val_accuracy: 0.7782 - val_loss: 0.4676\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4017 - val_accuracy: 0.7782 - val_loss: 0.4678\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4031 - val_accuracy: 0.7759 - val_loss: 0.4680\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8097 - loss: 0.4045 - val_accuracy: 0.7773 - val_loss: 0.4700\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4031 - val_accuracy: 0.7767 - val_loss: 0.4688\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4020 - val_accuracy: 0.7756 - val_loss: 0.4706\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4043 - val_accuracy: 0.7774 - val_loss: 0.4688\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4076 - val_accuracy: 0.7760 - val_loss: 0.4687\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4032 - val_accuracy: 0.7766 - val_loss: 0.4702\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4025 - val_accuracy: 0.7784 - val_loss: 0.4697\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4009 - val_accuracy: 0.7763 - val_loss: 0.4684\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4021 - val_accuracy: 0.7763 - val_loss: 0.4696\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4021 - val_accuracy: 0.7767 - val_loss: 0.4679\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4020 - val_accuracy: 0.7764 - val_loss: 0.4703\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4020 - val_accuracy: 0.7767 - val_loss: 0.4689\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4029 - val_accuracy: 0.7776 - val_loss: 0.4713\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4008 - val_accuracy: 0.7780 - val_loss: 0.4712\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4026 - val_accuracy: 0.7757 - val_loss: 0.4696\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4005 - val_accuracy: 0.7768 - val_loss: 0.4698\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.4004 - val_accuracy: 0.7765 - val_loss: 0.4696\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.3996 - val_accuracy: 0.7755 - val_loss: 0.4706\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4011 - val_accuracy: 0.7763 - val_loss: 0.4701\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.3992 - val_accuracy: 0.7788 - val_loss: 0.4700\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4025 - val_accuracy: 0.7756 - val_loss: 0.4708\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.4009 - val_accuracy: 0.7753 - val_loss: 0.4692\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.4027 - val_accuracy: 0.7764 - val_loss: 0.4701\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 0.4010 - val_accuracy: 0.7745 - val_loss: 0.4710\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4015 - val_accuracy: 0.7782 - val_loss: 0.4701\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3985 - val_accuracy: 0.7758 - val_loss: 0.4694\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.3974 - val_accuracy: 0.7762 - val_loss: 0.4724\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.3985 - val_accuracy: 0.7774 - val_loss: 0.4710\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.3954 - val_accuracy: 0.7775 - val_loss: 0.4705\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.3965 - val_accuracy: 0.7788 - val_loss: 0.4694\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 20/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 0.4924 - val_accuracy: 0.7807 - val_loss: 0.4569\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 0.4656 - val_accuracy: 0.7815 - val_loss: 0.4544\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.4612 - val_accuracy: 0.7811 - val_loss: 0.4526\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.4556 - val_accuracy: 0.7796 - val_loss: 0.4528\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.4497 - val_accuracy: 0.7812 - val_loss: 0.4512\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 0.4511 - val_accuracy: 0.7812 - val_loss: 0.4521\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.4491 - val_accuracy: 0.7827 - val_loss: 0.4520\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4476 - val_accuracy: 0.7783 - val_loss: 0.4541\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.4448 - val_accuracy: 0.7811 - val_loss: 0.4518\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4398 - val_accuracy: 0.7796 - val_loss: 0.4524\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7870 - loss: 0.4384 - val_accuracy: 0.7813 - val_loss: 0.4515\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.4373 - val_accuracy: 0.7817 - val_loss: 0.4541\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4360 - val_accuracy: 0.7783 - val_loss: 0.4532\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.4362 - val_accuracy: 0.7799 - val_loss: 0.4538\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.4344 - val_accuracy: 0.7792 - val_loss: 0.4532\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4335 - val_accuracy: 0.7776 - val_loss: 0.4536\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7940 - loss: 0.4320 - val_accuracy: 0.7794 - val_loss: 0.4536\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4305 - val_accuracy: 0.7808 - val_loss: 0.4542\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.4331 - val_accuracy: 0.7789 - val_loss: 0.4550\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4291 - val_accuracy: 0.7782 - val_loss: 0.4543\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.4294 - val_accuracy: 0.7778 - val_loss: 0.4564\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4305 - val_accuracy: 0.7789 - val_loss: 0.4542\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4286 - val_accuracy: 0.7782 - val_loss: 0.4531\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.4262 - val_accuracy: 0.7801 - val_loss: 0.4545\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4254 - val_accuracy: 0.7804 - val_loss: 0.4540\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4247 - val_accuracy: 0.7806 - val_loss: 0.4541\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4233 - val_accuracy: 0.7784 - val_loss: 0.4562\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4229 - val_accuracy: 0.7813 - val_loss: 0.4558\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4199 - val_accuracy: 0.7789 - val_loss: 0.4562\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7971 - loss: 0.4220 - val_accuracy: 0.7788 - val_loss: 0.4564\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4221 - val_accuracy: 0.7779 - val_loss: 0.4572\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7985 - loss: 0.4200 - val_accuracy: 0.7812 - val_loss: 0.4549\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4199 - val_accuracy: 0.7814 - val_loss: 0.4563\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4197 - val_accuracy: 0.7793 - val_loss: 0.4584\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4176 - val_accuracy: 0.7803 - val_loss: 0.4567\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4157 - val_accuracy: 0.7799 - val_loss: 0.4565\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4195 - val_accuracy: 0.7792 - val_loss: 0.4574\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4178 - val_accuracy: 0.7793 - val_loss: 0.4566\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4152 - val_accuracy: 0.7807 - val_loss: 0.4571\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4175 - val_accuracy: 0.7813 - val_loss: 0.4581\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4159 - val_accuracy: 0.7806 - val_loss: 0.4566\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.4140 - val_accuracy: 0.7793 - val_loss: 0.4579\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4173 - val_accuracy: 0.7790 - val_loss: 0.4575\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.4143 - val_accuracy: 0.7816 - val_loss: 0.4569\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4121 - val_accuracy: 0.7822 - val_loss: 0.4566\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4129 - val_accuracy: 0.7815 - val_loss: 0.4567\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4153 - val_accuracy: 0.7792 - val_loss: 0.4591\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 0.4157 - val_accuracy: 0.7782 - val_loss: 0.4595\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4121 - val_accuracy: 0.7794 - val_loss: 0.4588\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.4125 - val_accuracy: 0.7802 - val_loss: 0.4591\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4136 - val_accuracy: 0.7797 - val_loss: 0.4593\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4095 - val_accuracy: 0.7793 - val_loss: 0.4591\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4125 - val_accuracy: 0.7800 - val_loss: 0.4584\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4078 - val_accuracy: 0.7816 - val_loss: 0.4568\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4099 - val_accuracy: 0.7812 - val_loss: 0.4585\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4127 - val_accuracy: 0.7803 - val_loss: 0.4586\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.4114 - val_accuracy: 0.7812 - val_loss: 0.4586\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4103 - val_accuracy: 0.7803 - val_loss: 0.4578\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4117 - val_accuracy: 0.7801 - val_loss: 0.4594\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4091 - val_accuracy: 0.7794 - val_loss: 0.4625\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4078 - val_accuracy: 0.7788 - val_loss: 0.4612\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4120 - val_accuracy: 0.7806 - val_loss: 0.4621\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4044 - val_accuracy: 0.7792 - val_loss: 0.4598\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4069 - val_accuracy: 0.7818 - val_loss: 0.4595\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4108 - val_accuracy: 0.7817 - val_loss: 0.4598\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4093 - val_accuracy: 0.7796 - val_loss: 0.4606\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8067 - loss: 0.4058 - val_accuracy: 0.7811 - val_loss: 0.4614\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4080 - val_accuracy: 0.7817 - val_loss: 0.4592\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4070 - val_accuracy: 0.7804 - val_loss: 0.4598\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4059 - val_accuracy: 0.7814 - val_loss: 0.4607\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8099 - loss: 0.4050 - val_accuracy: 0.7797 - val_loss: 0.4624\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4068 - val_accuracy: 0.7792 - val_loss: 0.4623\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4064 - val_accuracy: 0.7811 - val_loss: 0.4623\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 0.4068 - val_accuracy: 0.7801 - val_loss: 0.4622\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4064 - val_accuracy: 0.7808 - val_loss: 0.4638\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4069 - val_accuracy: 0.7798 - val_loss: 0.4631\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4042 - val_accuracy: 0.7802 - val_loss: 0.4615\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4080 - val_accuracy: 0.7808 - val_loss: 0.4610\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4033 - val_accuracy: 0.7812 - val_loss: 0.4616\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8098 - loss: 0.4025 - val_accuracy: 0.7812 - val_loss: 0.4606\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.4055 - val_accuracy: 0.7843 - val_loss: 0.4591\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4043 - val_accuracy: 0.7816 - val_loss: 0.4634\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4019 - val_accuracy: 0.7830 - val_loss: 0.4609\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4032 - val_accuracy: 0.7809 - val_loss: 0.4629\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4033 - val_accuracy: 0.7810 - val_loss: 0.4637\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4066 - val_accuracy: 0.7803 - val_loss: 0.4618\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4020 - val_accuracy: 0.7823 - val_loss: 0.4622\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4018 - val_accuracy: 0.7817 - val_loss: 0.4629\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4033 - val_accuracy: 0.7830 - val_loss: 0.4623\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4023 - val_accuracy: 0.7809 - val_loss: 0.4624\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.3989 - val_accuracy: 0.7801 - val_loss: 0.4625\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.4001 - val_accuracy: 0.7808 - val_loss: 0.4634\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4032 - val_accuracy: 0.7801 - val_loss: 0.4647\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4012 - val_accuracy: 0.7825 - val_loss: 0.4628\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4006 - val_accuracy: 0.7807 - val_loss: 0.4644\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4004 - val_accuracy: 0.7817 - val_loss: 0.4628\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4008 - val_accuracy: 0.7806 - val_loss: 0.4649\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4007 - val_accuracy: 0.7816 - val_loss: 0.4636\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8147 - loss: 0.3986 - val_accuracy: 0.7818 - val_loss: 0.4641\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4023 - val_accuracy: 0.7805 - val_loss: 0.4652\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4046 - val_accuracy: 0.7819 - val_loss: 0.4651\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.4007 - val_accuracy: 0.7816 - val_loss: 0.4661\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.3998 - val_accuracy: 0.7815 - val_loss: 0.4644\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.3982 - val_accuracy: 0.7824 - val_loss: 0.4645\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.3971 - val_accuracy: 0.7816 - val_loss: 0.4642\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.3963 - val_accuracy: 0.7829 - val_loss: 0.4638\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.3986 - val_accuracy: 0.7812 - val_loss: 0.4647\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.3995 - val_accuracy: 0.7816 - val_loss: 0.4649\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.3982 - val_accuracy: 0.7820 - val_loss: 0.4647\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.3971 - val_accuracy: 0.7828 - val_loss: 0.4646\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.3974 - val_accuracy: 0.7821 - val_loss: 0.4667\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.3968 - val_accuracy: 0.7827 - val_loss: 0.4648\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.3997 - val_accuracy: 0.7817 - val_loss: 0.4651\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3995 - val_accuracy: 0.7824 - val_loss: 0.4664\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.3968 - val_accuracy: 0.7832 - val_loss: 0.4641\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.3985 - val_accuracy: 0.7831 - val_loss: 0.4651\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.3956 - val_accuracy: 0.7803 - val_loss: 0.4664\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3957 - val_accuracy: 0.7831 - val_loss: 0.4648\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3968 - val_accuracy: 0.7817 - val_loss: 0.4656\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.3955 - val_accuracy: 0.7827 - val_loss: 0.4657\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 21/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.4910 - val_accuracy: 0.7769 - val_loss: 0.4583\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.4676 - val_accuracy: 0.7765 - val_loss: 0.4571\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.4579 - val_accuracy: 0.7776 - val_loss: 0.4555\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7785 - loss: 0.4561 - val_accuracy: 0.7757 - val_loss: 0.4564\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4533 - val_accuracy: 0.7769 - val_loss: 0.4551\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7800 - loss: 0.4525 - val_accuracy: 0.7782 - val_loss: 0.4554\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.4475 - val_accuracy: 0.7774 - val_loss: 0.4558\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4471 - val_accuracy: 0.7775 - val_loss: 0.4552\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4461 - val_accuracy: 0.7777 - val_loss: 0.4553\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.4424 - val_accuracy: 0.7768 - val_loss: 0.4543\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4425 - val_accuracy: 0.7775 - val_loss: 0.4551\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.4385 - val_accuracy: 0.7753 - val_loss: 0.4578\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4376 - val_accuracy: 0.7768 - val_loss: 0.4561\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4378 - val_accuracy: 0.7760 - val_loss: 0.4552\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4342 - val_accuracy: 0.7791 - val_loss: 0.4551\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.4340 - val_accuracy: 0.7782 - val_loss: 0.4563\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.4346 - val_accuracy: 0.7763 - val_loss: 0.4557\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4340 - val_accuracy: 0.7780 - val_loss: 0.4551\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7930 - loss: 0.4307 - val_accuracy: 0.7775 - val_loss: 0.4560\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.4312 - val_accuracy: 0.7751 - val_loss: 0.4561\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4263 - val_accuracy: 0.7771 - val_loss: 0.4549\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.4255 - val_accuracy: 0.7757 - val_loss: 0.4562\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.4285 - val_accuracy: 0.7773 - val_loss: 0.4560\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.4284 - val_accuracy: 0.7777 - val_loss: 0.4553\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4250 - val_accuracy: 0.7770 - val_loss: 0.4574\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4236 - val_accuracy: 0.7774 - val_loss: 0.4572\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4238 - val_accuracy: 0.7743 - val_loss: 0.4581\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7986 - loss: 0.4214 - val_accuracy: 0.7780 - val_loss: 0.4573\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.4237 - val_accuracy: 0.7766 - val_loss: 0.4572\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4240 - val_accuracy: 0.7780 - val_loss: 0.4571\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7995 - loss: 0.4196 - val_accuracy: 0.7782 - val_loss: 0.4583\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4216 - val_accuracy: 0.7765 - val_loss: 0.4583\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4206 - val_accuracy: 0.7762 - val_loss: 0.4574\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4207 - val_accuracy: 0.7775 - val_loss: 0.4578\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4212 - val_accuracy: 0.7762 - val_loss: 0.4589\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.4230 - val_accuracy: 0.7776 - val_loss: 0.4576\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4176 - val_accuracy: 0.7776 - val_loss: 0.4571\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.4165 - val_accuracy: 0.7771 - val_loss: 0.4587\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4149 - val_accuracy: 0.7771 - val_loss: 0.4583\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.4148 - val_accuracy: 0.7764 - val_loss: 0.4585\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4172 - val_accuracy: 0.7753 - val_loss: 0.4596\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4152 - val_accuracy: 0.7765 - val_loss: 0.4597\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4150 - val_accuracy: 0.7777 - val_loss: 0.4607\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4141 - val_accuracy: 0.7761 - val_loss: 0.4618\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4119 - val_accuracy: 0.7762 - val_loss: 0.4604\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4125 - val_accuracy: 0.7777 - val_loss: 0.4621\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4141 - val_accuracy: 0.7787 - val_loss: 0.4583\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8025 - loss: 0.4144 - val_accuracy: 0.7762 - val_loss: 0.4609\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.4137 - val_accuracy: 0.7788 - val_loss: 0.4593\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4151 - val_accuracy: 0.7776 - val_loss: 0.4592\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.4129 - val_accuracy: 0.7789 - val_loss: 0.4593\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4112 - val_accuracy: 0.7796 - val_loss: 0.4586\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.4084 - val_accuracy: 0.7771 - val_loss: 0.4601\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4066 - val_accuracy: 0.7769 - val_loss: 0.4621\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4130 - val_accuracy: 0.7754 - val_loss: 0.4623\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4140 - val_accuracy: 0.7777 - val_loss: 0.4625\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4100 - val_accuracy: 0.7777 - val_loss: 0.4622\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.4109 - val_accuracy: 0.7781 - val_loss: 0.4622\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4121 - val_accuracy: 0.7780 - val_loss: 0.4614\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4125 - val_accuracy: 0.7769 - val_loss: 0.4623\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4099 - val_accuracy: 0.7768 - val_loss: 0.4636\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4096 - val_accuracy: 0.7764 - val_loss: 0.4639\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4086 - val_accuracy: 0.7775 - val_loss: 0.4629\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.4100 - val_accuracy: 0.7772 - val_loss: 0.4644\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4081 - val_accuracy: 0.7785 - val_loss: 0.4623\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4068 - val_accuracy: 0.7778 - val_loss: 0.4631\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4118 - val_accuracy: 0.7773 - val_loss: 0.4631\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4096 - val_accuracy: 0.7771 - val_loss: 0.4629\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4075 - val_accuracy: 0.7787 - val_loss: 0.4627\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.4047 - val_accuracy: 0.7778 - val_loss: 0.4630\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8054 - loss: 0.4113 - val_accuracy: 0.7788 - val_loss: 0.4637\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.4060 - val_accuracy: 0.7790 - val_loss: 0.4633\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4050 - val_accuracy: 0.7788 - val_loss: 0.4644\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4046 - val_accuracy: 0.7786 - val_loss: 0.4633\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4048 - val_accuracy: 0.7781 - val_loss: 0.4623\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4057 - val_accuracy: 0.7792 - val_loss: 0.4636\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4023 - val_accuracy: 0.7787 - val_loss: 0.4639\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4053 - val_accuracy: 0.7773 - val_loss: 0.4662\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4055 - val_accuracy: 0.7786 - val_loss: 0.4643\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4045 - val_accuracy: 0.7790 - val_loss: 0.4642\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4049 - val_accuracy: 0.7773 - val_loss: 0.4636\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4030 - val_accuracy: 0.7776 - val_loss: 0.4663\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4037 - val_accuracy: 0.7782 - val_loss: 0.4640\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4034 - val_accuracy: 0.7788 - val_loss: 0.4637\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4074 - val_accuracy: 0.7774 - val_loss: 0.4648\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4007 - val_accuracy: 0.7778 - val_loss: 0.4663\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4038 - val_accuracy: 0.7771 - val_loss: 0.4643\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4018 - val_accuracy: 0.7780 - val_loss: 0.4645\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4054 - val_accuracy: 0.7782 - val_loss: 0.4658\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4036 - val_accuracy: 0.7791 - val_loss: 0.4650\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4021 - val_accuracy: 0.7782 - val_loss: 0.4654\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4040 - val_accuracy: 0.7776 - val_loss: 0.4665\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4008 - val_accuracy: 0.7768 - val_loss: 0.4655\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4031 - val_accuracy: 0.7780 - val_loss: 0.4651\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4002 - val_accuracy: 0.7770 - val_loss: 0.4649\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4027 - val_accuracy: 0.7781 - val_loss: 0.4648\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4043 - val_accuracy: 0.7794 - val_loss: 0.4645\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.3958 - val_accuracy: 0.7778 - val_loss: 0.4660\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4026 - val_accuracy: 0.7775 - val_loss: 0.4667\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4013 - val_accuracy: 0.7789 - val_loss: 0.4659\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3989 - val_accuracy: 0.7780 - val_loss: 0.4653\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.3979 - val_accuracy: 0.7776 - val_loss: 0.4652\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4035 - val_accuracy: 0.7796 - val_loss: 0.4651\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.3985 - val_accuracy: 0.7792 - val_loss: 0.4648\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4004 - val_accuracy: 0.7785 - val_loss: 0.4672\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.3999 - val_accuracy: 0.7774 - val_loss: 0.4654\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.4012 - val_accuracy: 0.7802 - val_loss: 0.4656\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3999 - val_accuracy: 0.7788 - val_loss: 0.4655\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.4000 - val_accuracy: 0.7786 - val_loss: 0.4657\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4007 - val_accuracy: 0.7786 - val_loss: 0.4671\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4036 - val_accuracy: 0.7792 - val_loss: 0.4665\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3971 - val_accuracy: 0.7785 - val_loss: 0.4670\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.4013 - val_accuracy: 0.7779 - val_loss: 0.4680\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.3977 - val_accuracy: 0.7790 - val_loss: 0.4670\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.3987 - val_accuracy: 0.7802 - val_loss: 0.4660\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.3984 - val_accuracy: 0.7793 - val_loss: 0.4667\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.4020 - val_accuracy: 0.7797 - val_loss: 0.4653\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.4009 - val_accuracy: 0.7794 - val_loss: 0.4669\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.3968 - val_accuracy: 0.7794 - val_loss: 0.4657\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3981 - val_accuracy: 0.7790 - val_loss: 0.4672\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 22/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7631 - loss: 0.4943 - val_accuracy: 0.7786 - val_loss: 0.4569\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.4716 - val_accuracy: 0.7779 - val_loss: 0.4536\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.4648 - val_accuracy: 0.7771 - val_loss: 0.4539\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.4615 - val_accuracy: 0.7778 - val_loss: 0.4532\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.4540 - val_accuracy: 0.7783 - val_loss: 0.4514\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.4530 - val_accuracy: 0.7769 - val_loss: 0.4538\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.4511 - val_accuracy: 0.7778 - val_loss: 0.4522\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4503 - val_accuracy: 0.7781 - val_loss: 0.4521\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.4486 - val_accuracy: 0.7773 - val_loss: 0.4516\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7823 - loss: 0.4467 - val_accuracy: 0.7770 - val_loss: 0.4528\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4422 - val_accuracy: 0.7771 - val_loss: 0.4515\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.4451 - val_accuracy: 0.7769 - val_loss: 0.4519\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.4423 - val_accuracy: 0.7768 - val_loss: 0.4521\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4401 - val_accuracy: 0.7762 - val_loss: 0.4529\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4367 - val_accuracy: 0.7756 - val_loss: 0.4534\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.4377 - val_accuracy: 0.7763 - val_loss: 0.4536\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4387 - val_accuracy: 0.7764 - val_loss: 0.4531\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.4367 - val_accuracy: 0.7765 - val_loss: 0.4528\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.4335 - val_accuracy: 0.7773 - val_loss: 0.4533\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4341 - val_accuracy: 0.7769 - val_loss: 0.4541\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4313 - val_accuracy: 0.7768 - val_loss: 0.4536\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4327 - val_accuracy: 0.7762 - val_loss: 0.4559\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.4293 - val_accuracy: 0.7753 - val_loss: 0.4553\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4299 - val_accuracy: 0.7750 - val_loss: 0.4567\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7936 - loss: 0.4301 - val_accuracy: 0.7751 - val_loss: 0.4552\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4289 - val_accuracy: 0.7772 - val_loss: 0.4552\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4306 - val_accuracy: 0.7756 - val_loss: 0.4545\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4269 - val_accuracy: 0.7775 - val_loss: 0.4556\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4261 - val_accuracy: 0.7772 - val_loss: 0.4545\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4238 - val_accuracy: 0.7782 - val_loss: 0.4551\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4265 - val_accuracy: 0.7760 - val_loss: 0.4565\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.4257 - val_accuracy: 0.7774 - val_loss: 0.4553\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4276 - val_accuracy: 0.7748 - val_loss: 0.4570\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4256 - val_accuracy: 0.7769 - val_loss: 0.4561\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4260 - val_accuracy: 0.7771 - val_loss: 0.4549\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4210 - val_accuracy: 0.7764 - val_loss: 0.4559\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4218 - val_accuracy: 0.7782 - val_loss: 0.4554\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4240 - val_accuracy: 0.7774 - val_loss: 0.4563\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4199 - val_accuracy: 0.7780 - val_loss: 0.4564\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4178 - val_accuracy: 0.7766 - val_loss: 0.4566\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4202 - val_accuracy: 0.7780 - val_loss: 0.4569\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4205 - val_accuracy: 0.7772 - val_loss: 0.4572\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7994 - loss: 0.4216 - val_accuracy: 0.7794 - val_loss: 0.4551\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.4199 - val_accuracy: 0.7782 - val_loss: 0.4572\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4210 - val_accuracy: 0.7779 - val_loss: 0.4570\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4205 - val_accuracy: 0.7781 - val_loss: 0.4581\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8011 - loss: 0.4190 - val_accuracy: 0.7801 - val_loss: 0.4545\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4132 - val_accuracy: 0.7782 - val_loss: 0.4570\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.4165 - val_accuracy: 0.7782 - val_loss: 0.4555\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4171 - val_accuracy: 0.7753 - val_loss: 0.4578\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8048 - loss: 0.4142 - val_accuracy: 0.7793 - val_loss: 0.4568\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4176 - val_accuracy: 0.7786 - val_loss: 0.4575\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4133 - val_accuracy: 0.7774 - val_loss: 0.4560\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4139 - val_accuracy: 0.7796 - val_loss: 0.4583\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.4131 - val_accuracy: 0.7761 - val_loss: 0.4583\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4158 - val_accuracy: 0.7772 - val_loss: 0.4585\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4147 - val_accuracy: 0.7758 - val_loss: 0.4584\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4118 - val_accuracy: 0.7794 - val_loss: 0.4562\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4129 - val_accuracy: 0.7774 - val_loss: 0.4579\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4090 - val_accuracy: 0.7768 - val_loss: 0.4588\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.4140 - val_accuracy: 0.7785 - val_loss: 0.4603\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4117 - val_accuracy: 0.7787 - val_loss: 0.4576\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4130 - val_accuracy: 0.7785 - val_loss: 0.4582\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4147 - val_accuracy: 0.7781 - val_loss: 0.4582\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4099 - val_accuracy: 0.7794 - val_loss: 0.4580\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4152 - val_accuracy: 0.7775 - val_loss: 0.4603\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4141 - val_accuracy: 0.7805 - val_loss: 0.4589\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4092 - val_accuracy: 0.7753 - val_loss: 0.4600\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.4107 - val_accuracy: 0.7786 - val_loss: 0.4590\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4090 - val_accuracy: 0.7790 - val_loss: 0.4602\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4091 - val_accuracy: 0.7790 - val_loss: 0.4609\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4076 - val_accuracy: 0.7771 - val_loss: 0.4611\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4066 - val_accuracy: 0.7779 - val_loss: 0.4598\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4107 - val_accuracy: 0.7792 - val_loss: 0.4604\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.4073 - val_accuracy: 0.7806 - val_loss: 0.4605\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4082 - val_accuracy: 0.7781 - val_loss: 0.4623\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4057 - val_accuracy: 0.7797 - val_loss: 0.4588\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4086 - val_accuracy: 0.7780 - val_loss: 0.4606\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4080 - val_accuracy: 0.7778 - val_loss: 0.4607\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4071 - val_accuracy: 0.7802 - val_loss: 0.4616\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4072 - val_accuracy: 0.7776 - val_loss: 0.4627\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4070 - val_accuracy: 0.7781 - val_loss: 0.4615\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4066 - val_accuracy: 0.7788 - val_loss: 0.4617\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4050 - val_accuracy: 0.7802 - val_loss: 0.4620\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4046 - val_accuracy: 0.7794 - val_loss: 0.4620\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4048 - val_accuracy: 0.7792 - val_loss: 0.4607\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4065 - val_accuracy: 0.7781 - val_loss: 0.4619\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4051 - val_accuracy: 0.7789 - val_loss: 0.4617\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4053 - val_accuracy: 0.7789 - val_loss: 0.4622\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4059 - val_accuracy: 0.7790 - val_loss: 0.4617\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8099 - loss: 0.4041 - val_accuracy: 0.7784 - val_loss: 0.4623\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.4060 - val_accuracy: 0.7791 - val_loss: 0.4616\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4024 - val_accuracy: 0.7802 - val_loss: 0.4630\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4037 - val_accuracy: 0.7805 - val_loss: 0.4618\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4040 - val_accuracy: 0.7804 - val_loss: 0.4619\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4045 - val_accuracy: 0.7793 - val_loss: 0.4633\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4038 - val_accuracy: 0.7783 - val_loss: 0.4636\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4020 - val_accuracy: 0.7820 - val_loss: 0.4613\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4018 - val_accuracy: 0.7808 - val_loss: 0.4615\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4035 - val_accuracy: 0.7798 - val_loss: 0.4624\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4053 - val_accuracy: 0.7769 - val_loss: 0.4636\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.3993 - val_accuracy: 0.7786 - val_loss: 0.4626\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8118 - loss: 0.4015 - val_accuracy: 0.7793 - val_loss: 0.4629\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4027 - val_accuracy: 0.7808 - val_loss: 0.4627\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4023 - val_accuracy: 0.7822 - val_loss: 0.4597\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4054 - val_accuracy: 0.7811 - val_loss: 0.4607\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.3998 - val_accuracy: 0.7790 - val_loss: 0.4645\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.4006 - val_accuracy: 0.7797 - val_loss: 0.4631\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.3975 - val_accuracy: 0.7805 - val_loss: 0.4634\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4003 - val_accuracy: 0.7789 - val_loss: 0.4635\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4001 - val_accuracy: 0.7812 - val_loss: 0.4634\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4069 - val_accuracy: 0.7791 - val_loss: 0.4655\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.4046 - val_accuracy: 0.7794 - val_loss: 0.4619\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.4002 - val_accuracy: 0.7812 - val_loss: 0.4625\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.4001 - val_accuracy: 0.7796 - val_loss: 0.4627\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8135 - loss: 0.3985 - val_accuracy: 0.7797 - val_loss: 0.4632\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.3993 - val_accuracy: 0.7789 - val_loss: 0.4639\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4052 - val_accuracy: 0.7802 - val_loss: 0.4632\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.3997 - val_accuracy: 0.7804 - val_loss: 0.4629\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.3977 - val_accuracy: 0.7822 - val_loss: 0.4616\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 23/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7647 - loss: 0.4927 - val_accuracy: 0.7789 - val_loss: 0.4559\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.4675 - val_accuracy: 0.7795 - val_loss: 0.4546\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.4632 - val_accuracy: 0.7815 - val_loss: 0.4538\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7761 - loss: 0.4594 - val_accuracy: 0.7820 - val_loss: 0.4524\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4542 - val_accuracy: 0.7839 - val_loss: 0.4510\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4512 - val_accuracy: 0.7819 - val_loss: 0.4510\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.4476 - val_accuracy: 0.7821 - val_loss: 0.4520\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4482 - val_accuracy: 0.7806 - val_loss: 0.4508\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7829 - loss: 0.4461 - val_accuracy: 0.7812 - val_loss: 0.4502\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.4470 - val_accuracy: 0.7822 - val_loss: 0.4509\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.4416 - val_accuracy: 0.7809 - val_loss: 0.4515\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.4383 - val_accuracy: 0.7834 - val_loss: 0.4497\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.4392 - val_accuracy: 0.7818 - val_loss: 0.4496\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.4405 - val_accuracy: 0.7807 - val_loss: 0.4521\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.4348 - val_accuracy: 0.7814 - val_loss: 0.4515\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.4370 - val_accuracy: 0.7800 - val_loss: 0.4512\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4345 - val_accuracy: 0.7805 - val_loss: 0.4508\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4327 - val_accuracy: 0.7793 - val_loss: 0.4511\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4341 - val_accuracy: 0.7799 - val_loss: 0.4520\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7936 - loss: 0.4314 - val_accuracy: 0.7797 - val_loss: 0.4519\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.4309 - val_accuracy: 0.7810 - val_loss: 0.4517\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4303 - val_accuracy: 0.7817 - val_loss: 0.4515\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7947 - loss: 0.4289 - val_accuracy: 0.7812 - val_loss: 0.4518\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.4250 - val_accuracy: 0.7813 - val_loss: 0.4524\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.4275 - val_accuracy: 0.7802 - val_loss: 0.4524\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7941 - loss: 0.4291 - val_accuracy: 0.7799 - val_loss: 0.4520\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4265 - val_accuracy: 0.7805 - val_loss: 0.4518\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7971 - loss: 0.4233 - val_accuracy: 0.7812 - val_loss: 0.4527\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7977 - loss: 0.4247 - val_accuracy: 0.7795 - val_loss: 0.4523\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7984 - loss: 0.4230 - val_accuracy: 0.7806 - val_loss: 0.4522\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4222 - val_accuracy: 0.7792 - val_loss: 0.4539\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4220 - val_accuracy: 0.7801 - val_loss: 0.4538\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4227 - val_accuracy: 0.7807 - val_loss: 0.4549\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4225 - val_accuracy: 0.7803 - val_loss: 0.4547\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8003 - loss: 0.4180 - val_accuracy: 0.7809 - val_loss: 0.4528\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.4210 - val_accuracy: 0.7816 - val_loss: 0.4531\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4216 - val_accuracy: 0.7791 - val_loss: 0.4547\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.4182 - val_accuracy: 0.7797 - val_loss: 0.4530\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.4187 - val_accuracy: 0.7809 - val_loss: 0.4534\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4210 - val_accuracy: 0.7817 - val_loss: 0.4532\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8008 - loss: 0.4198 - val_accuracy: 0.7818 - val_loss: 0.4532\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8018 - loss: 0.4170 - val_accuracy: 0.7806 - val_loss: 0.4528\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.4187 - val_accuracy: 0.7797 - val_loss: 0.4536\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4160 - val_accuracy: 0.7811 - val_loss: 0.4530\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.4140 - val_accuracy: 0.7827 - val_loss: 0.4538\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4144 - val_accuracy: 0.7815 - val_loss: 0.4547\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4158 - val_accuracy: 0.7808 - val_loss: 0.4541\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4138 - val_accuracy: 0.7830 - val_loss: 0.4534\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.4135 - val_accuracy: 0.7829 - val_loss: 0.4528\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4159 - val_accuracy: 0.7830 - val_loss: 0.4527\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.4146 - val_accuracy: 0.7810 - val_loss: 0.4539\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.4148 - val_accuracy: 0.7793 - val_loss: 0.4557\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4115 - val_accuracy: 0.7826 - val_loss: 0.4530\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4114 - val_accuracy: 0.7814 - val_loss: 0.4549\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.4155 - val_accuracy: 0.7793 - val_loss: 0.4550\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4117 - val_accuracy: 0.7806 - val_loss: 0.4557\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4143 - val_accuracy: 0.7807 - val_loss: 0.4549\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4153 - val_accuracy: 0.7807 - val_loss: 0.4534\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4097 - val_accuracy: 0.7809 - val_loss: 0.4534\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4104 - val_accuracy: 0.7825 - val_loss: 0.4542\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4070 - val_accuracy: 0.7828 - val_loss: 0.4524\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.4061 - val_accuracy: 0.7832 - val_loss: 0.4540\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4072 - val_accuracy: 0.7800 - val_loss: 0.4558\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4117 - val_accuracy: 0.7809 - val_loss: 0.4546\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.4084 - val_accuracy: 0.7812 - val_loss: 0.4549\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4093 - val_accuracy: 0.7811 - val_loss: 0.4554\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4091 - val_accuracy: 0.7805 - val_loss: 0.4561\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4115 - val_accuracy: 0.7814 - val_loss: 0.4554\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4080 - val_accuracy: 0.7814 - val_loss: 0.4564\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.4099 - val_accuracy: 0.7809 - val_loss: 0.4564\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4080 - val_accuracy: 0.7817 - val_loss: 0.4557\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4085 - val_accuracy: 0.7809 - val_loss: 0.4562\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4050 - val_accuracy: 0.7820 - val_loss: 0.4574\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4098 - val_accuracy: 0.7818 - val_loss: 0.4566\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4064 - val_accuracy: 0.7789 - val_loss: 0.4572\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4052 - val_accuracy: 0.7805 - val_loss: 0.4559\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4056 - val_accuracy: 0.7813 - val_loss: 0.4566\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4037 - val_accuracy: 0.7819 - val_loss: 0.4549\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4064 - val_accuracy: 0.7812 - val_loss: 0.4559\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4052 - val_accuracy: 0.7814 - val_loss: 0.4554\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.4041 - val_accuracy: 0.7818 - val_loss: 0.4554\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4036 - val_accuracy: 0.7829 - val_loss: 0.4542\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4052 - val_accuracy: 0.7811 - val_loss: 0.4546\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4044 - val_accuracy: 0.7802 - val_loss: 0.4546\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4046 - val_accuracy: 0.7827 - val_loss: 0.4550\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4016 - val_accuracy: 0.7803 - val_loss: 0.4548\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4045 - val_accuracy: 0.7822 - val_loss: 0.4544\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4027 - val_accuracy: 0.7818 - val_loss: 0.4555\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4057 - val_accuracy: 0.7821 - val_loss: 0.4551\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4054 - val_accuracy: 0.7820 - val_loss: 0.4559\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8088 - loss: 0.4048 - val_accuracy: 0.7825 - val_loss: 0.4535\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4010 - val_accuracy: 0.7822 - val_loss: 0.4562\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4043 - val_accuracy: 0.7834 - val_loss: 0.4557\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4035 - val_accuracy: 0.7837 - val_loss: 0.4563\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4021 - val_accuracy: 0.7813 - val_loss: 0.4565\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.4003 - val_accuracy: 0.7832 - val_loss: 0.4566\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4048 - val_accuracy: 0.7840 - val_loss: 0.4563\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4016 - val_accuracy: 0.7835 - val_loss: 0.4560\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.4004 - val_accuracy: 0.7814 - val_loss: 0.4572\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4040 - val_accuracy: 0.7814 - val_loss: 0.4553\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4007 - val_accuracy: 0.7846 - val_loss: 0.4550\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.4034 - val_accuracy: 0.7814 - val_loss: 0.4574\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.3991 - val_accuracy: 0.7842 - val_loss: 0.4570\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4019 - val_accuracy: 0.7829 - val_loss: 0.4571\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4013 - val_accuracy: 0.7826 - val_loss: 0.4573\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4030 - val_accuracy: 0.7819 - val_loss: 0.4583\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8117 - loss: 0.4006 - val_accuracy: 0.7834 - val_loss: 0.4565\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.3978 - val_accuracy: 0.7811 - val_loss: 0.4588\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4000 - val_accuracy: 0.7800 - val_loss: 0.4583\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4025 - val_accuracy: 0.7820 - val_loss: 0.4568\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.3975 - val_accuracy: 0.7820 - val_loss: 0.4582\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.3959 - val_accuracy: 0.7814 - val_loss: 0.4561\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.3991 - val_accuracy: 0.7823 - val_loss: 0.4568\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.3987 - val_accuracy: 0.7827 - val_loss: 0.4571\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.3991 - val_accuracy: 0.7834 - val_loss: 0.4580\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8147 - loss: 0.3986 - val_accuracy: 0.7819 - val_loss: 0.4573\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.3998 - val_accuracy: 0.7835 - val_loss: 0.4566\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.3973 - val_accuracy: 0.7824 - val_loss: 0.4565\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4006 - val_accuracy: 0.7827 - val_loss: 0.4581\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.3953 - val_accuracy: 0.7841 - val_loss: 0.4583\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training model 24/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.4883 - val_accuracy: 0.7791 - val_loss: 0.4558\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7712 - loss: 0.4695 - val_accuracy: 0.7784 - val_loss: 0.4539\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7742 - loss: 0.4609 - val_accuracy: 0.7830 - val_loss: 0.4511\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.4556 - val_accuracy: 0.7821 - val_loss: 0.4495\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4526 - val_accuracy: 0.7851 - val_loss: 0.4483\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.4491 - val_accuracy: 0.7806 - val_loss: 0.4502\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7810 - loss: 0.4494 - val_accuracy: 0.7823 - val_loss: 0.4483\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.4473 - val_accuracy: 0.7832 - val_loss: 0.4490\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 0.4464 - val_accuracy: 0.7826 - val_loss: 0.4493\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.4440 - val_accuracy: 0.7828 - val_loss: 0.4491\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.4435 - val_accuracy: 0.7821 - val_loss: 0.4486\n",
      "Epoch 12/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.4420 - val_accuracy: 0.7813 - val_loss: 0.4491\n",
      "Epoch 13/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7912 - loss: 0.4350 - val_accuracy: 0.7835 - val_loss: 0.4483\n",
      "Epoch 14/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4372 - val_accuracy: 0.7812 - val_loss: 0.4494\n",
      "Epoch 15/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.4346 - val_accuracy: 0.7835 - val_loss: 0.4492\n",
      "Epoch 16/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.4342 - val_accuracy: 0.7793 - val_loss: 0.4511\n",
      "Epoch 17/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4364 - val_accuracy: 0.7820 - val_loss: 0.4500\n",
      "Epoch 18/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4301 - val_accuracy: 0.7809 - val_loss: 0.4499\n",
      "Epoch 19/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4333 - val_accuracy: 0.7814 - val_loss: 0.4492\n",
      "Epoch 20/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4277 - val_accuracy: 0.7813 - val_loss: 0.4505\n",
      "Epoch 21/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.4296 - val_accuracy: 0.7832 - val_loss: 0.4498\n",
      "Epoch 22/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.4249 - val_accuracy: 0.7815 - val_loss: 0.4512\n",
      "Epoch 23/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.4276 - val_accuracy: 0.7810 - val_loss: 0.4508\n",
      "Epoch 24/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.4277 - val_accuracy: 0.7812 - val_loss: 0.4502\n",
      "Epoch 25/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.4260 - val_accuracy: 0.7789 - val_loss: 0.4513\n",
      "Epoch 26/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4215 - val_accuracy: 0.7809 - val_loss: 0.4521\n",
      "Epoch 27/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4237 - val_accuracy: 0.7807 - val_loss: 0.4511\n",
      "Epoch 28/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4253 - val_accuracy: 0.7802 - val_loss: 0.4513\n",
      "Epoch 29/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.4207 - val_accuracy: 0.7812 - val_loss: 0.4510\n",
      "Epoch 30/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4239 - val_accuracy: 0.7808 - val_loss: 0.4527\n",
      "Epoch 31/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.4232 - val_accuracy: 0.7829 - val_loss: 0.4509\n",
      "Epoch 32/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4217 - val_accuracy: 0.7820 - val_loss: 0.4526\n",
      "Epoch 33/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4207 - val_accuracy: 0.7812 - val_loss: 0.4523\n",
      "Epoch 34/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4235 - val_accuracy: 0.7807 - val_loss: 0.4534\n",
      "Epoch 35/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4177 - val_accuracy: 0.7815 - val_loss: 0.4532\n",
      "Epoch 36/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4201 - val_accuracy: 0.7808 - val_loss: 0.4512\n",
      "Epoch 37/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.4155 - val_accuracy: 0.7798 - val_loss: 0.4537\n",
      "Epoch 38/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4191 - val_accuracy: 0.7822 - val_loss: 0.4516\n",
      "Epoch 39/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4122 - val_accuracy: 0.7823 - val_loss: 0.4535\n",
      "Epoch 40/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4162 - val_accuracy: 0.7791 - val_loss: 0.4549\n",
      "Epoch 41/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4140 - val_accuracy: 0.7827 - val_loss: 0.4540\n",
      "Epoch 42/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4189 - val_accuracy: 0.7822 - val_loss: 0.4537\n",
      "Epoch 43/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4158 - val_accuracy: 0.7823 - val_loss: 0.4537\n",
      "Epoch 44/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.4156 - val_accuracy: 0.7818 - val_loss: 0.4531\n",
      "Epoch 45/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 0.4124 - val_accuracy: 0.7816 - val_loss: 0.4559\n",
      "Epoch 46/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4157 - val_accuracy: 0.7818 - val_loss: 0.4537\n",
      "Epoch 47/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4152 - val_accuracy: 0.7820 - val_loss: 0.4537\n",
      "Epoch 48/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4109 - val_accuracy: 0.7819 - val_loss: 0.4536\n",
      "Epoch 49/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4110 - val_accuracy: 0.7818 - val_loss: 0.4542\n",
      "Epoch 50/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4123 - val_accuracy: 0.7832 - val_loss: 0.4535\n",
      "Epoch 51/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4093 - val_accuracy: 0.7829 - val_loss: 0.4535\n",
      "Epoch 52/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4127 - val_accuracy: 0.7822 - val_loss: 0.4549\n",
      "Epoch 53/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4136 - val_accuracy: 0.7824 - val_loss: 0.4553\n",
      "Epoch 54/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8059 - loss: 0.4105 - val_accuracy: 0.7814 - val_loss: 0.4551\n",
      "Epoch 55/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4105 - val_accuracy: 0.7814 - val_loss: 0.4545\n",
      "Epoch 56/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4106 - val_accuracy: 0.7817 - val_loss: 0.4553\n",
      "Epoch 57/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4093 - val_accuracy: 0.7824 - val_loss: 0.4547\n",
      "Epoch 58/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4122 - val_accuracy: 0.7803 - val_loss: 0.4565\n",
      "Epoch 59/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4106 - val_accuracy: 0.7826 - val_loss: 0.4556\n",
      "Epoch 60/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4088 - val_accuracy: 0.7823 - val_loss: 0.4541\n",
      "Epoch 61/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4089 - val_accuracy: 0.7846 - val_loss: 0.4551\n",
      "Epoch 62/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4105 - val_accuracy: 0.7823 - val_loss: 0.4542\n",
      "Epoch 63/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4095 - val_accuracy: 0.7818 - val_loss: 0.4556\n",
      "Epoch 64/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4084 - val_accuracy: 0.7825 - val_loss: 0.4552\n",
      "Epoch 65/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4073 - val_accuracy: 0.7827 - val_loss: 0.4565\n",
      "Epoch 66/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8072 - loss: 0.4075 - val_accuracy: 0.7816 - val_loss: 0.4549\n",
      "Epoch 67/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8080 - loss: 0.4080 - val_accuracy: 0.7814 - val_loss: 0.4561\n",
      "Epoch 68/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4083 - val_accuracy: 0.7822 - val_loss: 0.4549\n",
      "Epoch 69/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4089 - val_accuracy: 0.7818 - val_loss: 0.4553\n",
      "Epoch 70/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4105 - val_accuracy: 0.7831 - val_loss: 0.4561\n",
      "Epoch 71/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.4061 - val_accuracy: 0.7820 - val_loss: 0.4564\n",
      "Epoch 72/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4066 - val_accuracy: 0.7821 - val_loss: 0.4559\n",
      "Epoch 73/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4086 - val_accuracy: 0.7844 - val_loss: 0.4548\n",
      "Epoch 74/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4058 - val_accuracy: 0.7818 - val_loss: 0.4557\n",
      "Epoch 75/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.4027 - val_accuracy: 0.7824 - val_loss: 0.4542\n",
      "Epoch 76/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4051 - val_accuracy: 0.7834 - val_loss: 0.4554\n",
      "Epoch 77/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4039 - val_accuracy: 0.7840 - val_loss: 0.4539\n",
      "Epoch 78/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4052 - val_accuracy: 0.7826 - val_loss: 0.4570\n",
      "Epoch 79/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4063 - val_accuracy: 0.7829 - val_loss: 0.4549\n",
      "Epoch 80/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.4046 - val_accuracy: 0.7812 - val_loss: 0.4562\n",
      "Epoch 81/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.4016 - val_accuracy: 0.7828 - val_loss: 0.4568\n",
      "Epoch 82/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.4029 - val_accuracy: 0.7818 - val_loss: 0.4585\n",
      "Epoch 83/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4035 - val_accuracy: 0.7834 - val_loss: 0.4559\n",
      "Epoch 84/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4044 - val_accuracy: 0.7820 - val_loss: 0.4569\n",
      "Epoch 85/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4042 - val_accuracy: 0.7830 - val_loss: 0.4574\n",
      "Epoch 86/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4044 - val_accuracy: 0.7833 - val_loss: 0.4557\n",
      "Epoch 87/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8104 - loss: 0.4035 - val_accuracy: 0.7822 - val_loss: 0.4587\n",
      "Epoch 88/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4035 - val_accuracy: 0.7824 - val_loss: 0.4590\n",
      "Epoch 89/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4006 - val_accuracy: 0.7818 - val_loss: 0.4583\n",
      "Epoch 90/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4053 - val_accuracy: 0.7841 - val_loss: 0.4563\n",
      "Epoch 91/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4027 - val_accuracy: 0.7813 - val_loss: 0.4559\n",
      "Epoch 92/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8104 - loss: 0.4042 - val_accuracy: 0.7840 - val_loss: 0.4543\n",
      "Epoch 93/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.4030 - val_accuracy: 0.7839 - val_loss: 0.4565\n",
      "Epoch 94/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.4007 - val_accuracy: 0.7844 - val_loss: 0.4568\n",
      "Epoch 95/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 0.3982 - val_accuracy: 0.7825 - val_loss: 0.4570\n",
      "Epoch 96/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4010 - val_accuracy: 0.7843 - val_loss: 0.4547\n",
      "Epoch 97/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.3996 - val_accuracy: 0.7812 - val_loss: 0.4565\n",
      "Epoch 98/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4028 - val_accuracy: 0.7818 - val_loss: 0.4567\n",
      "Epoch 99/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4035 - val_accuracy: 0.7815 - val_loss: 0.4563\n",
      "Epoch 100/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4022 - val_accuracy: 0.7805 - val_loss: 0.4564\n",
      "Epoch 101/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3983 - val_accuracy: 0.7844 - val_loss: 0.4584\n",
      "Epoch 102/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8132 - loss: 0.4001 - val_accuracy: 0.7833 - val_loss: 0.4569\n",
      "Epoch 103/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4032 - val_accuracy: 0.7822 - val_loss: 0.4566\n",
      "Epoch 104/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.3996 - val_accuracy: 0.7821 - val_loss: 0.4574\n",
      "Epoch 105/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3989 - val_accuracy: 0.7820 - val_loss: 0.4587\n",
      "Epoch 106/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.3976 - val_accuracy: 0.7811 - val_loss: 0.4591\n",
      "Epoch 107/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.3998 - val_accuracy: 0.7815 - val_loss: 0.4581\n",
      "Epoch 108/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4021 - val_accuracy: 0.7825 - val_loss: 0.4571\n",
      "Epoch 109/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4000 - val_accuracy: 0.7845 - val_loss: 0.4562\n",
      "Epoch 110/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.3968 - val_accuracy: 0.7827 - val_loss: 0.4601\n",
      "Epoch 111/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8155 - loss: 0.3974 - val_accuracy: 0.7819 - val_loss: 0.4590\n",
      "Epoch 112/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.4005 - val_accuracy: 0.7813 - val_loss: 0.4585\n",
      "Epoch 113/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4026 - val_accuracy: 0.7821 - val_loss: 0.4578\n",
      "Epoch 114/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.3968 - val_accuracy: 0.7835 - val_loss: 0.4576\n",
      "Epoch 115/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.3961 - val_accuracy: 0.7826 - val_loss: 0.4576\n",
      "Epoch 116/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.3964 - val_accuracy: 0.7819 - val_loss: 0.4577\n",
      "Epoch 117/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8176 - loss: 0.3951 - val_accuracy: 0.7807 - val_loss: 0.4594\n",
      "Epoch 118/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.4000 - val_accuracy: 0.7832 - val_loss: 0.4584\n",
      "Epoch 119/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8124 - loss: 0.4006 - val_accuracy: 0.7846 - val_loss: 0.4574\n",
      "Epoch 120/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.3999 - val_accuracy: 0.7850 - val_loss: 0.4561\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Training model 25/90...\n",
      "Epoch 1/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.4843 - val_accuracy: 0.7808 - val_loss: 0.4506\n",
      "Epoch 2/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.4665 - val_accuracy: 0.7786 - val_loss: 0.4507\n",
      "Epoch 3/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.4603 - val_accuracy: 0.7805 - val_loss: 0.4489\n",
      "Epoch 4/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.4550 - val_accuracy: 0.7796 - val_loss: 0.4478\n",
      "Epoch 5/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.4492 - val_accuracy: 0.7787 - val_loss: 0.4472\n",
      "Epoch 6/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.4486 - val_accuracy: 0.7792 - val_loss: 0.4483\n",
      "Epoch 7/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4451 - val_accuracy: 0.7797 - val_loss: 0.4483\n",
      "Epoch 8/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4460 - val_accuracy: 0.7786 - val_loss: 0.4471\n",
      "Epoch 9/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.4415 - val_accuracy: 0.7803 - val_loss: 0.4468\n",
      "Epoch 10/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.4390 - val_accuracy: 0.7799 - val_loss: 0.4470\n",
      "Epoch 11/120\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4390 - val_accuracy: 0.7806 - val_loss: 0.4472\n",
      "Epoch 12/120\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100  # number of models in the ensemble\n",
    "models = []\n",
    "predictions = np.zeros((X_test_pca.shape[0], n_estimators))\n",
    "# we redefine the model because the shape of the train_set has changed since we did the PCA\n",
    "model_bag_overfit = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.05),\n",
    "    Dense(64, activation='relu', input_shape=(X_train_pca_truncated.shape[1],)),\n",
    "    Dropout(0.05),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model_bag_overfit.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "for i in range(n_estimators):\n",
    "    print(f\"Training model_bag_overfit {i + 1}/{n_estimators}...\")\n",
    "# create bootstrap sample\n",
    "    X_train_bootstrap, y_train_bootstrap = resample(X_train_pca_truncated, y_train_filtered, n_samples=len(X_train_pca), random_state=i)\n",
    "    # train the base model on the bootstrap sample\n",
    "    model_bag_overfit.fit(X_train_bootstrap, y_train_bootstrap, epochs=100, batch_size=400, validation_split=0.2, verbose=1)\n",
    "    # predict on test set\n",
    "    predictions[:, i] = model_bag_overfit.predict(X_test_pca).flatten()\n",
    "# aggregate predictions (majority vote)\n",
    "final_predictions = (np.mean(predictions, axis=1) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Bagging ensemble accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Data Set B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load dataset B (replace with the actual path)\n",
    "data_B = pd.read_csv(\"PATH_TO_DATASET_B\")\n",
    "\n",
    "# Normalize the feature columns using the same scaler as for training data\n",
    "X_B_scaled = scaler.transform(data_B)\n",
    "\n",
    "# Apply the same PCA transformation used for the training data\n",
    "X_B_pca = pca.transform(X_B_scaled)\n",
    "\n",
    "# Predict the labels for dataset B using the trained ensemble model\n",
    "predictions_B = (np.mean([model.predict(X_B_pca).flatten() for _ in range(n_estimators)], axis=0) > 0.5).astype(int)\n",
    "\n",
    "# Save predictions to a text file\n",
    "output_filename = \"06020137_Nahmias.txt\"  # Replace with your CID and surname\n",
    "np.savetxt(output_filename, predictions_B, fmt='%d')\n",
    "\n",
    "print(f\"Predictions saved to {output_filename}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
